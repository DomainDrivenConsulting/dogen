#+title: Sprint Backlog 93
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- add cross-language support.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2016-12-06 Tue 16:03]
| <75>                                                                        |         |       |      |       |
| Headline                                                                    | Time    |       |      |     % |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| *Total time*                                                                | *31:00* |       |      | 100.0 |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| Stories                                                                     | 31:00   |       |      | 100.0 |
| Active                                                                      |         | 31:00 |      | 100.0 |
| STARTED Sprint and product backlog grooming                                 |         |       | 1:51 |   6.0 |
| COMPLETED Edit release notes for previous sprint                            |         |       | 1:02 |   3.3 |
| COMPLETED Update readme                                                     |         |       | 0:11 |   0.6 |
| COMPLETED Test data generation for dates generates invalid dates            |         |       | 0:33 |   1.8 |
| COMPLETED Handle missing stitch templates scenario                          |         |       | 1:04 |   3.4 |
| COMPLETED Move project directory to output options                          |         |       | 1:10 |   3.8 |
| COMPLETED Update the conceptual model to clarify backends and kernels       |         |       | 4:20 |  14.0 |
| COMPLETED Detect knitter and disable code generation accordingly            |         |       | 1:15 |   4.0 |
| COMPLETED Clean up kernel and backend confusion                             |         |       | 5:17 |  17.0 |
| COMPLETED Add a "language" directory for each backend                       |         |       | 5:44 |  18.5 |
| COMPLETED Split C++ profiles and templates from C#                          |         |       | 1:11 |   3.8 |
| STARTED Add support for C#                                                  |         |       | 6:50 |  22.0 |
| STARTED Add support for Decimal numbers                                     |         |       | 0:32 |   1.7 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2016-12-02 Fri 09:01]--[2016-12-02 Fri 09:09] =>  0:08
    CLOCK: [2016-11-30 Wed 16:20]--[2016-11-30 Wed 16:30] =>  0:10
    CLOCK: [2016-11-30 Wed 13:37]--[2016-11-30 Wed 15:00] =>  1:23
    CLOCK: [2016-11-21 Mon 10:11]--[2016-11-21 Mon 10:21] =>  0:10

Updates to sprint and product backlog.

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2016-11-21 Mon 10:29]
    CLOCK: [2016-11-21 Mon 10:30]--[2016-11-21 Mon 11:24] =>  0:54
    CLOCK: [2016-11-21 Mon 10:21]--[2016-11-21 Mon 10:29] =>  0:08

Add github release notes for previous sprint.

Title: Dogen v0.92.0, "Praia AmÃ©lia"

#+begin_src markdown
Overview
========
The sprint's headline feature is the completion of the JSON frontend. In the past, the JSON frontend was used solely to supply "proxy models" to Dogen - i.e. top-level type definitions for external libraries such as ```std``` and ```boost```, required so that user models could consume external types.

With this release, we finally got the JSON frontend to provide the same level of support as the Dia frontend (modulus any undetected bugs). Note that Dia will remain the preferred frontend for Dogen's own development but - significantly - users are now free to choose their preferred frontend and are no longer required to install/use Dia in order to code-generate models.

As with everything else in Dogen, regrettably, the documentation is scarce. However, there are examples of JSON models in [the JSON test data pack](https://github.com/DomainDrivenConsulting/dogen/tree/master/test_data/yarn.json/input), which largely mirror [the Dia test data pack](https://github.com/DomainDrivenConsulting/dogen/tree/master/test_data/yarn.dia/input).

Other user visible changes
===================

- References are now supplied as part of the diagram rather than via the command line. This means you do not need to manually keep track of transitive references - you are only required to supply the models you directly depend on, and their references are automatically picked up. Use ```yarn.references``` to supply References via meta-data.
- External Modules are now supplied as part of the diagram rather than via the command line. This also means that references no longer require you to provide External Modules for each model that consumes them. Use ```yarn.dia.external_modules``` to supply External Modules in the Dia frontend, via meta-data. In the JSON frontend,  use ```"external_modules": "X"``` directly. As always, [Dogen's own Dia frontend models](https://github.com/DomainDrivenConsulting/dogen/tree/master/projects/input_models) provide modeling examples as well as examples for the the corresponding ```dogen.knitter``` [invocation](https://github.com/DomainDrivenConsulting/dogen/blob/master/projects/input_models/CMakeLists.txt).
- A new command line utility was added to convert Dia models into JSON models called ```tailor```. It was added primarily to simplify the work on JSON support, but it may also be useful for users wishing to migrate frontends.
- We are now uploading binary packages to [Bintray](https://bintray.com/domaindrivenconsulting/Dogen). At present we only upload Deb for Linux and DMGs for OSX. These packages are experimental. Any feedback is highly appreciated.
- Dogen no longer adds a trailing line in comments.

For more details see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_92.org).

Project Status
==========
With this release, we have more or less implemented all the major architectural features for this product we needed internally at Domain Driven Consulting, so we will focus more on using the product and fixing problems as we find them.

On the other hand, we have also successfully engaged a customer who requires C# support. It is likely that the next few iterations will focus on adding support for other languages.
#+end_src

*** COMPLETED Update readme                                           :story:
    CLOSED: [2016-11-21 Mon 11:36]
    CLOCK: [2016-11-21 Mon 11:25]--[2016-11-21 Mon 11:36] =>  0:11

Add some blurb about binary packages, JSON support and windows support.

*** COMPLETED Test data generation for dates generates invalid dates  :story:
    CLOSED: [2016-11-30 Wed 12:06]
    CLOCK: [2016-11-30 Wed 11:33]--[2016-11-30 Wed 12:06] =>  0:33

When we create dates greater than 27, we generate invalid dates. This
is because of this code:

#+begin_src
    unsigned int day((position + 1) % 27);
#+end_src

We are probably generating a zero when we get to 27.

*** COMPLETED Improve support for modules in JSON                     :story:
    CLOSED: [2016-11-30 Wed 13:41]

*Rationale*: addressed when we added JSON support.

At present we are implying the existence of modules in JSON by looking
at the types qname. This is not ideal because it means one cannot
supply meta-data for modules. We should probably revisit the layout to
have a nested structure with namespaces containing types.

We should still support "implied" modules because it makes the file
format less verbose for the common use case though.

*** COMPLETED Handle missing stitch templates scenario                :story:
    CLOSED: [2016-12-02 Fri 10:14]
    CLOCK: [2016-12-02 Fri 09:10]--[2016-12-02 Fri 10:14] =>  1:04

When bootstrapping a new model such as =quilt.csharp= which make use
of =artefact formatters=, code generation fails:

: Error: File not found: /home/marco/Development/DomainDrivenConsulting/dogen/projects/quilt.csharp/src/types/formatters/io/enum_formatter.stitch

This is because we haven't yet created the stitch templates. The right
thing to do is to create an empty template if none is found so that
bootstrapping can take place.

Actually its a bit dodgy that we are creating files in the middle of
formatting. Perhaps a better way is to do nothing. The user is still
responsible for providing the template. We just create a blank file
for the expanded content.

*** COMPLETED Move project directory to output options                :story:
    CLOSED: [2016-12-02 Fri 12:11]
    CLOCK: [2016-12-04 Sun 18:33]--[2016-12-04 Sun 18:44] =>  0:11
    CLOCK: [2016-12-02 Fri 11:12]--[2016-12-02 Fri 12:11] =>  0:59

At present we have only one C++ specific option left:

: project_directory_path

In truth, this is not C++ specific at all. We need to move it to
output options and delete the class.

Actually we have so few options now that it makes more sense to just
merge them into a single class.

*** COMPLETED Update the conceptual model to clarify backends and kernels :story:
    CLOSED: [2016-12-05 Mon 09:18]
    CLOCK: [2016-12-05 Mon 08:51]--[2016-12-05 Mon 09:17] =>  0:26
    CLOCK: [2016-12-05 Mon 08:12]--[2016-12-05 Mon 08:50] =>  0:38
    CLOCK: [2016-12-04 Sun 23:13]--[2016-12-05 Mon 00:33] =>  1:20
    CLOCK: [2016-12-04 Sun 20:36]--[2016-12-04 Sun 22:32] =>  1:56

*Rationale*: this story is not totally completed but its clear enough
so that we can now proceed with implementation. Further clean up will
have to wait for some available time.

It seems we did not do a great job at our first stab of the conceptual
model. Add the required clarifications for kernel and backends and do
a small tidy-up to ensure what's there makes sense.

*** COMPLETED Detect knitter and disable code generation accordingly  :story:
    CLOSED: [2016-12-05 Mon 14:50]
    CLOCK: [2016-12-05 Mon 15:23]--[2016-12-05 Mon 15:29] =>  0:06
    CLOCK: [2016-12-05 Mon 14:50]--[2016-12-05 Mon 15:22] =>  0:32
    CLOCK: [2016-12-05 Mon 14:12]--[2016-12-05 Mon 14:49] =>  0:37

At present you can try to build the codegen knitting targets even
before you built knitter. We should make them conditional on detecting
=knitter=. We just need to make sure this is not cached by CMake.

*** COMPLETED Clean up kernel and backend confusion                   :story:
    CLOSED: [2016-12-05 Mon 16:38]
    CLOCK: [2016-12-05 Mon 16:21]--[2016-12-05 Mon 16:38] =>  0:17
    CLOCK: [2016-12-05 Mon 15:30]--[2016-12-05 Mon 16:20] =>  0:50
    CLOCK: [2016-12-05 Mon 13:34]--[2016-12-05 Mon 14:01] =>  0:42
    CLOCK: [2016-12-05 Mon 11:09]--[2016-12-05 Mon 12:30] =>  1:21
    CLOCK: [2016-12-05 Mon 11:01]--[2016-12-05 Mon 11:08] =>  0:07
    CLOCK: [2016-12-05 Mon 09:41]--[2016-12-05 Mon 10:40] =>  1:24
    CLOCK: [2016-12-05 Mon 09:18]--[2016-12-05 Mon 09:40] =>  0:22
    CLOCK: [2016-12-04 Sun 19:41]--[2016-12-04 Sun 20:35] =>  0:54

We made it clear in the conceptual model that a kernel is made up of
one or more backends, but this was not carried out in the code
base. Now we need to instantiate multiple backends, we need to clean
up these terms.

Actually, the conceptual model is not quite as finished as we
expected. It doesn't really clarify backends or kernels, but seems to
imply that a kernel is what we've been calling a sub-kernel.

Tasks:

- clean up these definitions in the conceptual model.
- rename model in annotations to kernel (templates).
- add family to archetype location, and update existing kernel to be
  just the kernel rather than the family.
- rename all data files that refer to it, update JSON processing
  etc.

We are trying to introduce too many changes in one go, so it will be
difficult to isolate faults. We can break it down somewhat:

- split kernel from family;
- rename formatter to archetype in template kinds;
- rename global template to recursive template;
- make recursive template work at all levels.

Actually its not easy to split these tasks because they are
interrelated. However, we've moved out any work which is not strictly
required and done all the required work in one go.

*** COMPLETED Add a "language" directory for each backend             :story:
    CLOSED: [2016-12-06 Tue 11:15]
    CLOCK: [2016-12-06 Tue 11:12]--[2016-12-06 Tue 11:15] =>  0:03
    CLOCK: [2016-12-06 Tue 10:35]--[2016-12-06 Tue 11:11] =>  0:36
    CLOCK: [2016-12-06 Tue 10:23]--[2016-12-06 Tue 10:34] =>  0:11
    CLOCK: [2016-12-06 Tue 09:51]--[2016-12-06 Tue 10:22] =>  0:31
    CLOCK: [2016-12-06 Tue 09:02]--[2016-12-06 Tue 09:50] =>  0:48
    CLOCK: [2016-12-05 Mon 21:54]--[2016-12-05 Mon 22:01] =>  0:07
    CLOCK: [2016-12-05 Mon 21:30]--[2016-12-05 Mon 21:53] =>  0:23
    CLOCK: [2016-12-05 Mon 20:39]--[2016-12-05 Mon 21:29] =>  0:50
    CLOCK: [2016-12-05 Mon 20:17]--[2016-12-05 Mon 20:38] =>  0:21
    CLOCK: [2016-12-05 Mon 20:01]--[2016-12-05 Mon 20:16] =>  0:15
    CLOCK: [2016-12-05 Mon 17:27]--[2016-12-05 Mon 18:08] =>  0:41
    CLOCK: [2016-12-05 Mon 17:10]--[2016-12-05 Mon 17:26] =>  0:16
    CLOCK: [2016-12-05 Mon 16:38]--[2016-12-05 Mon 16:43] =>  0:05
    CLOCK: [2016-12-04 Sun 19:37]--[2016-12-04 Sun 19:40] =>  0:03
    CLOCK: [2016-12-04 Sun 18:53]--[2016-12-04 Sun 19:27] =>  0:34

In order to support multiple backends, we need to split the project
directory by backend - which maps to a programming language (at least
at present). For example:

: cpp
: csharp
: ...

Note that we do not support multiple kernels at present, but this
could easily be achieved by adding the kernel to the directory name:

: quilt.cpp
: quilt.csharp
: ...

The splitting of the output directory should only kick in when there
are two or more enabled backends. We also need to ensure there is
at least one enabled backend.

For this to work we need:

- =enabled= as a backend template, expanded for all available
  backends. The field needs to move up to the =quilt= configuration.
- =quilt= to check the conditions set above and inform the backends
  that they need to use the backend directory or not. We could
  optionally have a switch that forces always using backend
  directory. This is useful in cases where users have some models only
  for one language, but others models which use more than one language
  and want to use a consistent directory layout.
- add a backend field for the kernel directory name; this can also be
  a backend template. This allows users to configure the directory
  name.

Tasks:

- rename archetype location in backend to something else to reflect
  its real purpose (locations of all formatters). Source it directly
  from quilt rather than the quilt registrar in knit.
- add archetype location for the backend itself.
- read enabled field in the quilt model for all backends. Remember the
  number of enabled backends.
- before executing a backend, get its archetype location and obtain
  the corresponding enabled field. If not enabled, do not execute.
- if enabled, supply the number of enabled backends to the backend and
  pass it on to locator.
- add a field at quilt level: =enable_kernel_directories=. Defaults to
  false. If true, we always generate it. If false, and number of
  enabled backends > 1 we also generate it (logging a warning). Add a
  "kernel_type_group" to locator to read these new fields.
- add a field at quit.cpp level: directory. If we need a kernel
  directory, read this field and use it when creating output
  directory.
- rename backends to kernels, no need for two terms to mean the same
  thing.
- set =quilt.csharp.enabled= to false on all test models to start off
  with, and update them as we start adding C# support.

: +#DOGEN quilt.enable_kernel_directories=true

*** COMPLETED Split C++ profiles and templates from C#                :story:
    CLOSED: [2016-12-06 Tue 16:03]
    CLOCK: [2016-12-06 Tue 15:52]--[2016-12-06 Tue 16:03] =>  0:11
    CLOCK: [2016-12-06 Tue 15:38]--[2016-12-06 Tue 15:51] =>  0:13
    CLOCK: [2016-12-06 Tue 14:01]--[2016-12-06 Tue 14:48] =>  0:47

When we did =quilt.cpp= there was an implicit assumption that C++ and
C# would share formatters, profiles, etc. Hence they were named:

: artefact formatter
: helper formatter

And so forth. Same with the wale templates. However:

- the formatter interfaces for C# are different - simpler, so it makes
  no sense to add the C++ complexity;
- by implication, the wale templates will also be different too;
- so the profiles must be different as well.

However, these names are quite clear so we need to preserve some of
that clarity. Options:

: cpp artefact formatter
: cpp helper formatter

: artefact formatter (cpp)
: helper formatter (cpp)

: c++ artefact formatter
: c++ helper formatter

*** STARTED Add support for C#                                        :story:
    CLOCK: [2016-12-06 Tue 11:24]--[2016-12-06 Tue 12:20] =>  0:56
    CLOCK: [2016-12-06 Tue 11:16]--[2016-12-06 Tue 11:24] =>  0:08
    CLOCK: [2016-12-04 Sun 18:45]--[2016-12-04 Sun 18:52] =>  0:07
    CLOCK: [2016-12-04 Sun 18:29]--[2016-12-04 Sun 18:33] =>  0:04
    CLOCK: [2016-12-02 Fri 13:10]--[2016-12-02 Fri 13:28] =>  0:18
    CLOCK: [2016-12-02 Fri 11:06]--[2016-12-02 Fri 11:12] =>  0:06
    CLOCK: [2016-12-02 Fri 10:35]--[2016-12-02 Fri 11:05] =>  0:30
    CLOCK: [2016-12-02 Fri 10:15]--[2016-12-02 Fri 10:35] =>  0:20
    CLOCK: [2016-12-01 Thu 11:01]--[2016-12-01 Thu 12:16] =>  1:15
    CLOCK: [2016-11-30 Wed 16:21]--[2016-11-30 Wed 17:45] =>  1:24
    CLOCK: [2016-11-30 Wed 16:19]--[2016-11-30 Wed 16:20] =>  0:01
    CLOCK: [2016-11-30 Wed 16:01]--[2016-11-30 Wed 16:19] =>  0:18
    CLOCK: [2016-11-30 Wed 13:37]--[2016-11-30 Wed 15:00] =>  1:23

Create a quilt model for C#.

Notes:

- at present the formatters are all using wale templates for C++. This
  won't work. Create either new wale templates for C# or maybe to
  start off with just hand craft the formatters until we can see a
  pattern emerging.

Tasks:

- add one formatter in =quilt.csharp=, with a archetype location so
  that we generate its fields - remove the hack of manually generating
  archetype locations.

*** STARTED Add support for Decimal numbers                           :story:
    CLOCK: [2016-11-30 Wed 13:04]--[2016-11-30 Wed 13:36] =>  0:32

- try using ICU DecNumber library.
- check compiler support (MSVC may have decimals; if so, use that instead)

*** Knitting =quilt= does not work                                    :story:

When we invoke =knit_quilt= for some reason we seem to knit
=quilt.cpp=:

: $ ninja knit_quilt
: [1/1] Knitting Quilt C++ model

This seems to be some kind of ninja "feature".

For the moment we've put in a very ugly fix: we renamed the target
=knit_quiltx=.

*** Use templates for directory and prefix fields                     :story:

At present we have a lot of duplication on the annotations for certain
fields. This is because we need different defaults depending on the
facet etc. A different approach would be to use the appropriate
template (without default values) and then using profiles to default
those that need defaulting.

Other fields may also need a similar clean up:

- overwrite

In addition, we could add support for "default value variables". These
are useful for directories. They work as follows: the default value is
something like =${facet.simple_name}= or perhaps just
=${simple_name}=, in which case we assume the template kind determines
the target. Say the target is the kernel:

:      "family": "quilt",
:      "kernel": "quilt.cpp",

The simple name is then =kernel - family=, e.g. =cpp=. Unfortunately
this does not work for prefix.

Tasks:

- make prefix a recursive field at archetype level, adding default
  values to profiles.
- make directory a recursive field at facet level,  adding default
  values to profiles.

*** Add an example of redis and dogen                                 :story:

Building external project:

: cd /home/marco/Development/DomainDrivenConsulting/redis/build/output/gcc-6/Release &&
: CMAKE_PROGRAM_PATH=/home/marco/Development/DomainDrivenConsulting/dogen/build/output/gcc/Release/stage/bin
: CMAKE_INCLUDE_PATH=/usr/local/personal/include CMAKE_LIB_PATH=/usr/local/personal/lib
: cmake ../../../.. -G Ninja && Ninja -j5

Redis client:

https://github.com/nekipelov/redisclient
git@github.com:nekipelov/redisclient.git

*** Add support for object caches                                      :epic:

It would be good to have meta-model knowledge of "cacheability". This
is done by marking objects with a stereotype of =Cacheable=. It then
could translate to:

- adding a serialisation like interface with gets, puts, etc. We need
  to bind this to a specific cache such as memcache, coherence, etc.
- create a type to string which converts a key made up of primitives
  into a underscore delimited string, used as a key in the cache.
- we should also consider external libraries like [[https://github.com/cripplet/cachepp][cachepp]].

*** Models should have an associated language                          :epic:

#+begin_quote
*Story*: As a dogen user, I want to make sure I only use valid system
models so that I don't generate models that code generate but do not
compile.
#+end_quote

Certain models (e.g. system / library models) can only be used in a
give language; for example =boost= and =std= only make sense in C++. A
.Net library model would only make sense in .Net, etc. These are
Language Specific Models (LSM). Once a model depends on a LSM it
itself becomes an LSM and it should not be able to then make use of
models of other languages nor should one be able to request a code
generation for other languages.

However, one day we will have a system model which is a Language
Agnostic Model (LAM). The system model will provide a base set of
functionality across languages such as containers, and for each type
it will have mappings to language specific types. The mapping is
declared as dynamic extensions in the appropriate section
(i.e. =tags::cpp::mapped_type= or something of that ilk). If a model
depends only on LAMs, it is itself a LAM and can be used to generate
code on any supported language (presumably a supported language is
defined to be that for which we have both mappings and a code
generation backend).

A first step for this would be to have a language enumeration in yarn
which is a property of the model, and one entry of which is "language
agnostic".

*** Add support for Language Agnostic Models (LAM)                    :story:

When we start supporting more than one language, one interesting
feature would be to be able to define a model once and have it
generated for all supported languages. This would be achieved by
having a system model (or set of system models) that define all the
key types in a language agnostic manner. For example:

: lam::string
: lam::int
: lam::int16

Each of these types then has a set of meta-data fields that map them
to a type in a supported language:

: lam:string: cpp.concrete_type_mapping = std::string
: lam:string: csharp.concrete_type_mapping = string

And so on. We load the user model that makes use of LAM, we generate
the merged model still with LAM types and then we perform a
translation for each of the supported and enabled languages: for every
LAM type, we replace all its references with the corresponding
concrete type. We need to split the supplied mapping into a QName, use
the QName to load the system models for that language, look up the
type and replace it. After the translation no LAM types are left. We
end up with N yarn merged models where N is the number of supported and
enabled languages.

Each of these models is then sent down to code generation. This should
be equivalent to manually generating models per language - we could
use this as a test.

Once we have LAM, it would be great to be able to exchange data
between languages. This could be done as follows:

- XML: create a "LAM" XML schema, and a set of formatters that read
  and write from it. This is kind of like reverse mapping the types
  back to LAM types when writing the XML.
- JSON: similar approach to XML, minus the schema.
- POF: use the coherence libraries to dump the models into POF.

Tasks:

- create the LAM model with a set of basic types.
- add a set of mapping fields into yarn: =yarn.mapping.csharp=, etc
  and populate the types with entries for each supported language.
- create a notion of mapping of intermediate models into
  languages. The input is the merged intermediate model and the output
  is N models one per language. We also need a way to associate
  backends with languages. Each model is sent down to its backend.
- note that reverse mapping is possible: we should be able to
  associate a type on a given language with it's lam type. This means
  that, given a model in say C#, we could reconstruct a yarn lam model
  (or tell the user about the list of failures to map). This should be
  logged as a separate story.

*** Add C++-03 mode                                                    :epic:

#+begin_quote
*Story*: As a dogen user, I want to create models in C++ 03 so that I
can interface with legacy code.
#+end_quote

It shouldn't be too hard to generate C++-03 code in addition to
C++-14. We could follow the gcc/odb convention and have a =-std=
option for this in meta-data. The only problem would be testing - at
present the language settings comes from cmake, and we'd have to make
sure the compiler is not in C++-14 mode when compiling test models
in 03. Also, the mixing and matching of 03 with 14 may not be
trivial. We should wait for a use case.

It may be possible to add different flags to different projects in CMake.

*** Add support for thrift and protocol buffers                        :epic:

#+begin_quote
*Story*: As a dogen user, I want to expose dogen models to other
languages so that I can make use of them on these languages.
#+end_quote

Amongst other things, these technologies provide cross-language
support, allowing one to create c++ services and consume them from say
ruby, python, etc. At their heart they are simplified versions of
CORBA/DCOM, with IDL equivalents, IDL compilers, specification for
wire formats, etc. As they all share a number of commonalities, we
shall refer to these technologies in general as Distributed Services
Technologies (DST). We could integrate DST's with Dogen in two
ways. First approach A:

- generate the IDL for a model; we have enough information to produce
  something that is very close to it's Dogen representation,
  translated to the type system of the IDL; e.g. map =std::string=,
  =std::vector=, etc to their types. This IDL is then compiled by the
  DST's IDL to C++ compiler. Note: we could use LAM for this, but the
  problem is if one starts with a C++ model, one would have to convert
  it into LAM just to be able to do the mappings. A solution for this
  problem would be to "reverse map" LAM from C++ and get to the
  generic type this way.
- possibly generate the transformation code that takes a C++ object
  generated by Dogen and converts it into the C++ object generated by
  the DST's C++ compiler and vice-versa. We probably have enough
  information to generate these transformers automatically, after some
  analysis of the code generated by the DST's C++ compiler.

In order for this to work we need to have the ability to understand
function signatures for services so that we can generate the correct
service IDL for the DST. In fact, we should be able to mark certain
services as DST-only so that we do not generate a Dogen representation
for them. The DST service then internally uses the transformer to take
the DST's domain types and convert them into Dogen domain types, and
then uses the Dogen object model to implement the guts of the
service. When shipping data out, the reverse process takes place.

Approach A works really well when a service has a very narrow
interface, and performs most of it's work internally without exposing
it via the interface. Once the service requires the input (and/or
output) of a large number of domain types, we hit a cost limitation;
we may end up defining as many types in Dogen as there are in the IDL,
thus resulting in a large amount of transformations between the two
object models.

In these cases one may be tempted to ignore Dogen and implement the
service directly in terms of the DST's object model. This is not very
convenient as the type system is not as expressive as regular C++ -
there are a number of conventions that must be adopted, and
limitations imposed too due to the expressiveness of the IDL. We'd
also loose all the services provided by Dogen, which was the main
reason why we created it in the first place.

Approach B is more difficult. We could look into the wire format of
each DST and implement it as serialisation mechanism. For this to
work, the DST must:

- provide some kind of raw interface that allows one to plug in types
  serialisation manually. Ideally we wouldn't have to do this for
  services, just for domain types, but it depends on the low-level
  facilities available. A cursory look at both thrift and protocol
  buffers does not reveal easy access to such an interface.
- provide either a low-level wire format library (e.g. =std::string=
  to =string=, etc) or a well specified wire format that we could
  easily implement from scratch.

This approach is the cleaner technically, but its a lot of work, and
very hard to get right. We would have to have a lot of round-trip
tests. In addition, DST's such as thrift provide a wealth of wire
formats, so if there is no easy-access low-level wire format library,
it would be very difficult to get this right.

*** Add support for BSON serialisation                                :story:

It would be useful to support Mongo DB's BSON. There is a C++ stand
alone library for this:

https://github.com/jbenet/bson-cpp

For examples on how to use the C++ API see the tutorial:

https://github.com/mongodb/mongo-cxx-driver/wiki/Tutorial

*** Add support for deprecation                                       :story:

#+begin_quote
*Story*: As a dogen user, I want to mark certain properties, classes
or methods as deprecated so that I can tell my users to stop using
them.
#+end_quote

We should be able to mark classes and properties as deprecated and
have that reflected in both doxygen and C++-11 deprecated attributes.

Note that at present nothing stops the users from adding the marker
themselves.

Perhaps we should add general support for attributes. This would be
useful for languages like C# and Java, to control serialisation, etc.

*** Add a frontend for visual studio models                           :story:

It should be "fairly straightforward" to add a frontend for visual
studio. A sample project has been added to test data:

: test_data/visual_studio_modeling

We should also extend tailor to output these projects so we can test
it with existing models.

*** Create a tool to generate product skeletons                       :story:

Now that dogen is evolving to a MDSD tool, it would be great to be
able to create a complete product skeleton from a tool. This would
entail:

- directory structure. We should document our standard product
  directory structure as part of this exercise. Initial document added
  to manual as "project_structure.org".
- licence: user can choose one.
- copyright: input by user, used in CMakeFiles, etc. added to the
  licence.
- CI support: travis, appveyor
- EDE support:
- CMake support: top-level CMakefiles, CPack. versioning
  templates, valgrind, doxygen. For CTest we should also generate a
  "setup cron" and "setup windows scheduler" scripts. User can just
  run these from the build machine and it will start running CTest.
- conan support: perhaps with just boost for now
- agile with first sprint
- README with emblems.

Name for the tool: dart.

Tool should have different "template sets" so that we could have a
"standard dogen product" but users can come up with other project
structures.

Tool should add FindODB if user wants ODB support. Similar for EOS
when we support it again. We should probably have HTTP links to the
sources of these packages and download them on the fly.

Tool should also create git repo and do first commit (optional).

For extra bonus points, we should create a project in GitHub, Travis
and AppVeyor from dart.

We should also generate a RPM/Deb installation script for at least
boost, doxygen, build essentials, clang.

We should also consider a "refresh" or "force" statement, perhaps on a
file-by-file basis, which would allow one to regenerate all of these
files. This would be useful to pick-up changes in travis files, etc.

One problem with travis files is that each project has its own
dependencies. We should move these over to a shell script and call
these. The script is not generated or perhaps we just generate a
skeleton. This also highlights the issue that we have different kinds
of files:

- files that we generate and expect the user to modify;
- files that we generate but don't expect user modifications;
- files that the user generates.

We need a way to classify these.

Dart should use stitch templates to generate files.

We may need some options such as "generate boost test ctest
integration", etc.

Notes:

- [[https://github.com/elbeno/skeleton][Skeleton]]: project to generate c++ project skeletons.
- split all of the configuration of CMake dependencies from main CMake
  file. Possible name: ConfigureX? ConfigureODB, etc. See how find_X
  is implemented.
- detect all projects by looping through directories.
- fix CMake generation so that most projects are generated by Dogen.
- add option to Dogen to generate test skeleton.
- detect all input models and generate targets by looping through
  them.
- add CMake file to find knitter etc and include those files in
  package. We probably should install dogen now and have dogen rely on
  installed dogen first, with an option to switch to "built" dogen.

*** Merge properties factory with stitching factory                   :story:

In stitch we still have a few classes that are light on
responsibilities. One case is the stitching properties factory, traits
etc. We should merge all of this into a single class, properties
factory.

*** Rename project directory path                                     :story:

The C++ options have an attribute called
=project_directory_path=. This is a bit misleading; it is actually the
top-level directory that will contain the project directory. In
addition, this is not really C++ specific at all; it would apply to
any kernel and sub-kernel. We should rename it and move it to output
options.

*** Add log-level to command line                                     :story:

We are now increasingly logging at trace levels. We need to allow
users to supply a more fine-grained log configuration. This could be
done by simply allowing users to set the log level via a command-line
flag: =log_level=. It would replace verbose.

*** Consider adding =artefact_set= to formatters' model               :story:

We are using collections of artefacts quite a bit, and it makes sense
to create an abstraction for it such as a =artefact_set=. However, for
this to work properly we need to add at least one basic behaviour: the
ability to merge two artefact sets. Or else we will end up having to
unpack the artefacts, then merging them, then creating a new artefact
set.

Problem is, we either create the artefact set as a non-generatable
type - not ideal - or we create it as generatable and need to add this
as a free function. We need to wait until dogen has support for
merging code generation.

*** Consider supplying element configuration as a parameter           :story:

Figure out if element configuration is context or if it is better
expressed as a stand alone formatting parameter.

*** Formatters' repository should be created in quilt                 :story:

At present we are creating the formatters' repository in
=quilt.cpp=. However it will be shared by all backends in the
kernel. Move it up to =quilt= level and supply it as a paramter to the
backends.

*** Initialise formatters in the formatter's translation unit         :story:

At present we are initialising the formatters in each of the facet
initialisers. However, it makes more sense to initialise them on the
translation unit for each formatter. This will also make life easier
when we move to a mustache world where there may not be a formatter
header file at all.

*** Add knobs to control output of constructors and operators         :story:

At present we are outputting all of the default constructors and the
operators in the handcrafted templates. Ideally it should just be the
class name. We need a way of controlling all of the default
constructors and all of the operators in one go so we can set it on
the handcrafted profile.

** Deprecated
