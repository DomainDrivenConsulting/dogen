#+title: Sprint Backlog 98
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Improve ODB support.
- Improve C++ Visual Studio support.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2017-03-03 Fri 11:35]
| <75>                                                                        |         |       |       |       |
| Headline                                                                    | Time    |       |       |     % |
|-----------------------------------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                                                | *35:42* |       |       | 100.0 |
|-----------------------------------------------------------------------------+---------+-------+-------+-------|
| Stories                                                                     | 35:42   |       |       | 100.0 |
| Active                                                                      |         | 35:42 |       | 100.0 |
| STARTED Sprint and product backlog grooming                                 |         |       |  2:01 |   5.6 |
| COMPLETED Edit release notes for previous sprint                            |         |       |  0:30 |   1.4 |
| COMPLETED Fix the handling of ODB pragmas for yarn primitives               |         |       |  0:56 |   2.6 |
| COMPLETED Rename intermediate model expander and model factory              |         |       |  0:53 |   2.5 |
| COMPLETED Injection splits annotation from intermediate model               |         |       |  0:35 |   1.6 |
| COMPLETED ODB Fixes to support Oracle                                       |         |       |  2:14 |   6.3 |
| COMPLETED Setup codacy                                                      |         |       |  0:22 |   1.0 |
| STARTED Create a language independent ORM layer                             |         |       |  7:24 |  20.7 |
| STARTED Implement the database model using Northwind                        |         |       | 20:47 |  58.2 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2017-03-03 Fri 11:20]--[2017-03-03 Fri 11:35] =>  0:15
    CLOCK: [2017-03-03 Fri 10:15]--[2017-03-03 Fri 11:19] =>  1:04
    CLOCK: [2017-03-03 Fri 08:21]--[2017-03-03 Fri 08:39] =>  0:18
    CLOCK: [2017-02-24 Fri 13:01]--[2017-02-24 Fri 13:16] =>  0:15
    CLOCK: [2017-02-13 Mon 11:55]--[2017-02-13 Mon 12:04] =>  0:09

Updates to sprint and product backlog.

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2017-02-13 Mon 12:35]
    CLOCK: [2017-02-13 Mon 12:18]--[2017-02-13 Mon 12:35] =>  0:17
    CLOCK: [2017-02-13 Mon 12:04]--[2017-02-13 Mon 12:17] =>  0:13

Add github release notes for previous sprint.

Title: Dogen v0.97.0, "Marginal"

#+begin_src markdown
![alt text](http://www.angolabelazebelo.com/wp-content/uploads/2012/11/Namibe-23102661.jpg)
Marginal de MoÃ§amedes, Namibe, Angola. (C) Angola Bela. Sourced from Angola Bela's site.

Overview
=======
This sprint had work slightly scattered, but the core work are a few interesting features for users around enumerations and primitives - described below.

In this release we also started work on the next generation parser, thanks to @klemens-morgenstern who has laid its foundations. The integration work of this new parser will proceed over the next few sprints.

User visible changes
===============
In this sprint, a small number of user visible changes were made:

- **Enumerations are more configurable**: Its now possible to disable the ```invalid``` enumeration and add user defined enumeration values. This is useful for defining bitflags for example. See the ```enumeration``` test model for examples ([Dia](https://raw.githubusercontent.com/DomainDrivenConsulting/dogen/master/test_data/yarn.dia/input/enumeration.dia), [JSON](https://raw.githubusercontent.com/DomainDrivenConsulting/dogen/master/test_data/yarn.json/input/enumeration.json)).
- **Introduction of Primitives**: A new meta-model concept was introduced called a ```primitive```. This allows users to "redefine" built-in types or other select types such as ```std::string``` for their own purposes. As an example you can define a ```product_id``` as a primitive with an underlying type of ```std::string```. This makes the models more intuitive and the generated code more readable. See the ```primitive``` test model for examples ([Dia](https://raw.githubusercontent.com/DomainDrivenConsulting/dogen/master/test_data/yarn.dia/input/primitive.dia), [JSON](https://raw.githubusercontent.com/DomainDrivenConsulting/dogen/master/test_data/yarn.json/input/primitive.json)).
- **Improvements in Validation**: assorted updates to validation, including checking that the enumeration underlying type is valid as an enumeration type, checking for C# keywords, etc.

For more details of the work carried out this sprint, see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_97.org).

Next Sprint
========
The next sprint will continue to focus on Upsilon and hopefully C#.

Binaries
======
You can download experimental binaries from [Bintray](https://bintray.com/domaindrivenconsulting/Dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_0.97.0_amd64-applications.deb](https://dl.bintray.com/domaindrivenconsulting/Dogen/0.97.0/dogen_0.97.0_amd64-applications.deb)
- [dogen-0.97.0-Darwin-x86_64.dmg](https://dl.bintray.com/domaindrivenconsulting/Dogen/0.97.0/dogen-0.97.0-Darwin-x86_64.dmg)
- [dogen-0.97.0-Windows-AMD64.msi](https://dl.bintray.com/domaindrivenconsulting/Dogen/dogen-0.97.0-Windows-AMD64.msi)

**Note**: They are produced by CI so they may not yet be ready.

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/820962437465866241][Tweet]]

*** COMPLETED Fix the handling of ODB pragmas for yarn primitives     :story:
    CLOSED: [2017-02-25 Sat 21:53]
    CLOCK: [2017-02-25 Sat 21:32]--[2017-02-25 Sat 21:52] =>  0:20
    CLOCK: [2017-02-25 Sat 20:55]--[2017-02-25 Sat 21:31] =>  0:36

If we are to support primitives with ODB, we should probably have a
mechanism to automatically add the pragmas to the primitive:

: #pragma db value(region_id) schema("northwind")
: #pragma db member(region_id::value_) column("region_id")

In addition we are not generating pragmas at all for primitives at
present.

Actually we should only add the member pragma if there is at least one
value-level pragma.

Final decision on this was to generate the pragma on the back of a
schema pragma insertion and to inject the attribute automatically on
the back of it.

*** COMPLETED Rename intermediate model expander and model factory    :story:
    CLOSED: [2017-02-25 Sat 23:52]
    CLOCK: [2017-02-25 Sat 23:37]--[2017-02-25 Sat 23:52] =>  0:15
    CLOCK: [2017-02-25 Sat 22:58]--[2017-02-25 Sat 23:36] =>  0:38

Originally we thought of these classes as if they pertained to the
type of model they were working on; however, with the appearance of
first and second stage validation it became clear that we just have
two pipelines for two different stages of processing. Rename these two
classes to reflect the pipelines, and split out the final model
generation from the second stage.

*** COMPLETED Fix ODB targets                                         :story:
    CLOSED: [2017-02-25 Sat 23:56]

*Rationale*: Fixed as part of other codegen fixes.

At present the ODB targets make no sense:

- we must manually create =codegen_northwind=
- the name =codegen= is obscure - should just be "odb"

*** COMPLETED Injection splits annotation from intermediate model     :story:
    CLOSED: [2017-02-26 Sun 00:41]
    CLOCK: [2017-02-26 Sun 00:32]--[2017-02-26 Sun 00:41] =>  0:09
    CLOCK: [2017-02-26 Sun 00:05]--[2017-02-26 Sun 00:31] =>  0:26

For some random reason we decided to supply both the intermediate
model and the root annotation into the injectors, when they can
themselves obtain it from the intermediate model. This just causes
confusion because now it seems the API is telling us that the root
annotation could come from somewhere else, when in fact it
can't. Remove it from the API and force injectors to read it directly
from the intermediate model.

*** COMPLETED ODB Fixes to support Oracle                             :story:
    CLOSED: [2017-02-26 Sun 22:04]
    CLOCK: [2017-02-26 Sun 21:02]--[2017-02-26 Sun 22:04] =>  1:02
    CLOCK: [2017-02-25 Sat 23:54]--[2017-02-26 Sun 00:04] =>  0:10
    CLOCK: [2017-02-25 Sat 22:30]--[2017-02-25 Sat 22:57] =>  0:27
    CLOCK: [2017-02-25 Sat 21:54]--[2017-02-25 Sat 22:29] =>  0:35

At present we hard-coded quite a bit of the ODB profile just to allow
it to work for postgres. However, this is now causing problems when we
try to use oracle.

We need to make the hard-coded parameters configurable via meta-data.

#+begin_example
modified   Src/XDatabase/CMakeLists.txt
@@ -49,15 +49,16 @@ foreach(odb_file ${all_odb_files})
         string(REPLACE "\\" "_" type_name ${type_name})
         string(REPLACE "/" "_" type_name ${type_name})
+        set(pfh_dir "$ENV{PFH_LOCATION}")
         set(target_name "codegen_XDatabase_odb_${type_name}")
         add_custom_target(${target_name}
             WORKING_DIRECTORY ${CMAKE_BINARY_DIR}
-            COMMAND ${ODB_COMPILER}
+            COMMAND odb
             --options-file ${CMAKE_CURRENT_SOURCE_DIR}/src/options.odb
             --std c++11
             --output-dir ${CMAKE_CURRENT_SOURCE_DIR}/include/Stockpile/XDatabase/odb/
-            --odb-epilogue "\"#include \\\"Stockpile/XDatabase/odb/${odb_file}\"\\\""
-            -I c:/home/local/cpp/include -I ${CMAKE_CURRENT_SOURCE_DIR}/include
+            --odb-epilogue '\#include \"Stockpile/XDatabase/odb/${odb_file}\"'
+            -I ${pfh_dir}/include -I ${CMAKE_CURRENT_SOURCE_DIR}/include
             ${include_dir}/types/${type_name}.hpp)
         add_dependencies(codegen_XDatabase_odb ${target_name})


modified   Src/XDatabase/src/options.odb
@@ -13,10 +13,11 @@
# this material is strictly forbidden unless prior written permission is
# obtained from the copyright holder.
#
---std c++11
+# enable C++11. FIXME: causes ODB crash in options file.
+# --std c++11
-# target oracle
---database oracle
+# target postgres
+--database pgsql
 # use the boost profile
--profile boost
#+end_example

*** COMPLETED Make ODB backend settable from meta-data                :story:
    CLOSED: [2017-02-26 Sun 22:04]

*Rationale*: Fixed as part of another story.

At present we hard-coded the ODB backend in the options file. However:

- we may have more than one backend;
- users must be able to set them.

*** COMPLETED Setup codacy                                            :story:
    CLOSED: [2017-03-01 Wed 20:04]
    CLOCK: [2017-03-01 Wed 19:41]--[2017-03-01 Wed 20:03] =>  0:22

We created an account for codacy but never got round setting it
up. How to set it up:

#+begin_quote
For future reference, I didn't realise I needed to manually enable the
checkers: Code Patterns (left hand-side bar at the bottom), cppcheck,
tick all boxes (all 302 of them, in my case). You can also provide a
config file, apparently.
#+end_quote

*** STARTED Create a language independent ORM layer                   :story:
    CLOCK: [2017-03-02 Thu 09:39]--[2017-03-02 Thu 10:03] =>  0:24
    CLOCK: [2017-03-02 Thu 08:05]--[2017-03-02 Thu 09:38] =>  1:33
    CLOCK: [2017-03-02 Thu 06:48]--[2017-03-02 Thu 07:28] =>  0:40
    CLOCK: [2017-03-01 Wed 13:10]--[2017-03-01 Wed 17:57] =>  4:47

At present we are populating ODB pragmas manually. While this works,
this has a number of downsides:

- we need to add ODB schema pragmas to all types we want to
  generate. Ideally it would be better to just mark the type as
  "ORM generatable" or some other flag. Dogen then adds the appropriate
  ODB pragmas.
- we need to manually upper case all schemas and column names. Whilst
  this can be ameliorated by using the ODB compiler command line
  options, we still have to deal with the cases where the user
  overrides the schema name or the column name. Because ODB uses
  quotes, we get the values as-is, meaning the user needs to upper
  case all of them. This is a particular problem for primitives,
  because we are injecting the column name.
- whenever the primitive name matches the attribute name, we want to
  "reset" the column name; else we end up with a name like
  "my_id_my_id". Actually the solution is the other way around:
  primitives should always have a blank column name and the attribute
  using them should be responsible for setting the column name.

These are:

- =yarn.orm.enabled=: model module level. If true, will switch on language
  specific ORM. Do we need this? Users should just enable low-level
  ORM.
- =yarn.orm.generate_mapping=: boolean. If true, generate mapping for a
  given type.
- =yarn.orm.database=: container of supported database types. Create
  enumeration. PostgreSQL, etc. Model level.
- =yarn.orm.override=: if true, orm meta-data is ignored
  altogether. User is expected to manually supply ODB
  pragmas. Actually we can just not use "generate_mapping" for this
  type and add pragmas manually. Actually we should wait for a use
  case for this; we may need an "additive" override, or a "remove all
  and add only these" override. For now lets just not support
  overrides.
- =yarn.orm.schema_name=: model module level or element
- =yarn.orm.table_name=: element
- =yarn.orm.is_primary_key=: boolean. Attribute level.
- =yarn.orm.column_name=: string. Attribute level.
- =yarn.orm.nullable=: boolean. Attribute level.
- =yarn.org.naming_style=: enum: capitals, lowercase, as_is. Model
  level.
- =yarn.org.meta_type=: value or object.
- =yarn.org.type_mapping=: string. For now only BLOB is
  supported. Actually lets use a generic mapping scheme instead so
  that we push this logic to the user.

Basically we have the following "configuration points":

- =orm_model_configuration=: naming style, database, schema name;
- =orm_element_configuration=: generate mapping, schema name, table
  name, meta type
- =orm_attribute_configuration=: type, nullable, column name, is
  primary key.

We need to add classes in yarn to capture this.

*Previous Understanding*

When we start using odb in anger we need to tidy-up how it is
implemented. We need to split the concepts which properly belong in
yarn such as identity, primary key, foreign key, etc from those that
are odb specific (perhaps schema name etc). odb formatter simply maps
yarn concepts to odb concepts rather than having its own. We need to
dig out the stories around key support.

This story should only be done when we are building real databases
with odb.

This time has arrived now. We should create a set of concepts in yarn
related to ORM (object-relational mapping).

*** Add a "flat directory" mode                                       :story:

It would be nice to have a mode in which all files get placed in a
single-directory: no src, include, etc â just one big folder with all
files.

*** Add support for "one off" profiles                                :story:

At present one can define top-level profiles. These are useful, but in
practice we ended up still defining a lot of things in each model. We
need a way to associate a profile with a model by supplying it on the
command line. That way users can create profiles and store them next
to the model rather than having to create a data directory, etc etc.

*** Introduce dogen projects                                          :story:

At present we are manually configuring each dogen target, adding each
separately to the build system. Perhaps a better approach is to have a
dogen project file where one can configure all of the targets in one
go. We donât necessarily have to call dogen directly â perhaps another
command line tool is responsible for invoking dogen? The problem here
is that weâd end up with all dogen models in memory.

At any rate, the project file would contain all models for a given
product. We could possibly run with âallâ or âspecificâ whereby the
user would supply one or more projects to code generate. For all
properties that are common, weâd defined them only once somehow
(common regexes, log level, etc).

*** Make log directory configurable                                   :story:

It would be nice to supply a directory for the log files and get dogen
to output the logs there.

*** Clean up annotation scope types                                   :story:

As part of the attribute rename (which used to be called property) we
should have renamed the annotation scope as well to attribute.

In addition, we have a scope type of "entity" but the yarn meta-model
type is really "element".

We should also check if "not applicable" scope is in use, and if not
delete it.

*** Add a new annotation type of "pair"                               :story:

It would be nice to be able to declare a annotation type with a value
type of "pair" or "key value pair" and have the annotations
automatically perform the splitting. The separator should not be
equals, since we already use that for annotations kvps, but it could
be comma, pipe, etc. The API would be augmented to return a
=std::pair= with key and value.

One slight snag: the value could be of any type:

- boolean
- string
- enumeration (when we support these)
- even text collection

We can start by just supporting strings, but probably worthwhile
having a think on how to specify the type.

*** STARTED Implement the database model using Northwind              :story:
    CLOCK: [2017-02-28 Tue 06:41]--[2017-02-28 Tue 07:25] =>  0:44
    CLOCK: [2017-02-27 Mon 22:11]--[2017-02-27 Mon 22:34] =>  0:23
    CLOCK: [2017-02-27 Mon 21:10]--[2017-02-27 Mon 22:10] =>  1:00
    CLOCK: [2017-02-26 Sun 23:22]--[2017-02-27 Mon 00:10] =>  0:48
    CLOCK: [2017-02-26 Sun 22:48]--[2017-02-26 Sun 23:21] =>  0:33
    CLOCK: [2017-02-26 Sun 22:05]--[2017-02-26 Sun 22:47] =>  0:42
    CLOCK: [2017-02-25 Sat 19:47]--[2017-02-25 Sat 19:52] =>  0:05
    CLOCK: [2017-02-25 Sat 18:56]--[2017-02-25 Sat 19:46] =>  0:50
    CLOCK: [2017-02-25 Sat 18:02]--[2017-02-25 Sat 18:56] =>  0:54
    CLOCK: [2017-02-25 Sat 04:05]--[2017-02-25 Sat 05:54] =>  1:49
    CLOCK: [2017-02-24 Fri 21:01]--[2017-02-24 Fri 22:55] =>  1:54
    CLOCK: [2017-02-24 Fri 10:34]--[2017-02-24 Fri 12:39] =>  2:05
    CLOCK: [2017-02-24 Fri 09:01]--[2017-02-24 Fri 10:33] =>  1:32
    CLOCK: [2017-02-23 Thu 23:06]--[2017-02-23 Thu 23:39] =>  0:33
    CLOCK: [2017-02-23 Thu 19:15]--[2017-02-23 Thu 23:05] =>  3:50
    CLOCK: [2017-02-14 Tue 06:33]--[2017-02-14 Tue 07:30] =>  0:57
    CLOCK: [2017-02-13 Mon 20:25]--[2017-02-13 Mon 22:33] =>  2:08

Now we are using Dogen in anger with ODB, we need to make sure the
database model is actually exercising all of this functionality. One
easy way of achieving this is to use Microsoft's Northwind Database as
the base for the model.

- [[https://northwinddatabase.codeplex.com/][Northwind Database]]

We should implement it using Oracle and use this to test the changes
to ODB's oracle support.

Tasks:

- add comment for ODB targets
- add flag to mark a type as a value
- case of the identifiers is a problem: sometimes we get them
  uppercase (when we do them without quotes in sql plus) sometimes we
  get them lowercase (from odb). use =--sql-name-case= upper/lower as
  a flag.
- schema initialisation from statics is not working; this is as
  explained in [[http://www.codesynthesis.com/pipermail/odb-users/2013-May/001286.html][this email]]. We can force it by doing a query on that
  entity, but that then causes an exception.
- =head -n 200 northwind_ascii.sql | grep ^INSERT | cut -b 1-150 | uniq=

*** Add a top-level "Visual Studio" knob                              :story:

We have a number of features that only make sense when on Windows and
building for Visual Studio. We should have a top-level knob that
enables or disables all of these features in one go:

- =quilt.cpp.visual_studio.enabled=

*** Add =targetver.h= support                                         :story:

On windows we should be generating the targetver header.

Links:

- [[https://github.com/Microsoft/Windows-classic-samples/blob/master/Samples/RadialController/cpp/targetver.h][targetver.h]]

*** Add support for Visual Studio C++ projects                        :story:

Visual studio project needs the files to be listed by hand. We can
either generate the project or the user has to manually add the
files. This is a problem every time they change. Requirements:

- we need to be able to support multiple VS versions as well (user
  configurable)
- user may want to import property sheets
- need guids (as per C# projects)
- need additional library/include directories
- need to add pre-compiled headers support with /FI.
- add a solution for good measure, using the C# code.
- add filter files for headers and source files.

As per ODB, users may also want to build with different versions of
VS. We should allow generating more than one solution and postfix them
with the VS version.

We should also generate filters for the project:

- header files
- source files
- ODB header files
- ODB source files

The inclusion of ODB files must be done using regular expressions
because we do not want to have to do two passes for knit; so we don't
really know what files are available. However, if the ODB files have a
=cxx= extension, we can just =CLInclude= =*cxx=.

Links:

- [[https://msdn.microsoft.com/en-us/library/2208a1f2.aspx][Project Files]]

*** Add support for pre-compiled headers on windows                   :story:

Most VS users have pre-compiled headers. We need to generate
=stdafx.h= etc. For now we can have it minimally populated until we
understand better the requirements.

Actually we could probably do a very simple computation in quilt to
figure out the most frequently used headers and add those to
=stdafx=. We just need to go through the entire model in the inclusion
expander to perform this calculation.

In addition we need to make sure =stdafx= is added as the first
include.

We should have a quilt setting for pre-compilation. We should also
check that visual studio support is enabled in order to generate
=stdafx=.

*** Add support for DLL Main on windows                               :story:

At present we are manually generating DLL Main by hand and then
excluding it on regexes. This is not ideal and will be more of a
problem when we generate project files. Ideally we should code
generate it. Requirements:

- user must be able to disable it;
- user must be able to handcraft it in case they want different
  contents;

Links:

- [[https://msdn.microsoft.com/en-us/library/aa370448(v%3Dvs.85).aspx][DLL Main]]

*** Add C++-03 mode                                                    :epic:

#+begin_quote
*Story*: As a dogen user, I want to create models in C++ 03 so that I
can interface with legacy code.
#+end_quote

It shouldn't be too hard to generate C++-03 code in addition to
C++-14. We could follow the gcc/odb convention and have a =-std=
option for this in meta-data. The only problem would be testing - at
present the language settings comes from cmake, and we'd have to make
sure the compiler is not in C++-14 mode when compiling test models
in 03. Also, the mixing and matching of 03 with 14 may not be
trivial. We should wait for a use case.

It may be possible to add different flags to different projects in CMake.

Tasks:

- default ctors, final, noexcept. Need to manually add default
  ctor (e.g. force it).
- enums
- need to disable ODB c++ 11 as well.

*** Use =cxx= extension with ODB files                                :story:

At present we renamed the ODB extension to =.cpp=. This is to make the
ODB files part of the project:

: set(files "")
: file(GLOB_RECURSE files RELATIVE
:    "${CMAKE_CURRENT_SOURCE_DIR}/"
:    "${CMAKE_CURRENT_SOURCE_DIR}/*.cpp")

However, it's quite nice to have distinct extensions for ODB and Dogen
files. We should add a conditional in CMake that detects ODB and if
found adds:

: set(odb_files "")
: file(GLOB_RECURSE odb_files RELATIVE
:    "${CMAKE_CURRENT_SOURCE_DIR}/"
:    "${CMAKE_CURRENT_SOURCE_DIR}/*.cxx")
: set(files ${files} ${odb_files})

*** Add option to capitalise column and table names                   :story:

One very useful thing is to allow users to define types in camel case
or underscore separated but then have the ODB names generated all in
caps (schema name, table name, column name). The database we are
currently working with is all in caps and we are forced to manually
enter pragmas for every single type because of this. Instead, we
should have some meta-data:

: odb.use_capitals=true

This would automatically generate the pragmas.

One slight downside is that if a user then tries to manually override
the pragmas, we will have duplicates, in effect:

: #DOGEN odb_pragma=schema("northwind")
: #DOGEN odb_pragma=schema("NORTHWIND")

*** Add prefetch support to ODB                                       :story:

As per Boris email:

#+begin_quote
Hm, I am not sure the bulk approach (with a compiler-time pragma) is
right in this case. There we don't really have a choice since we need
to know the "batch buffer" size.

But here it is all runtime. Plus, you may want to have different
prefetch for different queries of the same object. In fact, you
can already customize it for queries (but not for object loads)
by using prepared queries (Section 4.5 in the manual):

1. Create prepared query.

2. Get its statement (statement()).

3. Cast it to odb::oracle::select_statement.

4. Call handle() on the result to get OCIStmt*.

5. Set custom OCI_ATTR_PREFETCH_ROWS.

6. Execute the query.

The problems with this approach are: (1) it is tedious and (2) it
doesn't work for non-query SELECT's (e.g., database::load()). So
perhaps the way to do it is:

1. Provide prefetch() functions on oracle::database() and
   oracle::connection() that can be used to modify database-wide
   and connection-wide prefetch values. Also set it to some
   reasonable default (say 512?)

2. Provide oracle::select_statement::prefetch() to make the
   prepared query approach less tedious.
#+end_quote

*** Replace the database model with the northwind model               :story:

As part of the [[https://github.com/DomainDrivenConsulting/zango][zango]] project we are creating a model that exercises
Dogen and ODB. It is largely based on the database model, minus the
basic types we had added a while ago. We should just drop the database
model and adopt the northwind model from zango.

*** Add ODB to the build machine                                      :story:

At present we are only compiling and running the ODB tests
locally. Now that ODB is becoming a core dependency, we need to make
sure we are running these tests on the build machines - Windows and
Linux at least.

*** Rename ODB parameters                                             :story:

At present we use the following form:

: #DOGEN ODB_PRAGMA=no_id

We need to use the new naming style =cpp.odb.pragma=. We also need to
rename the opaque_parameters to reflect ODB specific data.

*** Map upsilon primitives to intrinsics                              :story:

Upsilon allows users to create "strong typedefs" around primitve
types. We need to unpack these into their intrinsic counterparts and
them map the intrinsics to native types.

Slight mistake: we mapped the primitive types themselves but in
reality what needs to be mapped are the fields making references to
the primitive types. We should just filter out all primitives.

Additional wrinkle: what the end users want is to unpack "real
primitives" into intrinsics, but "other" primitives should be mapped
to objects. This can be achieved by hard-coding =Plaform= primitives
into the mapping layer. However, some non-platform primitives may also
be candidates too. We need to create a list of these to see how
widespread the problem is.

Another alternative is to apply hard-coded regexes:

- if the name matches any of the intrinsic names

Finally, the last option may be to have yet another mapping data file
format that lists the primitives to unbox.

*** Immutable types cannot be owned by mutable types                  :story:

When we try to create a mutable class that has a property of an
immutable type, the code fails to compile due to the swap
method. This is because immutable types do not provide swap.

*** "Assistant" type found in test model                              :story:

We seem to be generating an "Assistant" type on the =primitve= test model:

: 2017-02-01 10:28:44.513705 [DEBUG] [quilt.cpp.formattables.helper_expander] Procesing element: <dogen><test_models><primitive><Assistant>

Figure out what this type is and why its appearing on this test model.

*** Add mapping support between upsilon and LAM                       :story:

At present we map upsilon directly to a language-specific model
(C++/C#), which gets code-generated. However, from a tailor
perspective, this is not ideal; we would end up with N different
models. Ideally, we should get a LAM representation of the JSON model
which could then be used to code-generate multiple languages.

This is probably not too hard, given the mapper knows how to convert
between upsilon and LAM. We just need to finish LAM support and then
try mapping them and see what breaks. Tailor would have to somehow
tell yarn to set the output language to LAM.

Notes:

- if output is more than one language, change it to LAM. Otherwise
  leave it as language specific.
- we need to inject via meta-data the annotations for the output
  languages.
- We only need to perform mapping if input language is upsilon. For
  all other languages we can leave it as is. But for upsilon, tailor
  needs to do a full intermediate model workflow.
- unparsed type needs to be recomputed as part of mapping.
- we are not adding the LAM mapping to the upsilon id container.
- we need to add support for "default mappings"

*** Make the Zeta model compilable                                    :story:

We need to work through the list of issues with the Zeta model and get
it to a compilable state.

*** Add support for Language Agnostic Models (LAM)                    :story:

Tasks:

- create the basic LAM types and add mapping for both C# and C++.
- create a LAM test model which tests that the mapping for all types
  generates compilable code.

LAM type map:

| Type                            | C++                              | C#                                                | Upsilon              |
|---------------------------------+----------------------------------+---------------------------------------------------+----------------------|
| lam::byte                       | unsigned char                    | uchar                                             |                      |
| lam::character                  | char                             | char                                              |                      |
| lam::integer8                   | std::int8_t                      | sbyte                                             |                      |
| lam::integer16                  | std::int16_t                     | System.Int16                                      |                      |
| lam::integer32                  | std::int32_t                     | System.Int32                                      |                      |
| lam::integer64                  | std::int64_t                     | System.Int64                                      | Integer64            |
| lam::integer                    | int                              | int                                               |                      |
| lam::single_floating            | float                            | float                                             |                      |
| lam::double_floating            | double                           | double                                            | Double               |
| lam::boolean                    | bool                             | bool                                              | Boolean              |
| lam::string                     | std::string                      | string                                            | String, Binary, Guid |
| lam::date                       | boost::gregorian::date           | System.DateTime                                   | Date                 |
| lam::time                       | boost::posix_time::time_duration | System.TimeSpan                                   | UtcTime              |
| lam::date_time                  | boost::posix_time::ptime         | System.DateTime                                   | UtcDateTime          |
| lam::decimal                    | std::decimal                     | System.Decimal                                    | Decimal              |
| lam::dynamic_array<T>           | std::vector<T>                   | System.Collections.Generic.List<T>                | Collection           |
| lam::static_array<T>            | std::array<T>                    | System.Collections.Generic.Array<T>               |                      |
| lam::unordered_dictionary<K, V> | std::unordered_map<K, V>         | System.Collections.Generic.Dictionary<K, V>       |                      |
| lam::ordered_dictionary<K, V>   | std::map<K, V>                   | System.Collections.Generic.SortedDictionary<K, V> |                      |
| lam::unordered_set<K>           | std::unordered_set<K>            | System.Collections.Generic.HashSet<T>             |                      |
| lam::ordered_set<K>             | std::set<K>                      | System.Collections.Generic.SortedSet<T>           |                      |
| lam::queue<T>                   | std::queue<T>                    | System.Collections.Generic.Queue<T>               |                      |
| lam::stack<T>                   | std::stack<T>                    | System.Collections.Generic.Stack<T>               |                      |
| lam::linked_list<T>             | std::list<T>                     | System.Collections.Generic.LinkedList<T>          |                      |
| lam::pointer<T>                 | boost::shared_ptr<T>             | <erase>                                           |                      |

*Previous Understanding*

When we start supporting more than one language, one interesting
feature would be to be able to define a model once and have it
generated for all supported languages. This would be achieved by
having a system model (or set of system models) that define all the
key types in a language agnostic manner. For example:

: lam::string
: lam::int
: lam::int16

Each of these types then has a set of meta-data fields that map them
to a type in a supported language:

: lam:string: cpp.concrete_type_mapping = std::string
: lam:string: csharp.concrete_type_mapping = string

And so on. We load the user model that makes use of LAM, we generate
the merged model still with LAM types and then we perform a
translation for each of the supported and enabled languages: for every
LAM type, we replace all its references with the corresponding
concrete type. We need to split the supplied mapping into a QName, use
the QName to load the system models for that language, look up the
type and replace it. After the translation no LAM types are left. We
end up with N yarn merged models where N is the number of supported and
enabled languages.

Each of these models is then sent down to code generation. This should
be equivalent to manually generating models per language - we could
use this as a test.

Once we have LAM, it would be great to be able to exchange data
between languages. This could be done as follows:

- XML: create a "LAM" XML schema, and a set of formatters that read
  and write from it. This is kind of like reverse mapping the types
  back to LAM types when writing the XML.
- JSON: similar approach to XML, minus the schema.
- POF: use the coherence libraries to dump the models into POF.

Tasks:

- create the LAM model with a set of basic types.
- add a set of mapping fields into yarn: =yarn.mapping.csharp=, etc
  and populate the types with entries for each supported language.
- create a notion of mapping of intermediate models into
  languages. The input is the merged intermediate model and the output
  is N models one per language. We also need a way to associate
  backends with languages. Each model is sent down to its backend.
- note that reverse mapping is possible: we should be able to
  associate a type on a given language with it's lam type. This means
  that, given a model in say C#, we could reconstruct a yarn lam model
  (or tell the user about the list of failures to map). This should be
  logged as a separate story.

Links:

- [[http://stackoverflow.com/questions/741054/mapping-between-stl-c-and-c-sharp-containers][Mapping between stl C++ and C# containers]]
- [[http://stackoverflow.com/questions/3659044/comparison-of-c-stl-collections-and-c-sharp-collections][Comparison of C++ STL collections and C# collections?]]

*** Tidy-up "is floating point"                                       :story:

We should introduce "point type" enumeration to replace "is floating
point":

- none
- floating
- fixed
- exact

*** Enumerations coming out of Upsilon are empty                      :story:

We don't seem to be translating the enumerators into yarn
enumerators.

*** Add support for nullable built-ins and primitives                 :story:

One useful feature in C# is the ability to add nullable types:

: Nullable<int>
: ?

This is particularly useful for built-in types, although its also
applicable to value types. For primitives this is slightly more
straightforward and we can make it a property of the meta-type (since
the whole point is that users define new primitives for each domain
type). For built-ins its slightly more tricky because its a property
of the attribute. We'd have to extend:

- the name tree to add a "is nullable" to each name tree
- the parser to read nullable and do the right thing
- LAM, to suport some kind of =lam::nullable= which in C++ translates
  to =boost::optional= and C# =Nullable=. Interestingly enough we can
  create a "Nullable type" in the global namespace.

*** Add case conversion support                                       :story:

When we map a LAM model into C#, it will have whatever case we used
originally. This is not ideal as in C++ we'd like to use underscores
instead. It would be nice if there was an "identifier converter" that
went through the model and updated all identifiers from underscores to
camel case. This includes classes, attributes, enumerators, etc. The
LAM model would remain with underscores.

For this to work correctly we'd need some kind of "casing" enumeration
associated with the model, and then another one associated with each
language. This means that if the model is already in camel case, we
would just generate camel case for both C++ and C#.

*** Consider renaming LAM to a sewing term                            :story:

In keeping with the rest of Dogen we should also use a sewing term for
LAM. Wool is an interesting one.

*** Windows package has element mappings                              :story:

For some reason even after renaming the mappings file it is still on
windows. This could also be a bug of the installer; after a uninstall
and reinstall the problem went away. Double check with a clean
install.

*** Comments in C# appear to be the attribute name                    :story:

It seems we are copying across the attribute name rather than a
comment. This could also be a problem with the input. Check the Zeta
model.

*** Add support for generic container types to C#                     :story:

We should add all major container types and tests for them.

: IEnumerable<T>
: ICollection<T>
: IList<T>
: IDictionary<K, V>
: List<T>
: ConcurrentQueue<T>, ConcurrentStack<T>, LinkedList<T>
: Dictionary<TKey,âTValue>
: SortedList<TKey,âTValue>
: ConcurrentDictionary<TKey,âTValue>
: KeyedCollection<TKey,âTItem>

Notes:

- we need a way to determine if we are using a helper, the assistant
  or a sequence generator directly.

*** Allow users to choose mapping sets                                :story:

At present we load the "default" mappings, which are also the only
mappings available. It is entirely possible that users will not agree
with those mappings. If we add a name to the mappings, and provide a
meta-data tag to choose mappings we can then allow users to provide
their own and set the meta-data accordingly. Mapper then reads the
meta-data in the model and uses the requested element map. For this we
need to name the element maps and we also need to create a "mapping
set". These can be indexed by name in the mapping repository. Mapper
chooses the mapping set to use.

*** Allow users to override mapping sets at the element level         :story:

Sometimes we may want to use a different mapping just for a particular
element. For example, by default =lam::linked_list= binds to
=std::list= for C++; once Dogen supports =std::forward_list=, one may
want to override this for a partial number of elements. It would be
nice if one could have a meta-data tag at the attribute level that
would override the mapping. The one slight wrinkle is that we would
not be able to supply a breakdown of:

- simple name
- model name
- internal modules

and so forth. So this may cause issues for resolution. We'd have to
test it and see what breaks. If this fails, the alternative is that
the mapping is by id, and we'd resolve it internally using the mapping
container, e.g.:

- create a map of names for each language by id
- user supplies the id for a given language, we look it up and
  retrieve the name.

*** Add support for command line meta-data parameters                 :story:

We do not want to force end users to change their existing file
format. However, it is sometimes necessary to supply parameters into
dogen which are not representable in the existing format. We could
create a very simple extension to the command line arguments that
would generate scribbles; these would then be appended to the model
during the yarn workflow. Example:

: --kvp a=b

or:

: --meta-data a=b

*** Do not generate upsilon proxy models                              :story:

At present we are marking all types in an upsilon config as target. In
practice, only one of the models is the target.

*** Load system models based on language prefix                       :story:

We used a convention for system models that have the language as a
prefix:

: cpp.boost.json
: cpp.builtins.json
: cpp.std.json
: csharp.builtins.json
: csharp.system.collections.generic.json
: csharp.system.collections.json
: upsilon.builtins.json

Coincidentally, this could make life easier when it comes to filtering
models by language: we could pattern match the file name depending on
the language and only load those who match. The convention would then
become a rule for system models. With this we would not have to load
the models, process annotations, etc just to get access to the
language.

*** Add support for ignoring types                                    :story:

#+begin_quote
*Story*: As a dogen user, I want to ignore certain types I am working
on so that I can evolve my diagram over time, whilst still being able
to commit it.
#+end_quote

Sometimes when changing a diagram it may be useful to set some types
to "ignore", i.e. make dogen pretend they don't exist at all. For
instance one may want to introduce new types one at a time. It would
be nice to have a dynamic extension flag for ignoring.

We should probably have some kind of warning to ensure users are aware
of the types being ignored.

*** Add auxiliary function properties to c#                           :story:

We need to associate a function with an attribute and a
formatter. This could be the helper or the assistant (or nothing).

Actually this is not quite so straightforward. In =io= (c#) we have:

: assistant.Add("ByteProperty", value.ByteProperty, true/*withSeparator*/);

This is a bit of a problem because we now need to different
invocations, one for helper another for the assistant, which differ on
the function prototype. For the helper we need something like:

: Add(assistant, "ByteProperty", value.ByteProperty, true/*withSeparator*/);

So a string is no longer sufficient. Maybe we could have a struct with
auxiliary function properties:

- auxiliary function types = enum with { assistant, helper }
- auxiliary function name = string

So we can have a map of attribute id to map of formatter id to
auxiliary function properties.

Actually we should also create "attribute properties" as a top-level
container so that in the future we can latch on other attribute level
properties.

*** Add internal object dumper resolution                             :story:

We should try to resolve an object to a local dumper, if one exists;
for all model types and primitives. Add a registrar for local dumpers.

: using System;
: using System.Collections.Generic;
:
: namespace Dogen.TestModels.CSharpModel
: {
:     static public class DynamicDumperRegistrar
:     {
:         public interface IDynamicDumper
:         {
:             void Dump(AssistantDumper assistant, object value);
:         }
:
:         static private IDictionary<Type, IDynamicDumper> _dumpers = new Dictionary<Type, IDynamicDumper>();
:
:         static void RegisterDumper(Type type, IDynamicDumper dumper)
:         {
:         }
:     }
: }

*** Fix issues with bintray windows uploads                           :story:

At present we are doing a lot of hacks for windows:

- hardcoding the path to the package
- not uploading on just tags
- uploading to the top-level folder instead of the version.

Ideally we want to reuse the Travis BinTray descriptor but AppVeyor
does not support this directly.

*** Model references are not transitive                               :story:

For some reason we do not seem to be following references of
referenced models. We should load them automatically, now that they
are part of the meta-data. However, the =yarn.json= model breaks when
we remove the reference to annotation even though it does not use this
model directly and =yarn= is referencing it correctly.

*** Add support for boxed types                                       :story:

At present we support built-in types such as =int= but not
=System.Integer=. In theory we should be able to add these types with:

:        "quilt.csharp.assistant.requires_assistance": true,
:        "quilt.csharp.assistant.method_postfix": "ShortByte"

And they should behave just like built-ins.

*** Add handcrafted class to C# test model                            :story:

We should make sure handcrafted code works in C#.

Actually in order to get handcrafted types to work we need support for
enablement. This is a somewhat tricky feature so we should leave it
for after all the main ones are done.

*** Add support for arrays                                            :story:

At present the yarn parser does not support array notation:
=string[]=. We need to look into how arrays would work for C++ and
implement it in a compatible way.

Links:

- [[https://www.dotnetperls.com/array][array]]

*** Add fluency support for C#                                        :story:

We need to add fluent support for C#.

C# properties are not compatible with the fluent pattern. Instead, one
needs to create builders, across the inheritance tree.

Links:

- [[http://stackoverflow.com/questions/13761666/how-to-use-fluent-style-syntactic-sugar-with-c-sharp-property-declaration][How to use Fluent style syntactic sugar with c# property declaration]]

*** Add visitor support to C#                                         :story:

Implement the visitor formatters for C#.

*** Benchmarks do not work for utility tests                          :story:

When we run the benchmarks for utility we get an error:

: Running 95 test cases...
: /home/marco/Development/DomainDrivenConsulting/dogen/projects/utility/tests/asserter_tests.cpp(141): error: in "asserter_tests/assert_directory_good_data_set_returns_true": check asserter::assert_directory(e, a) has failed

Seems like the tests do not clean up after themselves. We need to add
some clean up logic and re-enable the tests.

*** Add cross-model support to C#                                     :story:

At present we do not have any tests that prove that cross-model
support is working (other than proxy models). We need to create a user
level model that makes use of types from another model. In theory it
should just work since we are using fully qualified names everywhere.

*** Generate AssemblyInfo in C#                                       :story:

We need to inject a type for this in fabric. For now we can leave it
mainly blank but in the future we need to have meta-data in yarn for
all of its properties:

: [assembly: AssemblyTitle ("TestDogen")]
: [assembly: AssemblyDescription ("")]
: [assembly: AssemblyConfiguration ("")]
: [assembly: AssemblyCompany ("")]
: [assembly: AssemblyProduct ("")]
: [assembly: AssemblyCopyright ("marco")]
: [assembly: AssemblyTrademark ("")]
: [assembly: AssemblyCulture ("")]
: [assembly: AssemblyVersion ("1.0.*")]

These appear to just be properties at the model level.

*** Consider adding a clone method for C#                             :story:

It would be nice to have a way to clone a object graph. We probably
have an equivalent story for this for C++ in the backlog.

*** Consider making the output directory configurable in C#           :story:

At present we are outputting binaries into the =bin= directory,
locally on the project directory. However, it would make more sense to
output to =build/output= like C++ does. For this to work, we need to
be able to supply an output directory as meta-data.

*** Add support for nuget                                             :story:

A proxy model may require obtaining a nuget package. Users should be
able to define a proxy model as requiring a nuget package and then
Dogen should generate packages.config and add all such models to it.

: +  <package id="NUnit" version="2.6.4" targetFramework="net45" />

*** Augment element ID with meta-model type                           :story:

The element ID is considered to be a system-level, opaque
identifier. It could, for all intents and purposes, be a large int. We
have decided to use a string so we can dump it to the log and figure
out what is going on without having to map IDs to a human-readable
value. In the same vein, we could also add another component to the ID
that would contain the meta-model element for that ID. This
information could be placed at the start.

Of course, we will not be able to remove the look-ups we have at
present that try to figure out the meta-model element because they are
related to resolution. But for any other cases it may result in
slightly more performant code. We need to look at all the use cases.

*** Identifiable needs to use camel case in C#                        :story:

At present we are building identifiables with underscores.

*** Generate windows packages with CPack                              :story:

We tried to generate windows packages by using the NSIS tool, but
there are no binaries available for it at present. However, it seems
CPack can now generate MSIs directly:

- [[http://stackoverflow.com/questions/18437356/how-to-generate-msi-installer-with-cmake][How to generate .msi installer with cmake?]]
- [[https://cmake.org/cmake/help/v3.0/module/CPackWIX.html][CPackWIX]]

We need to investigate how to get the build to produce MSIs using WIX.

*** Move enablement into quilt                                        :story:

We need to make use of the exact same logic as implemented in
=quilt.cpp= for enablement. Perhaps all of the enablement related
functionality can be lifted and grafted onto quilt without any major
changes.

*** Add feature to disable regions                                    :story:

We need a way to stop outputting regions if the user does not want
them.

*** Add parameters for using imported assemblies                      :story:

Assemblies imported via proxy models need to have the ability to
supply two parameters:

- assembly name: this is not always the same as the proxy model name;
- root namespace: similarly this may differ from the proxy model name.

These should be supplied as meta data and used when constructing
fabric types.

*** Add msbuild target for C# test model                              :story:

Once we are generating solutions, we should detect msbuild (or xbuild)
and build the solution. This should be a CMake target that runs on
Travis.

*** Add visibility to yarn elements                                   :story:

We need to be able to mark yarn types as:

- public
- internal

This can then be used by C++ as well for visibility etc.

*** Add partial element support to yarn                               :story:

We need to be able to mark yarn elements as "partial". It is then up
to programming languages to map this to a language feature. At present
only [[https://msdn.microsoft.com/en-us/library/wa80x488.aspx][C# would do so]].

It would be nice to have a more meaningful name at yarn
level. However, seems like this is a fairly general programming
concept now: [[https://en.wikipedia.org/wiki/Class_(computer_programming)#Partial][wikipedia]].

*** Add visibility to yarn attributes                                 :story:

We need to be able to mark yarn attributes as:

- public
- private
- protected

*** Add final support in C#                                           :story:

Links:

- [[https://msdn.microsoft.com/en-us/library/88c54tsw.aspx][sealed (C# Reference)]]

*** Add aspects for C# serialisation support                          :story:

We need to add serialisation support:

- C# serialisation
- Data Contract serialisation
- Json serialisation

In C# these are done via attributes so we do not need additional
facets. We will need a lot of configuration knobs though:

- ability to switch a serialisation method on at model level or
  element level.
- support for serialisation specific arguments such as parameters for
  Json.Net.

Links:

- [[https://msdn.microsoft.com/en-us/library/ms731923(v%3Dvs.110).aspx][Types Supported by the Data Contract Serializer]]
- [[https://msdn.microsoft.com/en-us/library/ms731073(v%3Dvs.110).aspx][Serialization and Deserialization]]
- [[https://msdn.microsoft.com/en-us/library/ms733127(v%3Dvs.110).aspx][Using Data Contracts]]
- [[https://msdn.microsoft.com/en-us/library/ms731923(v%3Dvs.110).aspx][Types Supported by the Data Contract Serializer]]

*** Consider adding =artefact_set= to formatters' model               :story:

We are using collections of artefacts quite a bit, and it makes sense
to create an abstraction for it such as a =artefact_set=. However, for
this to work properly we need to add at least one basic behaviour: the
ability to merge two artefact sets. Or else we will end up having to
unpack the artefacts, then merging them, then creating a new artefact
set.

Problem is, we either create the artefact set as a non-generatable
type - not ideal - or we create it as generatable and need to add this
as a free function. We need to wait until dogen has support for
merging code generation.

** Deprecated
