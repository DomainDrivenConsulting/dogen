#+title: Sprint Backlog 73
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) spike(p) }

* Mission Statement

- Continue the yarn refactors.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75
#+CAPTION: Clock summary at [2015-10-21 Wed 17:56]
| <75>                                                                        |        |      |      |
| Headline                                                                    | Time   |      |      |
|-----------------------------------------------------------------------------+--------+------+------|
| *Total time*                                                                | *0:05* |      |      |
|-----------------------------------------------------------------------------+--------+------+------|
| Stories                                                                     | 0:05   |      |      |
| Active                                                                      |        | 0:05 |      |
| STARTED Sprint and product backlog grooming                                 |        |      | 0:05 |
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2015-10-22 Thu 08:44]--[2015-10-22 Thu 08:50] =>  0:06
    CLOCK: [2015-10-21 Wed 17:51]--[2015-10-21 Wed 17:56] =>  0:05

Updates to sprint and product backlog.

*** STARTED Implement expander workflows                              :story:
    CLOCK: [2015-10-21 Wed 20:50]--[2015-10-21 Wed 21:38] =>  0:48

We need to move across code from the transformation models (dia, json)
into the expander code in yarn.

*** STARTED Rename nested qname to composite qname                    :story:
    CLOCK: [2015-10-22 Thu 08:10]--[2015-10-22 Thu 08:43] =>  0:33

*New understanding*:

This story requires further analysis. Blindly following the composite
pattern was tried but it resulted in a lot of inconsistencies because
we then had to follow MEC-33 and create =abstract_qname=; however, the
nested qname does not really behave like a composite qname; its more
like the difference between a type in isolation and a type
instantiated as an argument of a function. For example, whilst the
type in isolation may have unknown template parameters, presumably, as
an argument of a function these have been instantiated with real
types.

One way to solve this is just to make the type name a bit more
explicit rather than try to imply the composite pattern
(e.g. "nested"). We need a name that signifies "instantiated
type". Look at the C++ standard for the difference between defining a
generic type and instantiating a generic type.

No good names yet (type reference, type instantiation, instantiated
name). What are we trying to represent: an identifier which points to
a complete definition of a name such that the name can be instantiated
as a type in the underlying language. By "instantiated" we mean used
to define variables of this type. In this light: instantiable name,
definable name? If we choose instantiable name, we could then rename
"children" to type arguments.

*Previous understanding*:

We should just follow the composite pattern in the naming.

*** STARTED Update copyright notices                                  :story:

We need to update all notices to reflect personal ownership until DDC
was formed, and then ownership by DDC.

- first update to personal ownership has been done, but we need to
  test if multiple copyright entries is properly supported.

*** Copyright holders is scalar when it should be an array            :story:

At present its only possible to specify a single copyright holder. It
should be handled the same was as odb parameters, but because that is
done with a massive hack, we are not going to extend the hack to
copyright holders.

*** Refactor qname                                                    :story:

Split qname into name and location; location is made up of model name,
external module path, model path, internal module path.

Notes:

- populate model path as module name by default unless supplied by
  field.
- deal with the fallout in terms of file paths creation, etc.
- fix hardware model to supply model name but to have a blank model
  path.
- split model names with dots into multiple model paths.
- do not populate model path and qualified until resolution is done -
  these properties do not add any value. After resolution - perhaps
  as a last pass of the resolver - go through every single qname and
  compute these properties. This means that all calls to qualified
  prior to this need to be replaced to direct calls to qualified name
  builder.

More notes:

- within a partial model, there are two stages of processing: an
  initial pass in which we can identify all of the names of the
  elements declared in a model; and a second pass in which we can
  resolve all properties that belong to that model. By "resolve" we
  mean we can figure out if a property is referring to an element in a
  module inside the model or if its referring to an element in a
  different model. This can only be done when we have all the names of
  all the modules in the model.
- there is such a thing as a location: an object which allows one to
  figure out where a type is located in an imaginary "element
  space". In addition to the location, the element space has another
  dimension, given by the element "simple" name (from now on just
  name). The pair =(location, name)= corresponds to a unique point in
  the element space.
- there is such a thing as a unique element identifier: it is a string
  representation of the pair =(location, name)= according to a
  well-defined syntax.
- the pair =(location, name)= is an element identifier, because it
  uniquely identifies elements in the element space.
- the external module path is required to allow us to represent
  external containment; that is, cases where the model is contained in
  one or more namespaces, but we do not want to represent these inside
  the model.
- the internal module path is required to allow us to represent
  internal containment; that is, the element is contained in one or
  more modules, represented in the model.
- the model path represents containment inferred from the model name
  itself; that is, a composite model name such as =a.b.c=.
- the model name does not always contribute to the model path. For
  models such as hardware, the model has to have a name (it cannot be
  in a nameless file) but the types are in the global space. This
  means that we need to switch on/off the ability to have the model
  name contribute to the model namespace.
- model names are only relevant initially. We could store them in
  model class, but they will be thrown away during merging.
- references are used for several purposes: a) to determine that we
  have loaded all required models. b) to generate code dependencies
  against dependent models: at present just linking and registrar in
  serialisation. In order to figure out what to do with the reference
  we need to know its "kind". For dogen models, we need to generate
  registrars; for non-dogen models we do not. We always need to
  link. At present this is done via the origin types property. A
  better way of modeling this may be "is dogen model" or something
  along these lines.
- one model may have more than one set of link instructions. These are
  more related to the types than with the model itself. For example,
  in boost we need to link potentially against multiple
  libraries. This could be modeled by a dynamic property at the type
  level or model level. For dogen models it would be model level. The
  property may be empty (hardware, std).
- from a element identifier it is not possible to determine its model
  name. It may or may not be reconstructible from the model
  path. However, if one were to have a map of location to model name,
  one could at least figure out if the type is on any of the loaded
  models. We could keep track of all locations which are not within
  the model. Those must match the referenced models or else there is a
  type resolution failure.
- there is such a thing as a element instance identifier. We call it
  nested name at present. The element instance identifier identifies
  instantiations of types. It models two cases: for the case where the
  type has no type parameters, the instance identifier is equal to the
  element identifier; for all other cases, it is a hierarchical
  collection of element identifiers, modeling the type parameter
  structure.
- a model should have: an element identifier which is identical to the
  root module (the module that represents the model). A model is
  itself an element.

 a location; a name (meaning the original,
  possibly composite, model name); a

the
  types pace is hierarchical: its made up of the global namespace at
  the top (where types in the hardware model live), and then followed
  by all other namespaces "declared" at the top-level.
- there are four distinct cases of locations in the type space

Merged stories:

*Consider renaming qname*

As part of dynamic we came up with a better way of modeling names:
type is name, fields:

- simple
- qualified

This is a better way of modeling, as opposed to the SML way with a
=qname= which then contains a =simple_name=. We should use this
approach in SML to.

*Split model name from "contributing model name" in qname*

We need to find a way to model qnames such that there are two model
names: one which contributes to the namespaces and another which
doesn't. The specific use case is the primitives model where the model
has to have a name but we don't want the type names to have the model
name. Perhaps we need some kind of flag: model name contributes to
namespacing.

With this we can then remove the numerous hacks around the primitives
model name such as:

- // FIXME: mega hack to handle primitive model.

See comment in 'dot' story - we can have a model name and a model
package.

*** Refactor code around model origination                            :story:

- remove origin types and generation types, replacing it with just a
  boolean for is target.
- at present we are using origin type to determine whether to create a
  registrar, etc in cpp model. There is no other use case for
  this. This is done in several places due to the bad handling of C++
  specific types. Grep for =references= in =cpp= to find all
  locations.

*Previous Understanding*

In the past we added a number of knobs around generation, all with
their own problems:

- =origin_types=: was the model/type created by the user or the
  system. in reality this means did the model come from Dia or
  JSON. this is confusing as the user can also add JSON files (their
  own model library) and in the future the user can use JSON
  exclusively without needed Dia at all.

- =generation_types=: if the model is target, all types are to be
  generated /unless/ they are not properly supported, in which case
  they are to be "partially" generated (as is the case with
  services). This is a formatter decision and SML should not know
  anything about it.

These can be replaced by a single enumeration that indicates if the
type/model is target or not.

This work should be integrated with the model types story.

*** Remove primitive model handling in yarn dia transformer           :story:

We seem to be doing some handling for primitives which is no longer
required. The handling of current model is also very dodgy. All in
transformer's update model reference.

Actually this is nothing at all to do with the primitive model but all
to do with computing the correct name. We need to start using the
builder here.

*** Yarn refactor around partial model construction                   :story:

There are a number of activities done in the file importers which
really belong to the main meta-model. We should create a single
workflow for "post-processing" with these activities and move them
away from the importers.

Notes:

- add a module post processor that computes owner (containing
  module?), members, is top level. Seems like we already have a
  top-level module: containing module is null.
- add unparsed name to nested name. Update importers to read the
  unparsed name and not expand it. Create a "property expander" that
  parses the unparsed name and expands it to a proper nested
  name. Compute qualified for property types.
- reference expander to compute references.
- add some enumeration post-processing that assigns it a underlying
  type. Should be done with merged model (look for a primitive type with
  property =is_default_enumeration_type=).

*** Improve references management                                     :story:

At present, we compute model references as follows:

- in dia to sml we first loop through all types and figure out the
  distinct model names. This is done by creating a "shallow" qname
  with just the model name and setting its origin type to unknown.
- when we merge, we take the references of target - the only ones we
  care about - and then we check that against the list of the models
  we are about to merge. If there are any missing models we complain
  (see comments below). We then loop through the list of references
  and "resolve" the origin type of the model.

Note: We could actually also complain if there are too many models, or
more cleverly avoid merging those models which are not required. Or
even more cleverly, we could avoid loading them in the first place, if
only we could load target first.

A slightly better way of doing this would be:

- in SML create a references updater that takes a model and computes
  its reference requirements. It could also receive a list of "other"
  models from which to get their origin types to avoid using =unknown=
  at all, and checks that all reference requirements have been met.
- the current step =update_references= is just a call to the
  references updater, prior to merging, with the target model.

Note:

It seems that the references are incorrect at present; on rebuild, we
see serialisation's registrar moving for no reason:

: -    dogen::config::register_types(ar);
:      dogen::sml::register_types(ar);
: -    dogen::dynamic::schema::register_types(ar);
: +    dogen::config::register_types(ar);

The references have not changed at all in the dogen invocation:

:    --reference ${CMAKE_SOURCE_DIR}/diagrams/config.dia,dogen
:    --reference ${CMAKE_SOURCE_DIR}/diagrams/sml.dia,dogen
:    --reference ${CMAKE_SOURCE_DIR}/diagrams/formatters.dia,dogen
:    --reference ${CMAKE_SOURCE_DIR}/diagrams/schema.dia,dogen::dynamic

We need to fix this with the refactor.

*** Add =operator<= for names                                         :story:

We seem to redefine this all over the place. Create a utility class
somewhere.

*** Services and leaves are not properly handled                      :story:

We are manually ignoring services when calculating leaves.

*** Add support for model names with dots                             :story:

It is quite annoying to have to create folders and sub-folders for the
main projects. This is not too bad right now because we don't really
make use of nesting that much, other than with test models. However,
now that the architecture is clear and we need to make use of nesting,
it becomes more of a concern. For example:

: / a
:   / b
:   / c
: / d
:   / e
:   / f

This is clearer as:

: / a
: / a.b
: / a.c
: / d.e
: / d.f

However, in order to implement this we need a bit of cleverness:

- for the purposes of files, the dot represents a dot;
- for the purposes of namespaces, we must create several namespaces
  (e.g. yarn::core).

This is also inline with the idea that the model name does not always
contribute to the namespaces as required by primitives. We basically
need a cleverer version of qname to handle all of these scenarios.

It may also be worth taking into account the other story on this topic
where we considered using underscores instead of folders for facet
names. It may be nicer to have dots for this,
e.g. =types.my_class.hpp=.

Idea:

=qnames= should have a model name and a model package; only the model
package contributes to the namespaces. The model name is unpacked into
multiple model packages (e.g. "a.b" => a::b). The file name uses the
model name, not the model package.

*** Use dots in data files extensions                                 :story:

At the moment we use extensions such as =xmlyarn=. It should really be
=.xml.yarn= or something of the kind.

*** Refactor ownership hierarchy                                      :story:

Start implementing the archetype logic. Basically there is a artefact
unique identifier

- rename it to =artefact_descriptor=.
- remove all dia fields; these are now file importer specific and
  never reach dynamic.
- add =kernel= field. This is set to =stitch= or =quilt=.
- rename formatter field to =kind=

Merged stories:

*Consider adding "application" to ownership hierarchy*

Not all fields make sense to all tools in the dogen suite; some are
knit specific, some are stitch specific and some are shared. At
present this is not a problem because stitch loads up all of knit's
fields and assumes users won't make use of them. If they do, nothing
bad "should" happen. But a better way to solve this may be to only
load fields that belong to an application. We could add "application"
to ownership hierarchy, and filter on that. Note though that we would
need some way of saying "all applications" (e.g. at present, leave the
field blank).

*Consider renaming =ownership_hierarchy=*

We came up with the name =ownership_hierarchy= because we could not
think of anything else. However, it is not a particularly good name,
and it is increasingly so now that we need to use it across models. We
need a better name for this value type.

This work must be integrated with the [[https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_69.org#thoughts-on-cpp-refactoring][archetype work]].

*Split knitting from stitching settings*

*Rationale*: with "kernel" we will have quilt and stitch.

At present we only have a single common directory with all of the
available fields. Not all fields apply to both stitching and
knitting - but some do. We need a way to filter these. One possibility
is to use an approach similar to the formatter groups in the ownership
hierarchy. For now we simply have fields that have no meaning in
stitching but can be supplied by users.

*** Split formatter properties and associated classes from formattables :story:

We have two kinds of data: the formattables themselves (mapped from
yarn) and associated data (formatter properties). The latter is
totally independent. We should create a namespace for all of these
classes and a workflow that produces the data ready for consumption. A
tentative name is =manifest=.

*** Consider renaming includers                                       :story:

Its very confusing to have header files that include lots of other
header files called "includers". There is too much overloading. We
should consider calling them "master header files" as per Schaling
terminology in the [[http://theboostcpplibraries.com/boost.spirit][boost book]].

*** Replace qname with id's in yarn                                   :story:

*New Understanding*

This is a new spin on that old chestnut of splitting partial models
from full models. We probably got enough to do this. The

*Previous Understanding*

We don't really need qname in it's current form for the purposes of
yarn. We should:

- create a base class for all types in model called element.
- add a property called id to element. Compute id on the basis of
  hashing name and location. Change all model containers,
  relationships etc to use id instead of qname.

*** Rename types in =yarn= using MOF/eCore terms                      :story:

Rename the types in =yarn= to make them a bit more inline with
MOF/eCore. As much as possible but without going overboard. Ensure we
do not pick up meta-meta-model concepts by mistake. Rename nested
qname to something more sensible from MOF/eCore. Review all concept
names in this light.

*** Add support for pulling dependencies from biicode                 :story:

[[https://www.biicode.com/][Biicode]] is a nuget-like repo for c++. We should look into both
consuming dependencies from it and pushing dogen into it. In addition
there are associated emblems:

https://github.com/Manu343726/snail

We should also look into [[https://www.biicode.com/biicode-open-source-challenge][the challenge]].

We should push both the C++ libraries as well as the dogen binary.

We should take the least intrusive possible approach to start with, by
creating a split setup for biicode.

*** Create a set of definitions for tagging and meta-data             :story:

We still use these terms frequently. We should define them in dynamic
to have specific meanings.

*** Models should have an associated language                          :epic:

#+begin_quote
*Story*: As a dogen user, I want to make sure I only use valid system
models so that I don't generate models that code generate but do not
compile.
#+end_quote

Certain models (e.g. system / library models) can only be used in a
give language; for example =boost= and =std= only make sense in C++. A
.Net library model would only make sense in .Net, etc. These are
Language Specific Models (LSM). Once a model depends on a LSM it
itself becomes an LSM and it should not be able to then make use of
models of other languages nor should one be able to request a code
generation for other languages.

However, one day we will have a system model which is a Language
Agnostic Model (LAM). The system model will provide a base set of
functionality across languages such as containers, and for each type
it will have mappings to language specific types. The mapping is
declared as dynamic extensions in the appropriate section
(i.e. =tags::cpp::mapped_type= or something of that ilk). If a model
depends only on LAMs, it is itself a LAM and can be used to generate
code on any supported language (presumably a supported language is
defined to be that for which we have both mappings and a code
generation backend).

A first step for this would be to have a language enumeration in SML
which is a property of the model, and one entry of which is "language
agnostic".

*** Set enumeration underlying type in SML                            :story:

In cpp transformer we have hacked the underlying type of the
enumeration. Remove this hack and set it in SML. Still a hack, but
a tad better.

Actually this could be the first case where LAM/PIM is used: we could
call this something like integer.

This is also hacked in yarn_dia's transformer.

*** Add support for Language Agnostic Models (LAM)                    :story:

When we start supporting more than one language, one interesting
feature would be to be able to define a model once and have it
generated for all supported languages. This would be achieved by
having a system model (or set of system models) that define all the
key types in a language agnostic manner. For example:

: lam::string
: lam::int
: lam::int16

Each of these types then has a set of meta-data fields that map them
to a type in a supported language:

: lam:string: cpp.concrete_type_mapping = std::string
: lam:string: csharp.concrete_type_mapping = string

And so on. We load the user model that makes use of LAM, we generate
the merged model still with LAM types and then we perform a
translation for each of the supported and enabled languages: for every
LAM type, we replace all its references with the corresponding
concrete type. We need to split the supplied mapping into a QName, use
the QName to load the system models for that language, look up the
type and replace it. After the translation no LAM types are left. We
end up with N SML merged models where N is the number of supported and
enabled languages.

Each of these models is then sent down to code generation. This should
be equivalent to manually generating models per language - we could
use this as a test.

Once we have LAM, it would be great to be able to exchange data
between languages. This could be done as follows:

- XML: create a "LAM" XML schema, and a set of formatters that read
  and write from it. This is kind of like reverse mapping the types
  back to LAM types when writing the XML.
- JSON: similar approach to XML, minus the schema.
- POF: use the coherence libraries to dump the models into POF.

FIXME: we believed this story was already backloged but could not find
it on a quick search. Do a more thorough search.

*** Thoughts on simplifying the formattables generation               :story:

We have a problem in the way which we are doing the formattables:
because we are doing model traversals for each of the factories, we
cannot easily introduce a set of manually generated qnames such as the
registrar and includers. However, if we started off the main workflow
by creating a structure like so:

- qname
- optional entity (new base class in SML); if null we need to create
  extensions as an empty object.

We then need a list of these that get passed in to all repository
factories. These use a visitor of entity to resolve to a type (where
required).

We can inject types to this list that have a qname but no entity. For
these we generate some parts of the formatter properties. Actually, we
still need to generate inclusion lists even when there is no
entity. Perhaps we need to create a new method in the provider that
does not take an SML entity but still generates the inclusion list.

Actually this should all be done in SML. We should have zero qname
look-ups coming out of SML, just follow references. This story is a
variation of the split between "partial" models and "full" models.

Well not everything should be done in SML. We still need to create a
structure with the properties above, but that is done by iterating
through a list in the SML model.

One slight problem with this approach: sometimes we need to preserve
some relationships in the newly generated objects. For registrar we
need to preserve the model leaves. For the includers / master headers
we need to express somehow the inclusion relationship at the formatter
level. The latter is definitely a special case because it is a pure
C++ concept: include files cannot be modeled in SML. However,
registrar is slightly different because we still need to compute the
includes based on the leaves. This means that the above approach will
not provide a clean solution, unless we synthesise an SML object when
providing the includes. And of course we need to be careful taking
that route or else we will end up generating the object across all
facets.

*** Consider reducing the number of qname lookups in cpp model        :story:

At present we are using qnames all over the place in CPP. Nothing
stops us from using strings instead of qnames if that is more
efficient.

What is worse is that we seem to be doing a ridiculous amount of qname
lookups. It would be much nicer if we could somehow have all the data
in the right shape to avoid doing so many lookups.

This should be done as part of the move to =yarn=.

*** Handling of managed directories is incorrect                      :story:

At present we are querying the yarn dia importer to figure out what
the managed directories are. These are basically the top-level
directories from where we want the housekeeper to operate. In reality
this is (or can be placed) in the meta-data. We should be able to
extract the managed directories from the meta-data as a step in one of
the workflows.

This can be done by the backend. It does mean that we should be
returning a composite type from generation:

- list of files;
- list of managed directories.

Alternatively we could have a =managed_directories= method that takes
in an SML model and then internally reads in the meta-data for a given
model to produce the list.

*Merged with previous story*

Compute managed directories from knitting options

At present the backend is returning empty managed directories. This
means housekeeping will fail in the new world. We need to change the
interface of this method to take in the knitting options and return
the managed directories.

This is not entirely trivial. At present the managed directories are
computed in the locator. It takes into account split project, etc to
come up with all the directories used by the backend. We need to make
these decisions during path expansion, expect we only need manged
directories for the root object. However we do not know which object
is the root object at present, during the expansion. We could identify
it via the QName and the SML model in context thought. We could then
populate the managed directories as a text collection. We then need
some settings and a factory to pull out the managed directories from
the root object. This could be done in =managed_directories=, by
having an SML model as input.

*** Add include providers for all types                               :story:

We need to implement the provider container support for primitives,
modules and concepts.

Update:

- inclusion dependencies factory
- provider container

*** Implement all formatter interfaces                                :story:

We still have a couple of skeleton interfaces:

- primitve
- concepts

*** Do not compute inclusion directives for system models             :story:

It seems we are computing inclusion directives and other path
derivatives for system models:

: {
:   "__type__": "dogen::cpp::expansion::path_derivatives",
:   "file_path": "/home/marco/Development/DomainDrivenConsulting/output/dogen/clang-3.5/stage/bin/../test_data/all_primitives/actual/std/include/std/serialization/unique_ptr_fwd_ser.hpp",
:   "header_guard": "STD_SERIALIZATION_UNIQUE_PTR_FWD_SER_HPP",
:   "inclusion_directive": "<quote>std/serialization/unique_ptr_fwd_ser.hpp<quote>"
: }

This comes out of the workflow, so we possibly are then ignoring it
for the non-target types. So:

- can we avoid computing these altogether?
- are we ignoring it?

Actually this is the usual problem with the "origin" of the type. We
need a way to determine if this type needs computations or not. We
need to create a story to clean up the =origin_type= and
=generation_type= and then we can make use of it to determine if we
need to compute inclusion, path etc or not.

*** Header guard in formatters should be optional                     :story:

At present we are relying on empty header guards to determine what to
do in boilerplate. We should use boost optional.

*** Remove complete name and use qualified name                       :story:

At present we have both complete name and qualified name in
formatables. Qualified name is blank. We should remove complete name
and populate qualified name.

This is in nested type info.

*** Consider renaming registrar in boost serialisation                :story:

At present we have a registrar formatter that does the boost
serialisation work. However, the name =registrar= is a bit too
generic; we may for example add formatters for static registrars. We
should rename this formatter to something more meaningful. Also the
name registrar is already well understood to mean static registrar.

This is a big problem now that we cannot add a type with the name
registrar to the main model as it clashes with the serialisation
registrar.

We could simply name it serialisation registrar or some such name that
is very unlikely to clash. We should then have a validation rule that
stops users from defining types with that name.

We need to go through all of the renamed registrars and fix them.

*** Create more "utility" members in class info                       :story:

One way of making the templates a bit more manageable is to avoid
having really complex conditions. We could simplify these by giving
them intelligible names and making them properties of the
formattables - mainly class info as that's where the complexity seems
to stem from. For example:

: if ((!c.all_properties().empty() || c.is_parent()) && !c.is_immutable()) {

could be replaced with =has_swap=, or perhaps even =has_public_swap= /
=has_protected_swap=.

*** Consider renaming module path to internal module path             :story:

Since we have got a external module path, it would make sense for the
other to be the internal module path. This may be taking the symmetry
too far, so we need to have a think.

** Deprecated
