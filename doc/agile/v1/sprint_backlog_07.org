#+title: Sprint Backlog 07
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Finish moving file locator and dependencies into yarn.
- Start sorting out object templates and profiles.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2017-11-09 Thu 20:11]
| <75>                                                                        |        |      |      |       |
| Headline                                                                    | Time   |      |      |     % |
|-----------------------------------------------------------------------------+--------+------+------+-------|
| *Total time*                                                                | *3:58* |      |      | 100.0 |
|-----------------------------------------------------------------------------+--------+------+------+-------|
| Stories                                                                     | 3:58   |      |      | 100.0 |
| Active                                                                      |        | 3:58 |      | 100.0 |
| COMPLETED Edit release notes for previous sprint                            |        |      | 1:03 |  26.5 |
| COMPLETED Remove remnants of upsilon                                        |        |      | 0:35 |  14.7 |
| STARTED Remove yarn element types in dia frontend                           |        |      | 2:20 |  58.8 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2017-11-06 Mon 21:40]
    CLOCK: [2017-11-06 Mon 21:41]--[2017-11-06 Mon 21:59] =>  0:18
    CLOCK: [2017-11-06 Mon 21:03]--[2017-11-06 Mon 21:40] =>  0:37
    CLOCK: [2017-11-06 Mon 20:55]--[2017-11-06 Mon 21:03] =>  0:08

Add github release notes for previous sprint.

Title: Dogen v1.0.06, "Praia da Mariquita"

#+begin_src markdown
![Praia da Mariquita,](http://files.praiadamariquita.webnode.pt/200000109-50eaf52e2d/2015-10-17%2020.02.17.jpg)
_Praia da Mariquita, Namibe, Angola. (C) Praia da Mariquita Lodge, 2014._

Overview
=======
Our long road towards the clean up of the backends continued with another long and arduous sprint. The bulk of the work in this sprint was focused on two activities:

- **File locators work**: clean up the backend-specific file locators and move them into yarn. In order to do this we needed to generalise a large number of data structures that were originally designed to be language-specific. This has proven to be quite a challenge, and we probably still have another full sprint ahead of us on this work.
- **Additional exomodel work**: in the previous sprint we introduced the concept of _exomodels_; these originally used the regular meta-model elements such as ```yarn::object``` and so forth. This sprint it became obvious that a further round of simplification is still required, moving away from the core meta-model elements within the frontends. This work has only started but we can already see two obvious benefits: a) creating a frontend will be much easier, with very little code required b) the final JSON format will be quite trivial, making it easy for users to generate it or to map it from other tooling.

In addition to this, a number of "fun" activities where also undertaken to break away from the monotony of refactoring. These also provided tangible benefits in terms of Dogen development:

- **Consolidation of responsibilities in Yarn**: A number of classes were tidied up and moved into Yarn, making the meta-model more cohesive (file housekeeping, artefact writing, etc). Other classes already in Yarn were improved (better naming, remove classes that did not add any value, etc).
- **Integration of CCache in Travis**: most of our builds are now much quicker (in the order of tens of minutes or less) due to caching of translation units. Unfortunately, this work does not extend to GCC's Debug build (for some not yet understood reason) nor to OSX (given the peculiarities of its many packaging systems, we still haven't quite figure out how to install CCache) nor to Windows (its not clear that AppVeyor and/or MSVC support CCache or a CCache like tool).
- **Use of colour in Dia's UML diagrams**: as described below, we started colour-coding UML classes in Dia.
- **Revamp of project logo**: Dogen now sports a slightly more professional project logo [in Github](https://github.com/DomainDrivenConsulting/dogen).

User visible changes
================
The only user visible change this sprint is the introduction of a simple colour scheme for Dia UML Diagrams. This idea was largely copied from this paper: [Instinct: A Biologically Inspired Reactive Planner for Embedded Environments](http://www.robwortham.com/wp-content/uploads/2016/05/ICAPS-2016-PlanRob-Instinct-Planner.pdf). Note that the colours have no meaning to Dogen itself, but they do make interpreting diagrams a lot easier.

![Coloured UML Diagrams](https://github.com/DomainDrivenConsulting/dogen/raw/master/doc/blog/images/colour_coded_uml_diagrams.png)

Colouring is performed via a simple python script [available here](https://github.com/DomainDrivenConsulting/dogen/blob/master/projects/dia/python/colour.py), which can be executed in Dia's interactive python console.

As always, for gory details on the work carried out this sprint, see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/v1/sprint_backlog_06.org).

Next Sprint
===========
Next sprint we'll continue working on the new exomodel classes and resume the work on the backend-agnostic file locator.

Binaries
======
You can download binaries from [Bintray](https://bintray.com/domaindrivenconsulting/Dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_1.0.06_amd64-applications.deb](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.06/dogen_1.0.06_amd64-applications.deb)
- [dogen-1.0.06-Darwin-x86_64.dmg](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.06/dogen-1.0.06-Darwin-x86_64.dmg)
- [dogen-1.0.06-Windows-AMD64.msi](https://dl.bintray.com/domaindrivenconsulting/Dogen/dogen-1.0.06-Windows-AMD64.msi)

**Note**: They are produced by CI so they may not yet be ready.

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/927655421531361280][Tweet]]
- [[https://www.linkedin.com/feed/update/urn:li:activity:6333421782644719616][LinkedIn]]
- [[https://gitter.im/DomainDrivenConsulting/dogen][Gitter]]

*** STARTED Sprint and product backlog grooming                       :story:

Updates to sprint and product backlog.

*** COMPLETED Remove remnants of upsilon                              :story:
    CLOSED: [2017-11-07 Tue 09:00]
    CLOCK: [2017-11-07 Tue 08:39]--[2017-11-07 Tue 09:00] =>  0:21
    CLOCK: [2017-11-07 Tue 08:25]--[2017-11-07 Tue 08:39] =>  0:14

Originally we had removed upsilon as a frontend but it seems there are
still some remnants around yarn. Delete them.

*** STARTED Remove yarn element types in dia frontend                 :story:
    CLOCK: [2017-11-09 Thu 20:04]--[2017-11-09 Thu 20:11] =>  0:07
    CLOCK: [2017-11-09 Thu 19:35]--[2017-11-09 Thu 20:03] =>  0:28
    CLOCK: [2017-11-09 Thu 07:55]--[2017-11-09 Thu 08:40] =>  0:45
    CLOCK: [2017-11-07 Tue 18:09]--[2017-11-07 Tue 19:00] =>  0:51
    CLOCK: [2017-11-07 Tue 09:02]--[2017-11-07 Tue 09:11] =>  0:09

Instead of mapping to yarn element types, we should be using the
stereotypes directly.

Actually the right way of doing this is to split out the well-known
stereotypes from the other stereotypes.

*** Implement exomodel in terms of exoelements                        :story:

For details on the analysis, see the comments in the previous sprint.

Notes:

- now that there is no longer a mismatch between dia's model and
  yarn's model we can probably do away with the processed object and
  processed comment, and simply map dia directly into yarn.

Tasks:

- change yarn.dia to remember the "contained by" name rather than the
  module name. Construct the object names from the contained by
  name. Actually this won't work; the reason why we remember the
  entire module is because we need to do a lookup in order to find the
  module so we can update the documentation. We will still have this
  problem when it comes to exoelements. Best to just create another
  map this time to exoelement and follow the pattern. Actually, we can
  clean this up slightly: create a map of exoelements
- add exoelement, exoattribute.
- create a parallel infrastructure in dia that populates the
  exoelements.
- create a new transform that converts exoelements into
  endomodels. Somehow isolate the dia part of the pipeline so we can
  switch between new world and old world. Actually we could very
  simply check the exoelements container; if not empty use that,
  otherwise use legacy.
- once we get the dia side of the pipeline working, delete all classes
  related to old world in yarn.dia.
- create an hydrator that reads the new json and creates
  exoelements. Add some basic feature switch so we can alternate
  between new world and old world.

Problems:

- modules do not have a stereotype
- add yarn element types enum to yarn and a method that given a
  container of strings, returns the types. Use these in yarn.dia
- add string constants for element stereotypes and use these to mark
  the exoelements. Use this method in the stereotypes transforms in
  yarn.
- name does not have the module (e.g. contained by is not working).

*** Generate file paths as a transform                                :story:

See the comments in the previous sprint.

*** Split registrar into two classes                                  :story:

At present we do not distinguish between the setting up of the
registrar and the usage of the registrar. Up to know this is not a
major issue, although its a bit of a smell that we have to call
validate at some arbitrary point.

However, with the new parts/builder setup, this becomes even more of a
problem because we only want to build the parts once we have
registered all of the formatters. The right thing would have been to
have:

- a registrar builder, used during registration;
- a build step which returns the (validated) registrar. Once build is
  called, we should throw if anyone attempts to add more formatters.

This makes it hard to misuse the API.

Notes:

- how does this affect plugins? will it still be possible to register
  formatters from a shared library?

Tasks:

- create a registrar builder with most of the existing registrar
  interface. On build it computes the parts, generates the repository,
  etc and then supplies that to the registrar. The registrar itself is
  no longer static, just a member of the workflow.

*** Update backend shape to match yarn                                :story:

In an ideal world, the backends should be made up of two components:

- *meta-model*: a set of types that augment yarn with backend
  specific elements. This is what we call fabric at present.
- *transforms*: of these we have two kinds:
  - the model-to-model transforms that involve either yarn meta-model
    elements or backened specific meta-model elements. These live in
    fabric at present.
   - the model-to-text transforms that convert a meta-model element
     (yarn or backend specific) into an artefact. These we call
     formatters at present.

The ultimate destination for the backend is then to have a shape that
reflects this:

- rename formatters to transforms
- move artefact formatter into yarn; with this it means we can also
  move all of the top-level workflow formatting logic into
  yarn. However, before we can do this we must make all of the backend
  specific code in the formatter interface go away.
- note that at this point we no longer need to know what formatters
  belong to what backend other than perhaps to figure out if the
  backend is enabled. This means yarn can now have the registrars for
  formatters and organise them by backend. Which means the
  model-to-text chain will own all of these. However, we still have
  the managed directories to worry about; somehow, someone has to be
  able to compute the managed directories per kernel. This could be
  done at yarn level if the locator is clever enough.

Of course, before we can contemplate this change, we must first get
rid of formattables altogether.

We must also somehow model canonical formatters in yarn. Take this
into account when we do:

:        /*
:         * We must have one canonical formatter per type per facet.
:         * FIXME: this check is broken at the moment because this is
:         * only applicable to yarn types, not fabric types. It is also
:         * not applicable to forward declarations. We need some
:         * additional information from yarn to be able to figure out
:         * which types must have a canonical archetype.
:         */

*** Improvements to dia model                                         :story:

Assorted notes on cleaning-up the dia model:

- create a base class such as =value= and make all values inherit from
  it instead of using boost variant.
- according to DTD, a composite can be made up of either composites or
  attributes. We incorrectly modeled it as having just one inner
  composite.
- perhaps this is better thought of slightly differently: an attribute
  has child nodes. The child nodes can either be leaf nodes, in which
  case they are values, or non-leaf nodes in which case they are
  composite nodes. Composite nodes themselves can have child nodes. If
  they are leaf nodes they are values; if they are non-leaf nodes they
  are either attributes or composites.
- note that we do not need to use shared pointers in composite: we
  could simply have an attribute by value. However, we still need to
  handle the case where the children are either composite or
  attributes. So if we somehow could get composite and attribute to
  have a common base class, we could have a container of that base
  class in composite. For this we would need a shared pointer.
- consider adding the postfix =node= to class names and make it a real
  tree, as per dia's implementation.
- covert all vectors to lists since we do not know their sizes on
  construction.
- one thing to bear in mind is that if we fix the tree structure, we
  will break the XML parsing code in hydrator, which took quite a
  while to get right (and has hacks such as "inner composite").
- its not obvious why we need to treat =dia::string= in a different
  way from all other attribute values (except for =dia::font=).

*** Consider bucketing elements by meta-type in model                 :story:

At the moment we have a flat container of elements in the main
model. However, it seems like one of its use cases will be to bucket
the elements by meta-type before processing: formatters will want to
locate all formatters for a given meta-type and apply them all. At
present we are asking for the formatters for meta-name
repeatedly. This makes no sense, we should just ask for them once and
apply all formatters in one go.

For this we could simply group elements by meta-name in the model
itself and then use that container at formatting time. However, there
may be cases where looping through the whole model is more convenient
(during transforms) so this is not without its downsides.

Alternatively we could consider just bucketing in the formatters'
workflow itself.

This work will only be useful once we get rid of the formattables
model.

*** Properties vs configuration                                       :story:

Originally we had defined properties to mean things which are computed
and configuration to mean things which are read directly from the
meta-data and not touched afterwards. This made life easier in
determining how each class was used. However, this was not strictly
enforced and now there are many cases where properties are used when
configuration should have been (and probably vice-versa). In addition,
we have cases where we should have used configuration but used nothing
(type parameters springs to mind). We need to do a clean up of the
meta-model.

*** Create a text model post-processing chain                         :story:

The following transforms can be done after generation of the text model:

- clang format
- protected regions: read the file on disk, replace contents of the
  protected region with the data read from disk.

These can be contained in a post-processing chain for the text model.

Note that we need artefacts to have an associated language so that we
can use the correct clang format configuration. If a language is not
supported by clang format (e.g. c#) we should just skip the files. The
text model could group files by language.

*** Postfix and directory fields in annotations look weird            :story:

Why are we manually instantiating postfix and directory for each
formatter/facet instead of using templates?

*** Rename options to transformation request                          :story:

These are not really "options"; it is a request made into yarn to
code-generate a model. We haven't yet got a proper name but it has to
somehow involve the word "request". The best way is to visualise this
as part of some API where may such requests can be made (and handled
concurrently).

This also means we need to split out the request from the context. We
should have an initialisation phase where we construct the context and
then we should be able to reuse the pipeline for many requests. This
also means that the right place to put the transform metrics is in the
request - not the context - given that these are request specific.

The best way to go about it may be to have two contexts:

- transformation context: const; loaded at start-up.
- request context: request specific context, including probing and the
  request itself.

Then:

- clients are responsible for setting up the transformation
  context. This ensures we do it only once.
- clients are also responsible for setting up the request context, but
  they then do it for each request.

Note also that a request should support multiple target models.

*** Detect unqualified stereotypes                                    :story:

If a user enters say =enumeration= instead of =yarn::enumeration= we
are providing an unhelpful error message:

: Error: Attribute type is empty: structured

This is because we validate the class as if it was an object and then
figure out that there are no types against the attributes. One easy
way to make things more useful is to detect unqualified stereotypes
and error straight away with a more useful message such as "did you
mean yarn::xyz?".

We could also do the same if the stereotype is blank ("did you mean
enumeration?").

*** Tidy-up fabric                                                    :story:

Now we have dynamic transforms, we don't really need all the classlets
we've created in fabric. We can get away with probably just the
dynamic transform, calling all the factories.

*** Clean-up archetype locations modeling                             :story:

We now have a large number of containers with different aspects of
archetype locations data. We need to look through all of the usages of
archetype locations and see if we can make the data structures a bit
more sensible. For example, we should use archetype location id's
where possible and only use the full type where required.

Notes:

- formatters could return id's?
- add an ID to archetype location; create a builder like name builder
  and populate ID as part of the build process.

*** Use element ids for associations                                  :story:

There doesn't seem a need for having entire names for associations;
these are used to find information by ID anyway. We should try to
convert them to element id's instead and see what breaks.

- transparent, opaque associations
- base, derived visitor
- contained by

We can't do this for:

- visitor: we use the name in the formatter.

Actually there is a reason for this: we use the names to build the
file paths and the includes. We need to add some comments.

*** Add facet validation against language standard                    :story:

With the move of enablement to yarn, we can no longer validate facets
against the language standard. For example, we should not allow
hashing on C++ 98. The code was as follows:

#+begin_src c++
void enablement_expander::validate_enabled_facets(
    const global_enablement_configurations_type& gcs,
    const formattables::cpp_standards cs) const {
    BOOST_LOG_SEV(lg, debug) << "Validating enabled facets.";

    if (cs == formattables::cpp_standards::cpp_98) {
        using formatters::hash::traits;
        const auto arch(traits::class_header_archetype());

        const auto i(gcs.find(arch));
        if (i == gcs.end()) {
            BOOST_LOG_SEV(lg, error) << archetype_not_found << arch;
            BOOST_THROW_EXCEPTION(expansion_error(archetype_not_found + arch));
        }

        const auto& gc(i->second);
        if (gc.facet_enabled()) {
            const auto fctn(gc.facet_name());
            BOOST_LOG_SEV(lg, error) << incompatible_facet << fctn;
            BOOST_THROW_EXCEPTION(expansion_error(incompatible_facet + fctn));
        }
    }

    BOOST_LOG_SEV(lg, debug) << "Validated enabled facets.";
}
#+end_src

It was called from the main transform method in enablement transform,
prior to uptading facet enablement.

*** Tidy-up assistant API                                             :story:

Now we have element in assistant we can start removing the need for
element in the calls, making the templates simpler.

*** Facets incompatible with standards                                :story:

Some facets may not be supported for all settings of a language. For
example the hash facet is not compatible with C++ 98. We need to have
some kind of facet/formatter level validation for this.

*** Handcrafted templates                                             :story:

At present we generate constructors, swap, etc. for handcrafted
classes. Ideally users should be able to create a profile that enables
the things they want to see on a template and then associate it with a
stereotype. For this we will need aspect support.

*** Drop the original extension in tailor                             :story:

Filenames in tailor look weird:

: dart.dia.json

it should just be:

: dart.json

*** Move dependencies into yarn                                       :story:

Actually the dependencies will be generated at the kernel level
because 99% of the code is kernel specific. However, we need to make
it an external transform.

Tasks:

- create the locator in the C++ external transform
- create a dependencies transform that uses the existing include
  generation code.

*Previous understanding*

It seems all languages we support have some form of "dependencies":

- in c++ these are the includes
- in c# these are the usings
- in java these are the imports

So, it would make sense to move these into yarn. The process of
obtaining the dependencies must still be done in a kernel dependent
way because we need to build any language-specific structures that the
dependencies builder requires. However, we can create an interface for
the dependencies builder in yarn and implement it in each kernel. Each
kernel must also supply a factory for the builders.

*** Consider folding quilt into yarn                                  :story:

In the far distant future, when we finally finish merging all the
quilt specific stuff into yarn (e.g. formattables), it actually makes
sense to deprecate quilt as a concept. Yarn then becomes the central
point, and frontends and backends are just implementations that hook
into it. Thus we then have simply =yarn.cpp= and =yarn.csharp=.

However, there is still a concept that needs to be captured: the
kernel. That is, a set of backends that work together to provide some
kind of "service". In quilt's case the basic type definitions. We
could potentially want to implement other backends that are totally
distinct from quilt. However, we still do not have a concrete use case
for this. Thus it may make more sense to just fold now and worry about
these more flexible use cases when they arrive. We can always rename.

*** Code-generate annotations type templates                          :story:

Tasks:

- create a meta-model element for type templates. Add container in
  exomodel for it. Name: =yarn::annotation_type_template=?
- add frontend support for the type template element.
- add a transform that reads all the meta-data from type templates and
  populates the yarn element of the type template. Add this transform
  to the exomodel transforms, at the end of the chain (e.g. after
  annotations).
- create a meta-model element for the initialiser of type templates,
  made up of all type templates in the model. Add a container of
  initialiser in endomodel.
- add a transform that moves all of the type templates into the
  initialiser. This can be done as part of the exomodel to endomodel
  transform. Or maybe we should have a stand alone transform, and the
  final transform simply ignores type templates.
- create a registrar in annotations that registers type templates.
- create a stitch template for the initialiser, taking the registrar
  as an argument, and registering all type templates.
- add all type templates to all models, and generate the type
  initialisers.
- hook the type initialisers to the initialisers.
- change type group repository to initialise from the registrar.
- delete all type groups JSON and hydrator and related code.

Merged stories:

*Initialisation of meta-data*

At present we are reading meta-data files for every transformation. In
reality, it makes no sense to allow the meta-data files to change
dynamically, because the consumers of the meta-data are hard-coded. So
it would make more sense to treat them as a initialisation step. This
will make even more sense when we code-generate the types instead of
using JSON. Then we can hook up the generated code to the
initialisers.

*** Cannot make qualified references to concepts                      :story:

At present it is not possible to consume concepts defined in a
referenced model, nor is it possible to refer to a concept in a
different module from the module in which the element is in, e.g.: say
concept C0 is declared in module M0; all types of M0 can have C0 as
stereotype and that will resolve. However any types on any other
module cannot see the concept.

One suggestion is to allow scoped names in stereotypes:
=module::Concept=.

The heuristic for concept resolution is then:

- external modules are never part of the scoped name;
- on a scoped concept with M names, we first start by assuming that
  the first name is the model module and M-2 is/are the internal
  module(s). We try this for all names in M-2, e.g. first two names
  are model modules and M-3 names are internal modules and so forth.

*** Add support for object templates that work cross-model            :story:

We've implemented support for cross-model inheritance in sprint 87 but
we did not cover object templates. Most of the approach is the same,
but unfortunately we can't just reuse it.

Tasks:

- we need a refines field which is a text collection.
- we need refinement settings, factory etc.
- update parsing expander.

*** Move formatting styles into yarn                                  :story:

We need to support the formatting styles at the meta-model level.

*** Throw on unsupported stereotypes                                  :story:

In some cases we may support a feature in one language but not on
others like say ORM at present. If a user requests ORM in a C# model,
we should throw.

If we are in compatibility mode, however, we should not throw.

Note that we are already throwing if a stereotype is totally
unknown. The problem here is that the stereotype is known, but not
supported for all kernels. This is a bit trickier.

We also need to check the existing code in stereotypes transform to
stop trowing if compatibility flag is on.

*** Change order of includes according to Lakos major design rule     :story:

Lakos says:

#+begin_quote
The .c file of every component should include its own .h file as the
first substantive line of code.
#+end_quote

We decided to include it as the last line. However, Lakos approach has
the side-effect of automatically detecting headers that are missing
includes. We used to do this manually by generating =.cpp= files that
just included the header but then had to remove it because it was
slowing down compilation. With Lakos approach we get the best of both
worlds.

We need to also update the generated code to follow this
approach. This will require some thinking.

*** Move element segmentation into yarn                               :story:

We've added the notion that an element can be composed of other
elements in quilt, in order to handle forward declarations. However,
with a little bit of effort we can generalise it into yarn. It would
be useful for other things such as inner classes. We don't need to
actually implement inner classes right now but we should make sure the
moving of this feature into yarn is compatible with it.

Notes:

- seems like we have two use cases: a) we need all elements, master
  and extensions and we don't really care about which is which. b) we
  only want masters. However, we must be able to access the same
  element properties from either the master or the extension. Having
  said all that, it seems we don't really need all of the element
  properties for both - forward declarations probably only need:
  decoration and artefact properties.
- we don't seem to use the map in formattables model anywhere, other
  than to find master/extension elements.
- Yarn model could have two simple list containers (masters and
  all). Or maybe we don't even need this to start off with, we can
  just iterate and skip extensions where required.
- so in conclusion, we to move decoration, enablement and dependencies
  into yarn (basically decoration and artefact properties) first and
  then see where segmentation ends.

Tasks:

- add a concept for element extensions: =Extensible=. Contains a list
  of element pointers.
- populate it with the extensions.
- change enablement to merge all element properties of extensible
  elements.

*** Create a yarn locator                                             :story:

We need to move all functionality which is not kernel specific into
yarn for the locator. This will exist in the helpers namespace. We
then need to implement the C++ locator as a composite of yarn
locator. It will live in fabric.

*Other Notes*

At present we have multiple calls in locator, which are a bit
ad-hoc. We could potentially create a pattern. Say for C++, we have
the following parameters:

- relative or full path
- include or implementation: this is simultaneously used to determine
  the placement (below) and the extension.
- meta-model element:
- "placement": top-level project directory, source directory or
  "natural" location inside of facet.
- archetype location: used to determine the facet and archetype
  postfixes.

E.g.:

: make_full_path_for_enumeration_implementation

Interestingly, the "placement" is a function of the archetype location
(a given artefact has a fixed placement). So a naive approach to this
seems to imply one could create a data driven locator, that works for
all languages if supplied suitable configuration data. To generalise:

- project directory is common to all languages.
- source or include directories become "project
  sub-directories". There is a mapping between the artefact location
  and a project sub-directory.
- there is a mapping between the artefact location and the facet and
  artefact postfixes.
- extensions are a slight complication: a) we want to allow users to
  override header/implementation extensions, but to do it so for the
  entire project (except maybe for ODB files). However, what yarn's
  locator needs is a mapping of artefact location to  extension. It
  would be a tad cumbersome to have to specify extensions one artefact
  location at a time. So someone has to read a kernel level
  configuration parameter with the artefact extensions and expand it
  to the required mappings. Whilst dealing with this we also have the
  issue of elements which have extension in their names such as visual
  studio projects and solutions. The correct solution is to implement
  these using element extensions, and to remove the extension from the
  element name.
- each kernel can supply its configuration to yarn's locator via the
  kernel interface. This is fairly static so it can be supplied early
  on during initialisation.
- there is still something not quite right. We are performing a
  mapping between some logical space (the modeling space) and the
  physical space (paths in the filesystem). Some modeling elements
  such as the various CMakeLists.txt do not have enough information at
  the logical level to tell us about their location; at present the
  formatter itself gives us this hint ("include cmakelists" or "source
  cmakelists"?). It would be annoying to have to split these into
  multiple archetypes just so we can have a function between the
  archetype location and the physical space. Although, if this is the
  only case of a modeling element not mapping uniquely, perhaps we
  should do exactly this.
- However, we still have inclusion paths to worry about. As we done
  with the source/include directories, we need to somehow create a
  concept of inclusion path which is not language specific; "relative
  path" and "requires relative path" perhaps? These could be a
  function of archetype location.

*** Add a modeline to stitch                                          :story:

It would be nice to be able to supply the mode and other emacs
properties to stitch templates. For that we just need a special KVP
used at the top that contains the modeline:

: <#@ modeline="-*- mode: poly-stitch; tab-width: 4; indent-tabs-mode: nil; -*-" #>

Stitch can read this KVP and ignore it.

*** Create "opaque" kernel and element properties                     :story:

As part of the element container, we can have a set of base classes
that are empty: =opaque_element_properties=. This class is then
specialised in each kernel with the properties that are specific to
it. We probably need an equivalent for:

- kernel level properties
- element level properties
- attribute level properties.

We then have to do a lot of casting in the helpers.

Once we got these opaque properties, we can then create "kernel
specific expanders" which are passed in to the yarn workflow. These
populate the opaque properties.

*** Move helpers into yarn                                            :story:

Looking at helpers, it is clear that they are common to all
languages. We just need to rename the terminology slightly -
particularly wrt to streaming properties - and then move this code
across into yarn.

*** Move facet properties into yarn                                   :story:

We should be able to handle these generically in yarn.

*** Move ORM camel-case and databases into yarn                       :story:

We should handle this property at the ORM level, rather than at the
ODB level.

Similarly, we should move the ODB databases into yarn and make that a
ORM-level concept.

*** Distinguish between meta-types that require canonical archetypes  :story:

At present it is not possible to know which meta-types require
canonical archetypes and which don't. In the validation we said:

:         * We must have one canonical formatter per type per facet.
:         * FIXME: this check is broken at the moment because this is
:         * only applicable to yarn types, not fabric types. It is also
:         * not applicable to forward declarations. We need some
:         * additional information from yarn to be able to figure out
:         * which types must have a canonical archetype.

We should have some kind of flag in yarn to distinguish. This still
requires a bit of thinking.

*** Tidy-up of inclusion terminology                                  :story:

Random notes:

- imports and exports
- some types support both (headers)
- some support imports only (cpp)
- some support neither (cmakelists, etc).

*** Add support for qualified class names in dia                      :story:

#+begin_quote
*Story*: As a dogen user, I don't want to have to define packages in
certain cases.
#+end_quote

It has become apparent that creating large packages in dia and placing
all classes in a large package is cumbersome:

- there are issues with the large package implementation in dia,
  making copying and pasting a dark art; its not very obvious how one
  copies into a package (e.g. populating the child node id correctly).
- models do not always have a neat division between packages; in
  dogen, where packages would be useful, there are all sorts of
  connections (e.g. inheritance, association) between the package and
  the model "package" or other packages. Thus is very difficult to
  produce a representative diagram.

A solution to this problem would be to support qualified names in
class names; these would be interpreted as being part of the current
model. One would still have to define a large package, but it could be
empty, or contain only the types which only have connections inside
the package, plus comments for the package, etc.

** Deprecated
