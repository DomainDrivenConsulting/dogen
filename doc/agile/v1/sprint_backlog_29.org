#+title: Sprint Backlog 28
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) spike(p) }

* Sprint Goals

- Move remaining formattable types to logical and physical models.
- Merge =text= models.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2020-11-08 Sun 17:57]
| <75>                                                 |         |       |      |       |
| Headline                                             | Time    |       |      |     % |
|------------------------------------------------------+---------+-------+------+-------|
| *Total time*                                         | *15:35* |       |      | 100.0 |
|------------------------------------------------------+---------+-------+------+-------|
| Stories                                              | 15:35   |       |      | 100.0 |
| Active                                               |         | 15:35 |      | 100.0 |
| edit release notes for previous sprint               |         |       | 5:04 |  32.5 |
| Create a demo and presentation for previous sprint   |         |       | 0:28 |   3.0 |
| Sprint and product backlog grooming                  |         |       | 1:29 |   9.5 |
| Improvements to template processing in logical model |         |       | 0:26 |   2.8 |
| Add C++ helpers to the PMM                           |         |       | 8:08 |  52.2 |
#+tblfm: $5='(org-clock-time%-mod @3$2 $2..$4);%.1f
#+end:

*** COMPLETED edit release notes for previous sprint                  :story:
    CLOSED: [2020-11-06 Fri 14:11]
    :LOGBOOK:
    CLOCK: [2020-11-07 Sat 14:00]--[2020-11-07 Sat 14:15] =>  0:15
    CLOCK: [2020-11-07 Sat 10:41]--[2020-11-07 Sat 11:42] =>  1:01
    CLOCK: [2020-11-06 Fri 14:40]--[2020-11-06 Fri 14:43] =>  0:03
    CLOCK: [2020-11-06 Fri 13:02]--[2020-11-06 Fri 14:11] =>  1:09
    CLOCK: [2020-11-06 Fri 11:01]--[2020-11-06 Fri 12:26] =>  1:25
    CLOCK: [2020-11-04 Wed 22:01]--[2020-11-04 Wed 22:30] =>  0:29
    CLOCK: [2020-11-02 Mon 23:00]--[2020-11-02 Mon 23:14] =>  0:14
    CLOCK: [2020-11-02 Mon 22:22]--[2020-11-02 Mon 22:50] =>  0:28
    :END:

add github release notes for previous sprint.

release announcements:

- [[https://twitter.com/MarcoCraveiro/status/1324723551795118080][twitter]]
- [[https://www.linkedin.com/feed/update/urn:li:activity:6730489589905154048/][linkedin]]
- [[https://gitter.im/MASD-Project/Lobby][Gitter]]

#+begin_src markdown
![Praia das Miragens](https://upload.wikimedia.org/wikipedia/commons/f/f2/Parabolic_Shelters_%2818861902633%29.jpg?1604306484246)
_Artesanal market, Praia das Miragens, Moçâmedes, Angola. (C) [2015 David Stanley](https://www.wikiwand.com/pt/Mo%C3%A7%C3%A2medes)_.

# Introduction

Welcome to yet another Dogen release. After a series of hard-fought and seemingly endless sprints, this sprint provided a welcome respite due to its more straightforward nature. Now, this may sound like a funny thing to say, given we had to take what could only be construed as one _massive step sideways_, instead of continuing down the track beaten by the previous _n_ iterations; but the valuable lesson learnt is that, oftentimes, taking the _theoretically longer_ route yields much faster progress than taking the _theoretically shorter_ route. Of course, had we heeded van de Snepscheut, we would have known:

> In theory, there is no difference between theory and practice. But, in practice, there is.

What really matters, and what we keep forgetting, is how things work _in practice_. As we mention many a times in these release notes, the highly rarefied, highly abstract meta-modeling work is not one for which we are cut out, particularly when dealing with very complex and long-running refactorings. Therefore, anything which can bring the abstraction level as close as possible to normal coding is bound to greatly increase productivity, even if it requires adding "temporary code". With this sprint we finally saw the light and designed an architectural bridge between the dark _old world_ - largely hacked and hard-coded - and the bright and shiny _new world_ - completely data driven and code-generated. What is now patently obvious, but wasn't thus far, is that bridging the gap will let us to move quicker because we don't have to carry so much conceptual baggage in our heads every time we are trying to change a single line of code.

Ah, but we are getting ahead of ourselves! This and much more shall be explained in the release notes, so please read on for some exciting news from the front lines of Dogen development.

# User visible changes

This section normally covers stories that affect end users, with the video providing a quick demonstration of the new features, and the sections below describing them in more detail. As there were no user facing features, the video discusses the work on internal features instead.

[![Sprint 1.0.28 Demo](https://img.youtube.com/vi/tLzxPJMPFFI/0.jpg)](https://youtu.be/tLzxPJMPFFI)
_Video 1: Sprint 28 Demo._

# Development Matters

In this section we cover topics that are mainly of interest if you follow Dogen development, such as details on internal stories that consumed significant resources, important events, etc. As usual, for all the gory details of the work carried out this sprint, see [the sprint log](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_28.org).

## Significant Internal Stories

The main story this sprint was concerned with removing the infamous ```locator``` from the C++ and C# models. In addition to that, we also had a small number of stories, all gathered around the same theme. So we shall start with the locator story, but provide a bit of context around the overall effort.

### Move C++ locator into physical model

As we explained at length in the previous sprint's [release notes](https://github.com/MASD-Project/dogen/releases/tag/v1.0.27), our most pressing concern is finalising the conceptual model for the LPS (Logical-Physical Space). We have a pretty good grasp of what we think the end destination of the LPS will be, so all we are trying to do at present is to refactor the existing code to make use of those new entities and relationships, replacing all that has been hard-coded. Much of the problems that still remain stem from the "formattables subsystem", so it is perhaps worthwhile giving a quick primer of what formattables were, why they came to be and why we are getting rid of them. For this we need to travel in time, to close to the start of Dogen. In those long forgotten days, long before we had the benefit of knowing about MDE (Model Driven Engineering) and domain concepts such as M2M (Model-to-Model) and M2T (Model-to-Text) transforms, we "invented" our own terminology and approach to converting modeling elements into source code. The classes responsible for generating the code were called ```formatters``` because we saw them as a "formatting engine" that dumped state into a stream; from there, it logically followed that the things we were "formatting" should be called "formattables", well, because we could not think of a better name.

Crucially, we also assumed that the different technical spaces we were targeting had lots of incompatibilities that stopped us from sharing code between them, which meant that we ended up creating separate models for each of the supported technical spaces - _i.e._, ```C++``` and ```C#```, which we now call _major technical spaces_. Each of these ended up with its own formattables namespace. In this world view, there was the belief that we needed to transform models closer to their ultimate technical space representation before we could start generating code. But after doing so, we began to realise that the formattable types were almost identical to their logical and physical counterparts, with a small number of differences.

![Formattables types](https://github.com/MASD-Project/dogen/raw/master/doc/blog/images/dogen_formatables_sprint_23.png)
_Figure 1: Fragment of the formattables namespace, C++ Technical Space, circa [sprint 23](https://github.com/MASD-Project/dogen/releases/tag/v1.0.23)._

What we since learned is that the logical and physical models must be able to represent all of the data required in order to generate source code. Where there are commonalities between technical spaces, we should exploit them, but where there are differences, well, they must still be represented within the logical and physical models; there simply is _nowhere else_ to place them. In other words, there isn't a requirement to keep the logical and physical models _technical space agnostic_, as we long thought was needed; instead, we should aim for a single representation, but also not be afraid of multiple representations where they make more sense. With this began a very long-standing effort to move modeling elements across, one at a time, from ```formattables``` and the long forgotten ```fabric``` namespaces into their final resting place. The work got into motion _circa_ [sprint 18](https://github.com/MASD-Project/dogen/releases/tag/v1.0.18), and ```fabric``` was swiftly dealt with, but ```formattables``` proved more challenging. Finally, ten sprints later, this long running effort came unstuck when we tried to deal with the representation of paths (or "locations") in the new world because it wasn't merely just "moving types around"; the more the refactoring progressed, the more abstract it was becoming. For a flavour of just how abstract things are getting, have a read on Section "Add Relations Between Archetypes in the PMM" in [sprint 26's release notes](https://github.com/MASD-Project/dogen/releases/tag/v1.0.26).

Ultimately, it became clear that we tried to bite more than we could chew. After all, in a completely data driven world, all of the assembly performed in order to generate a path is done by introspecting elements of the logical model, the physical meta-model (PMM) and the physical model (PM). This is _extremely_ abstract work, where all that once were regular programming constructs have now been replaced by a data representation of some kind; and we had no way to validate any of these representations until we reached the final stage of assembling paths together, a sure recipe for failure. We struggled with this on the back-end of the last sprint and the start of this one, but then it suddenly dawned that we could perhaps move one step closer to the end destination without necessarily making the whole journey; going half-way or bridging the gap, if you will. The moment of enlightenment revealed by this sprint was to move the hard-coded concepts in formattables to the new world of transforms and logical/physical entities, _without fully making them data-driven_. Once we did that, we found we had something to validate against that was much more like-for-like, instead of the massive impedance mismatch we are dealing with at present.

So this sprint we moved the majority of types in formattables into their logical or physical locations. As the story title implies, the bulk of the work was connected to moving the ```locator``` class on both C# and C++ formattables. This class had a seemingly straightforward responsibility: to build relative and full paths in the physical domain. However, it was also closely intertwined with the old-world formatters and the generation of dependencies (such as the include directives). It was difficult to unpick all of these different strands that connected the locator to the old world, and encapsulate them all inside of a transform, making use only of data available in the physical meta model and physical model, but once we achieved that all was light.

There were lots of twists and turns, of course, and we did find  some cases that do not fit terribly well the present design. For instance, we had assumed that there was a natural progression in terms of projections, _i.e._:

- from an external representation;
- to the simplified internal representation in the codec model;
- to the projection into the logical model;
- to the projection into the physical model;
- to, ultimately, the projection into a technical space - _i.e._, code generation.

As it turns out, sometimes we need to peek into the logical model after the projection to the physical model has been performed, which is not quite so linear as we'd want. This may sound slightly confusing, given that the entire point of the LPS is to have a model that combines both the logical _and_ physical dimensions. Indeed, it is so; but what we do not expect is to have to modify the logical dimension _after_ it was constructed and projected into the physical domain. Sadly, this is the case when computing items that require lists of project items such build files. Problems such as this made it for a tricky journey, but we somehow managed to empty out the C++ formattables model to the last few remaining types - the helpers - which we will hopefully mop up next sprint. C# is not lagging far behind, but we decided to tackle them separately now.

### Move stand-alone formattables to physical/logical models

Given that the locator story (above) became a bit of a mammoth - consuming 50% of the total ask - we thought we would separate any formattable types which were not directly related to locator into its own story. As it turns out there were still quite a few, but this story does not really add much to the narrative above given that the objectives were very much the same.

### Create a video series on the formattables refactor

A lot of the work for the formattables refactor was captured in a series of coding videos. I guess you'd have to be a pretty ardent fan of Dogen to find these interesting, especially as it is an 18-part series, but if you are, you can finally binge. Mind you, the recording does not cover the _entirety_ of the formattables work, for reasons we shall explain later; at around 15 hours long, it covers just about 30% of the overall time spent on these stories (~49 hours). _Table 1_ provides an exhaustive list of the videos, with a short description for each one; a link to the playlist itself is available below (_c.f._ _Video 2_).

[![Sprint 1.0.28 Demo](https://img.youtube.com/vi/pMqUzX0PU_I/0.jpg)](https://www.youtube.com/playlist?list=PLwfrwe216gF0NHaErGDeJrtGU8pAoNYlG)
_Video 2: Playlist "MASD - Dogen Coding: Formatables Refactor"._

With so much taped coding, we ended up penning a few reflections on the process. These are partially a rehashing of what we had already learned (_c.f._ [Sprint 19](https://github.com/MASD-Project/dogen/releases/tag/v1.0.19), section "Recording of coding sessions"), but also contain some new insights. They can be summarised as follows:

- taped coding acts as a motivating factor, for some yet to be explained reason. It's not as if we have viewers or anything, but for some reason the neo-cortex seems to find it easier to get on with work if we think that we are recording. To be fair, we already experienced this with the MDE Papers, which had worked quite well in the past, though we lost the plot there a little bit of late.
- taped coding is great for thinking through a problem in terms of overall design. In fact, it's great if you try to explain the problem out loud in simple terms to a (largely imaginary) lay audience. You are forced to rethink the problem, and in many cases, it's easier to spot flaws with your reasoning as you start to describe it.
- taped coding is not ideal if you need to do "proper" programming, at least for me. This is because it's difficult to concentrate on coding if you are also describing what you are doing - or perhaps I just can't really multitask.

In general, we found that it's often good to do a video as we start a new task, describe the approach and get the task started; but as we get going, if we start to notice that progress is slow, we then tend to finish the video where we are and complete the task offline. The next video then recaps what was done, and begins a new task. Presumably this is not ideal for an audience that wants to experience the reality of development, but we haven't found a way to do this without degrading productivity to unacceptable levels.

|Video|Description|
|--------|-------------|
|[Part 1](https://youtu.be/CPugL2Qmj0c)|In this part we explain the rationale for the work and break it into small, self-contained stories.|
|[Part 2](https://youtu.be/4UW8HNPYdm0)|In this part we read the project path properties from configuration.|
|[Part 3](https://youtu.be/YN6i3fmZaVo)|In this part we attempt to tackle the locator directly, only to find out that there are other types which need to be cleaned up first before we can proceed.|
|[Part 4](https://youtu.be/MlgeBEThR0Y)|In this part we finish the locator source code changes, only to find out that there are test failures. These then result in an investigation that takes us deep into the tracing subsystem.|
|[Part 5](https://youtu.be/S533ja8Uvqc)|In this part we finally manage to get the legacy locator to work off of the new meta-model properties, and all tests to go green.|
|[Part 6](https://youtu.be/4pouLW4oLCw)|Yet more work on formattables locator.|
|[Part 7](https://youtu.be/nhmLWBKuTCE)|In this part we try to understand why the new transform is generating different paths from the old transform and fix a few of these cases.|
|[Part 8](https://youtu.be/_-zBX6JBX74)|In this part we continue investigating incorrect paths being produced by the new paths transform.|
|[part 9](https://youtu.be/3Jy02qjjSkQ)|In this part we finally replace the old way of computing the full path with the new (but still hacked) transform.|
|[Part 10](https://youtu.be/S7U3VhkDQ8E)|In this part we start to tackle the handling of inclusion directives.|
|[Part 11](https://youtu.be/9Y15-nbIddg)|In this video we try to implement the legacy dependencies transform, but bump into numerous problems.|
|[Part 12](https://youtu.be/1GaWU6o5_vs)|More work in the inclusion dependencies transform.|
|[Part 13](https://youtu.be/3kWLjk_PhIQ)|In this part we finish copying across all functions from the types facet into the legacy inclusion dependencies transform.|
|[Part 14](https://youtu.be/BIdkYHBcnwk)|In this part we start looking at the two remaining transforms in formatables.|
|[Part 15](https://youtu.be/KoRl8OL0GZY)|In this video we first review the changes that were done offline to remove the C++ locator and then start to tackle the stand-alone formatable types in the C++ model.|
|[Part 16](https://youtu.be/h-kXGcTUcac)|In this part we start to tackle the streaming properties, only to find out it's not quite as trivial as we thought.|
|[Part 17](https://youtu.be/QSDSa_AtD5M)|In this video we recap the work done on the streaming properties, and perform the refactor of the C++ standard.|
|[Part 18](https://youtu.be/NH60Pi85HTQ)|In this video we tackle the C++ aspect properties.|

_Table 1: Individual videos on the playlist for the formattables refactor._

### Assorted smaller stories

Before we decided on the approach narrated above, we tried to continue to get the data-driven approach done. That resulted in a number of small stories that progressed the approach, but didn't get us very far:

- **Directory names and postfixes are PMM properties**: Work done to model directory names and file name postfixes correctly in the PMM. This was a very small clean-up effort, that sadly can only be validated when we start assembly paths properly within the PMM.
- **Move ```enabled``` and ```overwrite``` into ```enablement_properties```**: another very small tidy-up effort that improved the modeling around enablement related properties.
- **Tracing of orchestration chains is incorrect** : whilst trying to debug a problem, we noticed that the tracing information was incorrect. This is mainly related to chains being reported as transforms and transforms using incorrect names due to copy-and-pasting errors.
- **Add full and relative path processing to PM**: we progressed this ever-so-slightly but we bumped into many problems so we ended up postponing this story for the next sprint.
- **Create a factory transform for parts and archetype kinds**: as with the previous story, we gave up on this one.
- **Analysis on a formatables refactor**: this was the analysis story that revealed the inadequacies of the present attempt of diving straight into a data-driven approach from the existing formattables code.

### Presentation for APA

We were invited by the Association of Angolan Programmers (Associação dos Programadores Angolanos) to do a presentation regarding research. It is somewhat tangential to Dogen, in that we do not get into a lot of details with the code itself but it may still be of interest. However, the presentation is in Portuguese. A special shout out and thanks goes to Filipe Mulonde (twitter: [@filipe_mulonde](https://twitter.com/filipe_mulonde)) and Alexandre Juca (twitter: [@alexjucadev](https://twitter.com/alexjucadev)) for inviting me, organising the event and for their work in APA in general.

[![Sprint 1.0.28 Demo](https://img.youtube.com/vi/yKfAhkYtQYM/0.jpg)](https://youtu.be/yKfAhkYtQYM)
_Video 3: Talk: "Pesquisa científica em Ciência da Computação" (Research in Computer Science)._

## Resourcing

Sadly, we did not improve our lot this sprint with regards to proper resource attribution. We created one massive story, the locator work, at 50%, and a smattering of smaller stories which are not very representative of the effort. In reality we should have created a number of much smaller stories around the locator work, which is really more of an epic than a story. However, we only realised the magnitude of the task when we were already well into it. At that point,  we did split out the other formattable story, at 10% of the ask, but it was a bit too little too late to make amends. At any rate, 61% of the sprint was taken with this formattables effort, and around 18% or so went on the data-driven effort; on the whole, we spent close to 81% on coding tasks, which is pretty decent, particularly if we take into account our "media" commitments. These had a total cost of 8.1%, with the lion's share (6.1%) going towards the presentation for APA. Release notes (5.5%) and backlog grooming (4.7%) were not particularly expensive, which is always good to hear. However, what was not particularly brilliant was our utilisation rate, dwindling to 35% with a total of 42 elapsed days for this sprint. This was largely a function of busy work and personal life. Still, it was a massive increase over the previous sprint's 20%, so we are at least going on the right direction.

![Sprint 28 stories](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_28_pie_chart.jpg)
_Figure 2_: Cost of stories for sprint 28.

## Roadmap

We actually made some changes to the roadmap this time round, instead of just forwarding all of the items by one sprint as we customarily do. It does see that we have five clear themes to work on at present so we made these into entries in the road map and assigned a sprint each. This is probably far too optimistic, but nonetheless the entire point of the roadmap is to give us a general direction of travel rather than oracular predictions on how long things will take - which we already know too well is a futile effort. What is not quite so cheerful is that the roadmap is already pointing out to March 2021 as the earliest, most optimistic date for completion, which is not reassuring.

![Project Plan](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_28_project_plan.png)

![Resource Allocation Graph](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_28_resource_allocation_graph.png)

# Binaries

You can download binaries from either [Bintray](https://bintray.com/masd-project/main/dogen/1.0.28) or GitHub, as per Table 1. All binaries are 64-bit. For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available in [zip](https://github.com/MASD-Project/dogen/archive/v1.0.28.zip) or [tar.gz](https://github.com/MASD-Project/dogen/archive/v1.0.28.tar.gz) format.

| Operative System | Format | BinTray | GitHub |
|----------|-------|-----|--------|
|Linux Debian/Ubuntu | Deb | [dogen_1.0.28_amd64-applications.deb](https://dl.bintray.com/masd-project/main/1.0.28/dogen_1.0.28_amd64-applications.deb) | [dogen_1.0.28_amd64-applications.deb](https://github.com/MASD-Project/dogen/releases/download/v1.0.28/dogen_1.0.28_amd64-applications.deb) |
|OSX | DMG | [DOGEN-1.0.28-Darwin-x86_64.dmg](https://dl.bintray.com/masd-project/main/1.0.28/DOGEN-1.0.28-Darwin-x86_64.dmg) | [DOGEN-1.0.28-Darwin-x86_64.dmg](https://github.com/MASD-Project/dogen/releases/download/v1.0.28/DOGEN-1.0.28-Darwin-x86_64.dmg)|
|Windows | MSI | [DOGEN-1.0.28-Windows-AMD64.msi](https://dl.bintray.com/masd-project/main/DOGEN-1.0.28-Windows-AMD64.msi) | [DOGEN-1.0.28-Windows-AMD64.msi](https://github.com/MASD-Project/dogen/releases/download/v1.0.28/DOGEN-1.0.28-Windows-AMD64.msi) |

_Table 2: Binary packages for Dogen._

**Note:** The OSX and Linux binaries are not stripped at present and so are larger than they should be. We have [an outstanding story](https://github.com/MASD-Project/dogen/blob/master/doc/agile/product_backlog.org#linux-and-osx-binaries-are-not-stripped) to address this issue, but sadly CMake does not make this a trivial undertaking.

# Next Sprint

The goals for the next sprint are:

- to finish formattables refactor;
- to start implement path and dependencies via PMM.

That's all for this release. Happy Modeling!
#+end_src

*** COMPLETED Create a demo and presentation for previous sprint      :story:
    CLOSED: [2020-11-06 Fri 14:40]
    :LOGBOOK:
    CLOCK: [2020-11-06 Fri 14:12]--[2020-11-06 Fri 14:40] =>  0:28
    :END:

Time spent creating the demo and presentation.

**** Presentation

***** Dogen v1.0.28, "Praia das Miragens"

    Marco Craveiro
    Domain Driven Development
    Released on 2nd November 2020

***** Move C++ locator into physical model
***** Move stand-alone formattables to physical/logical models

*** STARTED Sprint and product backlog grooming                       :story:
    :LOGBOOK:
    CLOCK: [2020-11-07 Sat 14:15]--[2020-11-07 Sat 15:06] =>  0:51
    CLOCK: [2020-11-07 Sat 08:49]--[2020-11-07 Sat 09:08] =>  0:19
    CLOCK: [2020-11-06 Fri 14:43]--[2020-11-06 Fri 14:53] =>  0:10
    CLOCK: [2020-11-02 Mon 22:50]--[2020-11-02 Mon 22:59] =>  0:09
    :END:

Updates to sprint and product backlog.

*** COMPLETED Move C# locator into physical model                     :story:
    CLOSED: [2020-11-07 Sat 14:38]

*Rationale*: completed in the previous sprint.

As per C++ model.

*** COMPLETED Move inclusion into physical model                      :story:
    CLOSED: [2020-11-07 Sat 14:40]

*Rationale*: completed in the previous sprint. We did it the legacy
way but we should create a new story for the "new world" way.

- try to use artefacts to store dependencies.

*** COMPLETED Move assorted c++ and c# properties into meta-model properties :story:
    CLOSED: [2020-11-07 Sat 14:41]

*Rationale*: completed in the previous sprint.

List of properties to move:

- =aspect_properties=
- =test_data_properties=
- =streaming_properties=
- =cpp_standards=
- =build_files_expander=: requires updating logical model with the
  properties, and then creating transforms.
- =assistant_properties=
- =attribute_properties=

Create a transform to read these properties or add it to the existing
meta-model properties transform.

*** COMPLETED Move directive group generation to physical model       :story:
    CLOSED: [2020-11-07 Sat 14:41]

*Rationale*: completed in the previous sprint. We did it the legacy
way but we should create a new story for the "new world" way.

- handle header guards as well.
- consider renaming this to relative paths.
- consider the role of parts in the directive groups.

*** COMPLETED Improvements to template processing in logical model    :story:
    CLOSED: [2020-11-08 Sun 12:26]
    :LOGBOOK:
    CLOCK: [2020-11-08 Sun 12:00]--[2020-11-08 Sun 12:26] =>  0:26
    :END:

At present we resolve wale template contents in a transform:
=logic_less_templates_population_transform= and then render both wale
and stitch templates in another: =archetype_rendering_transform=. We
need to merge these transforms and drop the archetype prefix.

Notes:

- drop the prefix on =archetype_text_templating=.
- drop relations in =archetype_text_templating= and see what
  breaks. Actually these are needed to model the template relations,
  which we have not yet completed.

*** STARTED Add C++ helpers to the PMM                                :story:
    :LOGBOOK:
    CLOCK: [2020-11-08 Sun 16:19]--[2020-11-08 Sun 17:57] =>  1:38
    CLOCK: [2020-11-08 Sun 15:55]--[2020-11-08 Sun 16:18] =>  0:23
    CLOCK: [2020-11-08 Sun 12:26]--[2020-11-08 Sun 13:24] =>  0:58
    CLOCK: [2020-11-08 Sun 11:12]--[2020-11-08 Sun 11:59] =>  0:47
    CLOCK: [2020-11-07 Sat 22:34]--[2020-11-07 Sat 22:44] =>  0:10
    CLOCK: [2020-11-07 Sat 22:22]--[2020-11-07 Sat 22:33] =>  0:11
    CLOCK: [2020-11-07 Sat 21:14]--[2020-11-07 Sat 22:11] =>  0:57
    CLOCK: [2020-11-07 Sat 15:47]--[2020-11-07 Sat 18:25] =>  2:38
    CLOCK: [2020-11-07 Sat 15:20]--[2020-11-07 Sat 15:46] =>  0:26
    :END:

Although temporarily, we need to add a representation of helpers on
the PMM. These must be sufficient to cater for the current use cases
in formattables.

Notes:

- we need an archetype for the helper with the meta-model elements
  populated via variability.
- create a PMM type to model the properties in the helper
  interface. Create archetype for helpers; we need transform and
  factory. Add a helper family to facet mapping.
- move reducer to the orchestration model. Do it in both LPS and
  logical model. Remove reducer from formattables.
- add helpers to PMM. Need four archetypes (factory and transform,
  header and implementation). Add logical transform using PMM to
  generate helper properties. Remove helper expander.
- once we finish integrating template, mark them as non generatable:

:     // FIXME: for now we still need these as generatable.


Merged stories:

*Move c++ helper related classes to logical model*

Classes to move:

- =helper_descriptor=

*Move helpers to text and physical models*

- move helper properties to text model.
- move helpers as text transforms to text model. Refactor them to use
  the new text model transform interface.

*** Add C# helpers to the PMM                                         :story:

Notes:

- merge c++ and c# helpers.

*** Move assorted formattable properties in C#                        :story:

We have a number of types lying around formattables in C# that need to
be moved to their correct logical and physical destination.

*** Prune non-generatable types from logical model                    :story:

Add a pruning transform that filters out all non-generatable types
from logical model.

Actually we can't just do this directly else the inclusion will not
work. However we do have a "reducer" transform in the formattables
namespace which needs to be moved to the new world.

*** Remove formatables namespace                                      :story:

When all types have been moved, we can delete the formatables types
and namespace.

*** Create a "combined" assistant in =text=                           :story:

Assistant should not really exist, but to get us to the next step we
should just make it a helper in =text= model. We just need to merge
the C++ and C# classes into one and move it to =text=.

*** Clean up helpers interface and move it to =text=                  :story:

Notes:

- we need to include the wale template in the meta-model
  element. Once this is done we should see if we can remove the stitch
  and wale formatters in the c++ model.
- the helper interface should only take logical and physical types so
  that we can move it to =text=. However, we may be using the
  assistant. See if we can create the assistant inside the helper as
  we do with formatters.

*** Move context and M2T interface to =text= model                    :story:

Implement these two types in terms of logical or physical types, and
move them to =text= model.

Merged stories:

*Create a common formatter interface*

Once all language specific properties have been moved into their
rightful places, we should be able to define a formatter interface
that is suitable for both c++ and c# in generation. We should then
also be able to move all of the registration code into generation. We
then need to look at all containers of formatters etc to see what
should be done at generation level.

Once we have a common formatter interface, we can add the formatters
themselves to the =element_artefacts= tuple. Then we can just iterate
through the tuples and call the formatter instead having to do
look-ups.

Also, at this point we can then update the physical elements generated
code to generate the transform code for backend and facet
(e.g. delegation and aggregation of the result).

*Move =model_to_text_transform= to =text= model*

This type has now been cleaned up and should be the same for C++ and
C# so should be moved to the common model.

*** Implement M2T chains via code generation                          :story:

We need to update the =backend= and =part= transforms to be a set of
calls to their "children", based on the PMM. Once this is done we can
remove all of the existing infrastructure in the TS models:

- repositories
- initialisers
- workflows
- traits
- registrars

Notes:

- in the new world we no longer need a M2T interface at the text
  transform level. The backend chain knows of all of the facet chains;
  and the facet chains know of all of the archetypes. We can dispatch
  the element using the visitor into a concrete type and then find the
  archetypes that process that type. However, we do not want to
  generate an apply method per logical element...

Merged stories:

*Implement backend and facet transform*

The backend transform should:

- return the ID of the backend;
- use the facet and archetype transforms to process all elements.

Check backlog for a story on this.

*** Replace =formatting_error= with =transformation_error=            :story:

Now that we moved from formatters to M2T transforms, we should stop
throwing =formatting_error= and start throwing
=transformation_error=. This needs to be done for both C# and C++ text
models.

*** Feature initializer with no features does not compile             :story:

We removed all the features from =masd::variability::initializer= and
the compilation failed with the following error:

#+begin_quote
[5/19] Building CXX object projects/dogen.text.cpp/src/CMakeFiles/dogen.text.cpp.lib.dir/types/feature_initializer.cpp.o
FAILED: projects/dogen.text.cpp/src/CMakeFiles/dogen.text.cpp.lib.dir/types/feature_initializer.cpp.o
/usr/bin/clang++-11  -DENABLE_CPP_REF_IMPL_TESTS -DENABLE_CSHARP_REF_IMPL_TESTS -DLZMA_API_STATIC -D_GLIBCXX_USE_CXX11_ABI=1 -Istage/include -I../../../../projects/dogen/include -I../../../../projects/dogen.identification/include -I../../../../projects/dogen.physical/include -I../../../../projects/dogen.cli/include -I../../../../projects/dogen.utility/include -I../../../../projects/dogen.variability/include -I../../../../projects/dogen.dia/include -I../../../../projects/dogen.codec/include -I../../../../projects/dogen.codec.dia/include -I../../../../projects/dogen.codec.json/include -I../../../../projects/dogen.codec.org_mode/include -I../../../../projects/dogen.tracing/include -I../../../../projects/dogen.logical/include -I../../../../projects/dogen.orchestration/include -I../../../../projects/dogen.templating/include -I../../../../projects/dogen.text/include -I../../../../projects/dogen.text.cpp/include -I../../../../projects/dogen.text.csharp/include -I../../../../projects/dogen.relational/include -isystem /work/DomainDrivenConsulting/masd/vcpkg/masd/installed/x64-linux/include -Wall -Wextra -Wconversion -Wno-mismatched-tags -pedantic -Werror -Wno-system-headers -Woverloaded-virtual -Wwrite-strings  -frtti -fvisibility-inlines-hidden -fvisibility=hidden  -O3 -DNDEBUG -fPIC   -std=gnu++17 -MD -MT projects/dogen.text.cpp/src/CMakeFiles/dogen.text.cpp.lib.dir/types/feature_initializer.cpp.o -MF projects/dogen.text.cpp/src/CMakeFiles/dogen.text.cpp.lib.dir/types/feature_initializer.cpp.o.d -o projects/dogen.text.cpp/src/CMakeFiles/dogen.text.cpp.lib.dir/types/feature_initializer.cpp.o -c ../../../../projects/dogen.text.cpp/src/types/feature_initializer.cpp
../../../../projects/dogen.text.cpp/src/types/feature_initializer.cpp:26:52: error: unused parameter 'rg' [-Werror,-Wunused-parameter]
register_entities(variability::helpers::registrar& rg) {
#+end_quote

We could perhaps issue a dogen warning for the absence of features but
the code should compile.

*** Move all text transforms in c++ and c# models into text model     :story:

- rename namespaces to fit the hierarchy of LPS.

Merged stories:

*Merge C++ and C# model into =m2t=*

Once we remove all of formatables and helpers from each technical
space and once we remove all of the transforms in =m2t= that don't
really belong there, we can probably merge all of these models into
one. We would then have a =transforms= namespace, with sub-namespaces
per language. Each of the namespaces is declared as a backend.

*** Deprecate managed directories                                     :story:

There should only be one "managed directory" at the input stage, which
is the component directory (for component models). If parts have
relative directories off of the component directory then we should add
to the list of managed directories inside the PM pipeline.

*** Consider renaming =text= to =logical_physical=                    :story:

This is really the right name for the model; the text processing part
are the transforms that are done on the model.

Notes:

- rename =logical_physical_region= to just =region=.

*** Rename "model-to-X" to TLAs                                       :story:

Given that model-to-text (M2T) and text-to-model (T2M) - to a lesser
extent - are well known TLAs in MDE we should make use of these in
class names. The names we have at present are very long. The
additional size is not providing any benefits.

*** Remove wale instantiation from stitch                             :story:

Though we've split wale out of stitch in the logical model, its still
possible to instantiate a wale template within stitch. We should
remove this as well.

** Deprecated
*** CANCELLED Colouring script should be included as part of package  :story:
    CLOSED: [2020-11-07 Sat 15:03]

*Rationale*: we won't be needing this once we move away from Dia.

Users should be able to make use of script as well. We need a tools
folder in share.

*** CANCELLED Consider generating the colour script                   :story:
    CLOSED: [2020-11-07 Sat 15:04]

*Rationale*: we won't be needing this once we move away from Dia.

At present we have to manually update the colour script every time we
add a new modeling element. In an ideal world, we should associate the
colour with the modeling element and/or profile as part of the model
itself. Dogen could then generate the script. Even more ideal would be
if the script could include the "package" version of the script -
e.g. run the MASD script first then run the local one. This requires a
little bit of thinking because the script would be generated from the
profiles and the profiles model is not expressed as code.

A simpler version of this is to just go through the dia palette models
and associate stereotypes with colours. Then use it to build the
script. The user supplies one or more models as input. It would be a
new "command" in dogen.

Actually we should just create a meta-element for the colouring
script. It is populated by looking at the static properties of each
meta-element (once they are modeled correctly). If [[*Add support for "colour themes" to dogen][there are themes]],
we should make it a function that takes in an argument with the theme
name. Note also that we should take into account user-defined
colouring schemes. This is mainly associated with profiles. For this
we just need to have a colour property in the profile and use it in
exactly the same fashion as we do for meta-elements. For good measure,
once we start [[*Colouring script should be included as part of package][distributing the colouring script with dogen]], we can
simply call the main script from the user script.

Links:

- [[https://seaborn.pydata.org/tutorial/color_palettes.html][seaborn: Choosing color palettes]]
- [[https://seaborn.pydata.org/installing.html][seaborn: Installing and getting started]]
- [[https://stackoverflow.com/questions/38249454/extract-rgb-or-6-digit-code-from-seaborn-palette][SO: Extract RGB or 6 digit code from Seaborn palette]]
