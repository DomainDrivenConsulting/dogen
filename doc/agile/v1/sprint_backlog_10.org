#+title: Sprint Backlog 10
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Finish addressing build issues; key thing is to get the tests
  working again across the board.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2018-10-16 Tue 09:41]
| <75>                                                                        |         |       |      |       |
| Headline                                                                    | Time    |       |      |     % |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| *Total time*                                                                | *11:41* |       |      |   0.0 |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| Stories                                                                     | 11:41   |       |      |   0.0 |
| Active                                                                      |         | 11:41 |      |   0.0 |
| Edit release notes for previous sprint                                      |         |       | 1:05 |   0.0 |
| Sprint and product backlog grooming                                         |         |       | 0:10 |   0.0 |
| Create a document with release steps                                        |         |       | 0:11 |   0.0 |
| Add vcpkg support to osx builds                                             |         |       | 4:46 |   0.0 |
| Add support for kcov                                                        |         |       | 3:09 |   0.0 |
| High-level model thoughts                                                   |         |       | 2:20 |   0.0 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2018-10-15 Mon 11:22]
    :LOGBOOK:
    CLOCK: [2018-10-15 Mon 11:35]--[2018-10-15 Mon 11:54] =>  0:19
    CLOCK: [2018-10-15 Mon 10:36]--[2018-10-15 Mon 11:22] =>  0:46
    :END:

Add github release notes for previous sprint.

Title: Dogen v1.0.09, "Kubata"

#+begin_src markdown
![Kubata](http://www.africavernaculararchitecture.com/wp-content/uploads/2015/03/Angola-Flickr-Rob-and-Sophie55061521f2fff.jpg) _Traditional Angolan village house. [(C) Rob and Sophie](http://www.africavernaculararchitecture.com/angola/)_.

# Overview

As described on [the previous sprint](https://github.com/MASD-Project/dogen/releases/tag/v1.0.08), the key objective at present is to get all the infrastructure up-to-date after a hiatus of a year or so of development. This is a requirement so that we can move to C++ 17 and start to make use of all the nice new libraries available. As such, this sprint was entirely taken with infrastructure clean up. Whilst these changes are not user visible, they still provide important benefits to project development so we'll briefly summarise them here.

## MASD Project Transition

We have started to sync up the work on the PhD with the work on Dogen. This sprint, the main focus was on creating an organisation solely for _Model Assisted Software Development_ (more details on that in the future), and moving all of the infrastructure to match - [Bintray](https://bintray.com/masd-project/main/dogen), [Travis](https://travis-ci.org/MASD-Project/dogen/builds), [Gitter](https://gitter.im/MASD-Project/Lobby) and the like.

## Move to vcpkg

Historically, we've always had a problem in keeping dogen's dependencies up-to-date across the three supported platforms. The problem stems from a lack of a cross-platform package manager in C++. Whilst we tried [Conan](https://conan.io/) in the past, we never managed to get it working properly for our setup. With this sprint we started the move towards using [vcpkg](https://vcpkg.readthedocs.io/en/latest/).

Whilst it still has some deficiencies, it addresses our use case particularly well and will allow us to pick up new dependencies fairly easily going forward. This is crucial as we expand the number of facets available, which hopefully will happen over the next couple of months. In this sprint we have completed the transition to vcpkg for Linux and Windows; the next sprint will be OSX's turn. With the introduction of vcpkg we took the opportunity to upgrade to [boost 1.68](https://www.boost.org/users/history/version_1_68_0.html) on Linux and Windows.

## Add CDash support

Since we moved away from our own infrastructure we lost the ability to know which tests are passing and how long test execution is taking. With this sprint we resurrected CDash/CTest support, with a new dashboard, available [here](https://my.cdash.org/index.php?project=MASD+Project+-+Dogen). There are still a few tweaks required - a lot of tests are still failing due to setup issues - but its clearly a win as we can now see a clearer picture across the testing landscape.

## Move reference models out of Dogen's repository

For a long time we've been struggling to build Dogen within the hour given to us by Travis. An easy win was to move the reference models ([C++](https://github.com/MASD-Project/cpp_ref_impl) and [C#](https://github.com/MASD-Project/csharp_ref_impl)) away from the main repository. This is also a very logical thing to do as we want these to be examples of stand-alone Dogen products, so that we can point them out to users as an example of how to use the product. Work still remains to be done on the reference implementations (CTest/CDash integration, clean up tests) but the bulk has been done this sprint.

For more details of the work carried out this sprint, see [the sprint log](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_09.org).

# User visible changes

Two tiny featurelets were added this sprint:

- **Development Binaries**: We now generate binaries for development releases. These are overwritten with every commit on BinTray.
- **Improvements on ```--version```**: The command now outputs build information to link it back to the build agent and build number. Note that these details are used only for information purposes. We will add GPG signatures in the future to validate the binaries.

```
$ dogen.knitter  --version
Dogen Knitter v1.0.09
Copyright (C) 2015-2017 Domain Driven Consulting Plc.
Copyright (C) 2012-2015 Marco Craveiro.
License: GPLv3 - GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>.
Build: Provider = 'travis' Number = '2082' Commit = '53a1a169bd6f15c4388add9da933be2a353c4cbf' Timestamp = '2018/10/14 21:54:46'
IMPORTANT: build details are NOT for security purposes.
```

# Next Sprint

Infrastructural work will hopefully conclude on the next sprint, but the next big task is getting all the tests to run and pass.

# Binaries

You can download binaries from [Bintray](https://bintray.com/masd-project/main/dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_1.0.09_amd64-applications.deb](https://dl.bintray.com/masd-project/main/1.0.09/:dogen_1.0.09_amd64-applications.deb)
- [dogen-1.0.09-Darwin-x86_64.dmg](https://dl.bintray.com/masd-project/main/1.0.09/:dogen-1.0.09-Darwin-x86_64.dmg)
- [dogen-1.0.09-Windows-AMD64.msi](https://dl.bintray.com/masd-project/main/:dogen-1.0.09-Windows-AMD64.msi)

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/1051785972206247936][Tweet]]
- [[https://www.linkedin.com/feed/update/urn:li:activity:6457553749215899648/][LinkedIn]]
- [[https://gitter.im/MASD-Project/Lobby][Gitter]]

*** STARTED Sprint and product backlog grooming                       :story:
    :LOGBOOK:
    CLOCK: [2018-10-15 Mon 10:25]--[2018-10-15 Mon 10:35] =>  0:10
    :END:

Updates to sprint and product backlog.

*** COMPLETED Create a document with release steps                    :story:
    CLOSED: [2018-10-15 Mon 11:34]
    :LOGBOOK:
    CLOCK: [2018-10-15 Mon 11:23]--[2018-10-15 Mon 11:34] =>  0:11
    :END:

We seem to now have a number of steps when releasing. Create a project
document for this.

*** STARTED Add vcpkg support to osx builds                           :story:
    :LOGBOOK:
    CLOCK: [2018-10-16 Tue 09:28]--[2018-10-16 Tue 09:38] =>  0:10
    CLOCK: [2018-10-15 Mon 22:50]--[2018-10-15 Mon 23:20] =>  0:30
    CLOCK: [2018-10-15 Mon 17:58]--[2018-10-15 Mon 18:05] =>  0:07
    CLOCK: [2018-10-15 Mon 16:30]--[2018-10-15 Mon 17:29] =>  0:59
    CLOCK: [2018-10-15 Mon 12:47]--[2018-10-15 Mon 15:31] =>  2:44
    CLOCK: [2018-10-15 Mon 11:54]--[2018-10-15 Mon 12:10] =>  0:16
    :END:

Following on from our investigation, we need to add vcpkg to the
travis osx builds (clang). While we're there, update all the tools to
latest in preparation to switching to C++ 17.

Notes:

- it seems its not possible to move to XCode 10 without upgrading the
  OS. This includes the Command Line tools only package as well.
- an alternative is to install the LLVM + clang package supplied by
  the LLVM project. The disadvantage is that we probably also need to
  use this in travis because using two different versions of clang is
  probably not the best idea. We could try and see what happens first,
  but ultimately we'll end up having to install it on travis. The
  binary is 300 MB, which is not ideal but should be ok.
- vcpkg misbehaves a bit when used from clang7. [[https://github.com/Microsoft/vcpkg/issues/4476][Reported]] to
  mothership.

*** STARTED Add support for kcov                                      :story:
    :LOGBOOK:
    CLOCK: [2018-10-16 Tue 09:39]--[2018-10-16 Tue 09:41] =>  0:02
    CLOCK: [2018-10-15 Mon 22:50]--[2018-10-15 Mon 23:20] =>  0:30
    CLOCK: [2018-10-15 Mon 19:01]--[2018-10-15 Mon 19:39] =>  0:38
    CLOCK: [2018-10-15 Mon 17:58]--[2018-10-15 Mon 18:34] =>  0:36
    CLOCK: [2018-10-15 Mon 17:51]--[2018-10-15 Mon 17:57] =>  0:06
    CLOCK: [2018-10-15 Mon 17:30]--[2018-10-15 Mon 17:50] =>  0:20
    CLOCK: [2018-10-15 Mon 16:05]--[2018-10-15 Mon 16:29] =>  0:24
    CLOCK: [2018-10-15 Mon 15:31]--[2018-10-15 Mon 16:04] =>  0:33
    :END:

Try to see how hard it is to integrate kcov with the current build.

Notes:

- annoyingly, kcov has some binary dependencies rather than being a
  stand alone binary:

: apt-get install libcurl4-openssl-dev zlib1g-dev libdw-dev libiberty-dev

  as we could not figure out how to install just the SO's in travis,
  we ended up installing the dev packages. These are a lot more than
  what is actually required, but it'll do for now.
- we seem to upload to coveralls, but nothing shows up on the
  site. Try to manually generate coverage first.

*** High-level model thoughts                                         :story:
    :LOGBOOK:
    CLOCK: [2018-10-11 Thu 16:06]--[2018-10-11 Thu 18:26] =>  2:20
    :END:

Jot down ideas on the separation between the API and the
implementation in dogen products.

Notes:

- we now have the notion of "distribution channels": UI/UX (wt, qt, gtk
  mobile, etc), DX (swagger, boost asio, library itself).
- the product API should not have any dependencies in terms of storage
  mechanisms; it should have some kind of "model source" interface
  that can then be implemented in terms of the filesystem, GH repo,
  postgres database etc.
- even though it does not make a lot of sense to have a model source
  as part of the remoting API, for consistency reasons we should still
  support it. That is, a code generation end point will merely call
  some internal functions to source the models rather than call
  another endpoint, and users probably don't really need something
  that just reads a model and returns the injector version.
- the distribution channels are a function of the product API.

*** Windows MSI is very large                                         :story:

Package went from 5 MB to 80 MB over the last 3 days. The cause for
this appears to be that we started including tests on the standard
package.

*** Ignore all failing tests                                          :story:

At present we have a number of tests that are commented out but appear
as failing under cdash. This is very confusing. We need to mark them
with the ignore macro. We should not waste time fixing the tests as
they need to be re-written using the diff framework.

*** Rename debian package                                             :story:

At present our package is called =dogen-applcations=. Since there will
only be one dogen application/package, this is a confusion name. We
should rename it. Names:

- masd-dogen

*** Finish adding support for clang-cl builds                         :story:

We have added preliminary support for building with clang-cl on
windows, but the build is not green. Most of the errors seem to be on
boost.

Links:

- [[https://ci.appveyor.com/project/mcraveiro/dogen/builds/19463961/job/6bnv6ppljlklu2ag][Release build]]
- [[https://ci.appveyor.com/project/mcraveiro/dogen/builds/19463961/job/45yhn8sdhexvsdmi][Debug build]]
- [[https://github.com/Kitware/CDash/issues/733][CDash reporting problems]]

*** Tidy-up dogen windows package                                     :story:

There are a few inconsistencies with the package:

- dogen components have a strange structure:
  "Dogen/runtime/dogen".
- we should probably have a top-level umbrella for MASD, under which
  dogen installs.
- package name is windows amd64. We should use the vcpkg triplets for
  simplicity (e.g. x64-windows).

*** Mapping of third-party dependencies                               :story:

System models should follow the physical structure of
dependencies. That is, we should not have a "boost" system model, but
instead a boost-test etc. Each of these can then have mappings
(e.g. vcpkg name, build2 name, etc). Users must declare these
references just like they do with user models. Dogen can then create
code for:

- cmake targets, properly linking against libraries;
- vcpkg install, at product level, by de-duplicating component
  dependencies;
- possibly distro dependencies.

We should only have a mandatory dependency, which is the STL. In
addition, we need different models for each version (e.g. c++ 03,
etc). This makes it easier to include the right types.

Note that each model must have an associated version. The version
should be part of the file name. However, maybe we need to distinguish
between TS version (11, 17, etc) from library version.

*** Upgrade to c++ 17                                                 :story:

There are quite a few dependencies for this to happen:

- on windows we need to somehow include =/std:c++latest=
- we need to move to latest boost as it seems Boost 1.62 breaks on c++
  17. We should wait until Beast is included in Boost before we do
  this.
- we need to install latest CMake, which is not available on nuget; so
  we need to fetch the zip/msi from https://cmake.org/files/v3.10/ and
  unpack it. Only latest supports VS 2017. Then set the CMake
  generator:

:    $generator="Visual Studio 15 2017 Win64";

- set the appveyor image:

: image:
:  - Visual Studio 2017

- set the CMake version:

:     set(CMAKE_CXX_STANDARD 14)

*** Rename input models directory to models                           :story:

We need to move the dogen project to the new directory layout whereby
all models are kept in the =models= directory.

*** Add basic "diff mode"                                             :story:

We need a very simple way of checking all generated files in memory
against what's in the file system and returning a flag if they are
different. We can then use these flags to determine if tests pass. In
the future we can extend this approach to include a proper diff of the
files, but for now we just need a reliable way to run system tests
again.

Actually the right solution for this is to see the processing as part
of a chain:

- out of the generator come a set of artefacts with operations (write,
  merge, ignore)
- these get joined with a transform that reads the state of the file
  system. It then adds more operations: delete, etc. If there are no
  diffs, it marks those files as skip.
- the final step is a processor which gets that model and executes the
  operations. This can then be replaced by a "reporter" that simply
  states what the operations would be.

Diff mode is using the report to see if there are any diffs.

*** dogen as a github integration                                     :story:

Perhaps there are some useful services dogen could provide to users in
terms of dogen integration. If, with every commit, we could regenerate
the model and read the current state in github, we could then provide
a status report:

- the model does not build; red emblem. Some changes were made to the
  model (or to dogen) that make the model invalid. User should take
  action.
- the model builds but generates files that are different from what's
  checked in on github. yellow emblem. Provide a report with the
  diffs. This can either be because the code generator has changed or
  the user changed the model.
- the model builds and generates exactly the same code; green emblem.

With this approach we have two advantages:

- we do not need to add projects as part of the dogen tests; the
  service takes its place. We can still add a few as the core tests,
  but we don't need to expand it much beyond reference implementation
  and dogen itself.
- we exercise dogen itself as well as the rest endpoint generation
  code in a way that is actually useful to end users; it would be nice
  to know immediately when something breaks.

Notes:

- we'll need some kind of way of dealing with tokens and secrets in
  order to support private GH projects.

*** Add reporting support to dogen model testing                      :story:

Dogen should have a mode which generates a report for a run rather
than code generate. The report could look like so:

:              /project_a
:                  /summary for this commit
:                  /diffs
:                  /errors
:                  /benchmark data
:                  /probing data
:                  /log

If the report was largely in HTML we could link it to the dogen docs
and save it into git. This would make troubleshooting much easier. If
the report contains the probing data it would be easier to figure out
what went wrong. We should also keep track of the model that was
generated (e.g. its location and git commit) so we can download it and
reproduce it locally.

*** Rework the tests using diff mode                                  :story:

Once we have diff mode, we need to find some kind of workflow for
tests:

- each product is composed of a git URL and a list of models.
- we git clone all repos as part of the build process.
- directories and model locations are hard-coded in each test.
- test runs against the model and hard-coded location, produces the
  diff. Test asserts of the diff being non-zero.

*** Fix the northwind model                                           :story:

There are numerous problems with this model:

- at present we have oracle support on ODB. Oracle libs are not
  distributed with debian. If we do not find oracle we do not compile
  northwind. This is not ideal. We should remove oracle support from
  northwind, and install odb support in the build machine (hopefully
  available as debs).
- the tests are commented out and require a clean up.
- the tests require a database to be up.

Notes:

- it is possible to setup [[https://docs.travis-ci.com/user/database-setup/#postgresql][postgres on travis]]

*** Simplify split configuration configuration                        :story:

At present we have two separate command line parameters to configure
the main output directory and the directory for header files. The
second parameter is used for split configurations. The problem is that
we now need to treat split configuration projects specially because of
this. It makes more sense to force the header directory to be relative
to the output path and make it a meta-data parameter.

*** Update all stereotypes to masd                                    :story:

We need to start distinguishing MASD from dogen. The profile for UML
is part of MASD rather than dogen, so we should update all stereotypes
to match. We need to make a decision regarding the "dia extensions" -
its not clear if its MASD or dogen.

*** Make "ignore regexes" a model property                            :story:

At present we have a command line option:
=--ignore-files-matching-regex=. It is used to ignore files in a
project. However, the problem is, because it is a command line option,
it must be supplied with each invocation of Dogen. This means that if
we want to run dogen from outside the build system, we need to know
what options were set in the build scripts or else we will have
different results. This is a problem for testing. We should make it a
meta-data option, which is supplied with each model and even more
interesting, can be used with profiling. This means we can create
profiles for specific purposes (ODB, lisp, etc) and then reuse them in
different projects.

*** Incorrect generation when changing external modules               :story:

When fixing the C# projects, we updated the external modules, from
=dogen::test_models= to =CSharpRefImpl=. Regenerating the model
resulted in updated project files but the rest of the code did not
change. It worked by using =-f=. It should have worked without forcing
the write.

*** Code coverage does not work for C#                                :story:

It seems that using NUnit and OpenCov does not work. The main reason
appears to be the use of shadow copying, which is no longer optional
on NUnit 3.

Links:

- https://github.com/Ullink/gradle-opencover-plugin/issues/1
- https://github.com/codecov/example-csharp/blob/master/appveyor.yml
- https://www.appveyor.com/blog/2017/03/17/codecov/

*** Improve comments on reference implementation                      :story:

At present it is very difficult to understand what each model and/or
each type does in the reference implementations. We need to add some
comments to make it more obvious.

*** Code generate C# models using msbuild                             :story:

At present we did a quick hack to code generate in C#: a simple bash
script that runs dogen. However, this is not how we expect the end
user to consume it; there should be a msbuild target that:

- detects the code generator;
- contains the configuration (e.g. options, location of models);'
- runs the code generator - possibly every time models change;
- has a tailor target to generate JSON.

*** Add project documentation                                         :story:

We should be able to create a simple set of docs following on from the
[[https://ned14.github.io/outcome/][outcome project]]. They seem to be using Hugo.

Links:

- https://github.com/foonathan/standardese
- https://github.com/ned14/outcome/tree/develop/doc/src

*** Create the =generation= model                                     :story:

Create a new model called =generation= and move all code-generation
related class to it.

We need to create classes for element properties and make model have a
collection that is a pair of element and element properties. We need a
good name for this pair:

- extended element
- augmented element
- decorated element: though not using the decorator pattern; also, we
  already have decoration properties so this is confusing.

Alternatively we could just call it =element= and make it contain a
modeling element.

Approach:

- create a new generation model, copying across all of the meta-model
  and transform classes from yarn. Get the model to transform from
  endomodel to generation model.
- augment formattables with the new element properties. Supply this
  data via the context or assistant.

Problems:

- all of the transforms assume access to the modeling element means
  access to the generation properties. However, with the introduction
  of the generation element we now have a disconnect. For example, we
  sometimes sort and bucket the elements, and then modify them; this
  no longer works with generation elements because these are not
  pointers. It would be easier to make the generation properties a
  part of the element. This is an ongoing discussion we've had since
  the days of formattables. However, in formattables we did write all
  of the transforms to take into account the formattable contained
  both the element and the formattable properties, whereas now we need
  to update all transforms to fit this approach. This is a lot more
  work. The quick hack is to slot in the properties directly into the
  element as some kind of "opaque properties". We could create a base
  class =opaque_properties= and then have a container of these in
  element. However, to make it properly extensible, the only way is to
  make it a unordered set of pointers.
- actually the right solution for this is to use multiple
  inheritance. For each modeling element we need to create a
  corresponding generation version of it, which is the combination of
  the modeling element and a generation element base class. Them the
  generation model is made up of pointers to generation elements and
  it dispatches into generation elements descendants in the
  formatter. The key point is to preserve the distinction between
  modeling (single element) vs generation (projection across facet
  space).

*** Create a =ci= folder in build                                     :story:

We should use the same approach as nupic for organising the scripts: a
top-level =ci= folder with folders per CI system. We should also
follow their naming convention for the build scripts which seem to
follow the CI events.

Links:

- https://github.com/numenta/nupic.core/tree/master/ci

** Deprecated
*** CANCELLED Split dogen testing from core                           :story:
    CLOSED: [2018-10-05 Fri 15:33]

*Rationale*: this story was cleaned up and split into several stories.

At present we have tests in modeling that perform "code generation";
that is, regenerate all dogen test models from JSON and Dia. These are
boost unit tests. Due to this, we have welded the test models with the
core models, which means that we cannot easily separate repos without
a lot of hacks. However, if we were to generalise the problem: there
is no reason why test models should be coupled with the core or
treated specially; they are just an instance of a project with dogen
models which can be used to validate dogen. A better approach is to
move all this work to "system testing", done using the dogen binary
rather than within unit tests. This would work as follows:

- add a mode in dogen called "validation mode" or diagnostics, etc. In
  this mode, dogen does not write files to the file system but instead
  produces a number of "reports":
  - a list of all validation errors, if any, in GCC format, pointing
    to the original models.
  - a set of diff files with all the differences, if any.
  - a benchmark report.
  - a top-level report with the project name, its git repo and the git
    commit.
- projects that wish to help dogen must have a well-defined target to
  generate the reports for all models under test.
- dogen project contains a script with a list of such projects and
  their git repos. Every time we build dogen core we install the
  package into the travis VM and run the reports.
- a environment variable containing the path into which to write the
  reports must be set before running dogen.
- a git repo is created with all the reports, and a structure as
  follows:
  /repo
      /branch
          /dogen_commit
              /summary for this commit
              /project_a
                  /summary for this commit
                  /diffs
                  /errors
                  /benchmark data
              /project_b
 ...
- to avoid clashes, make the branches named after the build,
  e.g. travis osx etc.
- git clones are shallow (1 commit)
- once all reports are generated into the git report repo, the build
  commits the report. The comment is the dogen commit.
- a travis build is triggered on the back of the commit. It checks the
  latest commit. If the report is a pass the build is green, if its a
  fail the build is red.
- in an ideal world the system tests build is separate from the dogen
  core build, and triggered from a bintray upload. However, as we do
  not know how to do this yet, we can just run the system tests at the
  end of the dogen build.
- we should split the reporting work from the build separation. We
  could have a simple build that just fails if there are any diffs to
  start off with and worry about reporting later.

With this approach we can have any number of projects contributing to
validate dogen (including dogen itself). The only slight downside is
that the models must always be up-to-date (e.g. if the user has
changed the model but not regenerated, system tests will
fail). Perhaps we could have different categories of test models:
mandatory and optional. Mandatory must pass, optional do not
contribute to the build failing. However, they still show up in the
report.

Links:

- https://github.com/cubicdaiya/dtl


*** CANCELLED Create a build script just for C#                       :story:
    CLOSED: [2018-10-04 Thu 17:50]

*Rationale*: no longer needed after the split of reference models.

At the moment we are doing C++ and C# on the same build script, making
it really complex. It would be much easier to have a separate C# build
script. We should also have a separate install script for C# so we
don't have to waste time installing packages if we're not going to use
them.

*** CANCELLED Create a new exoelement chain                           :story:
    CLOSED: [2018-10-04 Thu 17:54]

*Rationale*: given the amount of churn the refactor stories have had,
this story is no longer relevant.

We need to create a new exoelement chain that uses the new exoelements
to bootstrap a endomodel.

*** CANCELLED Start documenting the theoretical aspects of Dogen      :story:
    CLOSED: [2018-10-05 Fri 10:28]

*Rationale*: this will be taken care of by the thesis.

Up to now we have more or less coded Dogen as we went along; we
haven't really spent a lot of time worrying about the theory behind
the work we were carrying out. However, as we reached v1.0, the theory
took center stage. We cannot proceed to the next phase of the product
without a firm grasp of the theory. This story is a starting point so
we can decide on how to break up the work.

*** CANCELLED Sections to add to manual                               :story:
    CLOSED: [2018-10-05 Fri 10:29]

*Rationale*: this will be taken care of by the thesis.

Random list of things that we need to have in manual:

- Drivers/frontends: The importance of drivers to allow existing
  frameworks to interoperate; eCore, MSVC, Dia, JSON.  Structural
  variability at modeling level. Dia frontend: use of colours,
  validation (checking of stereotypes), "on the impact of layout
  quality to understanding UML diagrams", this constrains the size of
  a model.
- Stitch. Variability regions vs aspects (Oberweis paper "modeling
  variability in template-based code generators"). Why we need both
  feature modeling and variability regions / aspects: because features
  are a high-level concept that is implemented using variability
  regions. We need to map layers to facets and to our generation
  model. Dependencies between features and variability regions.
- External integration and its importance, cartridges. integration
  with Clang, ODB, XML tool.
- Agile and MDD: tight integration. Lightweight MDD with agile

*** CANCELLED Use the in-memory interface of LibXml                   :story:
    CLOSED: [2018-10-05 Fri 10:30]

*Rationale*: we should just drop libxml altogether and use XSD tool.

At present, our C++ wrappers on top of LibXml are using the file based
interface. We should do in-memory processing of the XML file. Once
this is in place, we can change the exogenous transformers to use
strings rather than paths to files.

*** CANCELLED Consider simplifying frontend testing                   :story:
    CLOSED: [2018-10-05 Fri 11:01]

*Rationale*: this will be resolved with the new diff based tests.

At present we are outputting code for every supported frontend, and
then checking they are binary identical. This is fine given that we
only have two frontends. Once we had a visual studio frontend, it may
make more sense to stop generating code for all frontends and simply
diff the middle-end to ensure we generate an identical yarn model. We
can continue to test end to end one of the frontends (dia).

We had command line options available in the past that generated only
a merged model. We need to look into the backlog for these.

This is a problem specially in light of adding new backends because
now we are code-generating the cross product of frontends and
backends.

*** CANCELLED Update dynamic section in manual                        :story:
    CLOSED: [2018-10-05 Fri 11:08]

*Rationale*: this will be taken care of by the thesis.

We need to talk about the new fields, field templates, etc.

*** CANCELLED Some test models do not build on run all specs          :story:
    CLOSED: [2018-10-05 Fri 11:09]

*Rationale*: should no longer be a problem after the repo splitting.

For some reason we are not building some of the test models when doing
a run all specs, in particular:

- exception
- comments

this may be because we have no specs for them. We need to find a way
to build them somehow.

Merged stories:

*Add test model sanitizer to test models target*

At present if we build test models we don't seem to build the
sanitizer.

*** CANCELLED C++ workflow should perform a consistency check         :story:
    CLOSED: [2018-10-05 Fri 11:11]

*Rationale*: this will no longer be required when we implement proper
feature model support.

We should ensure that all facets and formatters available in the
registrar have corresponding field definitions and vice-versa. This
was originally to be done by some kind of "feature graph" class, but
since we need to use this data for other purposes, the main workflow
could take on this responsibility - or we could create some kind of
"validator" class to which the workflow delegates.

*** CANCELLED Implement module expander test                          :story:
    CLOSED: [2018-10-05 Fri 11:14]

*Rationale*: code has changed quite a bit since then.

We copied across the code for the module expander test from yarn json
but didn't actually finished implementing it.

*** CANCELLED Consider using the same API as boost property tree in selector :story:
    CLOSED: [2018-10-05 Fri 11:14]

*Rationale*: no longer required once we have proper feature support.

At present we have the type of the value in the method names in the
selector, e.g. =get_text_content=. It would be better to have a =get=
that takes in a template parameter, e.g. =get<text>=. However, in
order to do this we need to have some kind of mapping between the
schema value (=text=) and the raw value (=std::string=). This requires
some template magic.

Once this is done we can also make the API a bit more like the
property tree API such as for example returning =boost::optional= for
the cases where the field may not exist.

We have started introducing =try_select...=. This was preferred to
=get_optional= because we are not getting an optional but instead
trying to get.

*** CANCELLED Add dynamic consistency validation                      :story:
    CLOSED: [2018-10-05 Fri 11:15]

*Rationale*: no longer required once we have proper feature support.

We need to check that the default values supplied for a field are
consistent with the field's type. This could be done with a
=validate()= method in workflow.

Actually since we can only create fields from JSON, we should just add
a check there.

*** CANCELLED Update manual with detailed model descriptions           :epic:
    CLOSED: [2018-10-05 Fri 11:18]

*Rationale*: this will be taken care of by the thesis.

#+begin_quote
*Story*: As a dogen developer, I want to read about the architecture
of the application so that I don't have to spend a lot of time trying
to understand the source code.
#+end_quote

We should add CRCs for the main classes, with an explanation of what
each class does; we should also explain the separation of the
transformation logic between the core model (e.g. =dia=) and the
transformation model (e.g. =dia_to_sml=). We should describe what the
workflow does in each model.

We should only implement this story when all of the major refactoring
has been done.

*** CANCELLED Add tests for general settings factory                  :story:
    CLOSED: [2018-10-05 Fri 11:21]

*Rationale*: once these become part of the meta-model, most of these
won't make any sense.

Some simple tests come to mind:

- empty data files directory results in empty factory;
- valid data files directory results in non-empty factory;
- invalid data files directory results in exception;
- more than one data files directory results in expected load;
- creating annotation for test model types works as expected.
- missing fields result in expected exceptions.

*** CANCELLED Add tests for =general_settings_factory=                :story:
    CLOSED: [2018-10-05 Fri 11:21]

*Rationale*: once these become part of the meta-model, most of these
won't make any sense.

Tests:

- missing licence
- missing modeline
- empty marker
- different marker for two objects
- consider moving generate preamble into annotation
