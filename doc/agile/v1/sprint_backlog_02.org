#+title: Sprint Backlog 02
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Continue work on the yarn refactor

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2017-07-14 Fri 12:43]
| <75>                                                                        |         |       |      |       |
| Headline                                                                    | Time    |       |      |     % |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| *Total time*                                                                | *37:35* |       |      | 100.0 |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| Stories                                                                     | 37:35   |       |      | 100.0 |
| Active                                                                      |         | 37:35 |      | 100.0 |
| STARTED Sprint and product backlog grooming                                 |         |       | 1:07 |   3.0 |
| COMPLETED Edit release notes for previous sprint                            |         |       | 0:24 |   1.1 |
| COMPLETED Implement the context class                                       |         |       | 1:12 |   3.2 |
| COMPLETED Implement the exogenous transformation chain                      |         |       | 4:11 |  11.1 |
| COMPLETED Implement the pre-processing chain                                |         |       | 1:35 |   4.2 |
| COMPLETED Refactor mapping repository factory                               |         |       | 0:12 |   0.5 |
| COMPLETED Implement the output languages transform                          |         |       | 0:37 |   1.6 |
| COMPLETED Use forward declaration for context                               |         |       | 0:20 |   0.9 |
| COMPLETED Implement the references chain                                    |         |       | 2:43 |   7.2 |
| COMPLETED Implement the merge transform                                     |         |       | 0:40 |   1.8 |
| COMPLETED Implement the model generation chain                              |         |       | 0:13 |   0.6 |
| COMPLETED Implement the model assembly chain                                |         |       | 0:50 |   2.2 |
| COMPLETED Implement the post-processing chain                               |         |       | 3:31 |   9.4 |
| COMPLETED Move helpers from =transforms= namespace                          |         |       | 0:45 |   2.0 |
| COMPLETED Replace expanders with transforms                                 |         |       | 0:03 |   0.1 |
| COMPLETED Port all expander unit tests to transforms                        |         |       | 0:42 |   1.9 |
| COMPLETED Remove all legacy classes from yarn                               |         |       | 0:55 |   2.4 |
| COMPLETED Implement the mapper as a transform                               |         |       | 0:46 |   2.0 |
| COMPLETED Move helpers from main yarn namespace                             |         |       | 1:29 |   3.9 |
| COMPLETED Move all data types into its own namespace                        |         |       | 9:00 |  23.9 |
| CANCELLED Move artefacts from formatters into meta-model                    |         |       | 0:54 |   2.4 |
| CANCELLED Use transformation context in quilt                               |         |       | 0:20 |   0.9 |
| COMPLETED Create an options validator                                       |         |       | 0:39 |   1.7 |
| STARTED Implement the code-generation chain                                 |         |       | 4:27 |  11.8 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2017-07-14 Fri 12:04]--[2017-07-14 Fri 12:23] =>  0:19
    CLOCK: [2017-07-08 Sat 17:16]--[2017-07-08 Sat 17:19] =>  0:03
    CLOCK: [2017-07-07 Fri 11:18]--[2017-07-07 Fri 11:23] =>  0:05
    CLOCK: [2017-07-03 Thu 20:15]--[2017-07-03 Thu 20:55] =>  0:40

Updates to sprint and product backlog.

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2017-07-05 Wed 16:08]
    CLOCK: [2017-07-03 Thu 20:56]--[2017-07-03 Thu 21:20] =>  0:24

Add github release notes for previous sprint.

Title: Dogen v1.0.01, "Academia de Pesca"

#+begin_src markdown
![Academia de Pesca](http://cdn1.portalangop.co.ao/angola/pt_pt/files/highlight/2015/10/45/0,6bd49eb1-adcc-40fd-93c8-257b4d4aae16.jpg)
_Academia de Pesca, Namibe. (C) Angola Press._

Overview
=======

This was an extremely quiet and long sprint, mainly focused on reading the literature on Model Driven Engineering.

User visible changes
===============
In this sprint, a couple of minor user visible features were added:

- **Emacs mode for stitch**: we now have syntax highlighting in emacs for stitch templates.

For more details of the work carried out this sprint, see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/v1/sprint_backlog_01.org).

Next Sprint
===========
In the next sprint we'll continue to work on cleaning up yarn's internals.

Binaries
======
You can download experimental binaries from [Bintray](https://bintray.com/domaindrivenconsulting/Dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_1.0.01_amd64-applications.deb](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.01/dogen_1.0.01_amd64-applications.deb)
- [dogen-1.0.01-Darwin-x86_64.dmg](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.01/dogen-1.0.01-Darwin-x86_64.dmg)
- [dogen-1.0.01-Windows-AMD64.msi](https://dl.bintray.com/domaindrivenconsulting/Dogen/dogen-1.0.01-Windows-AMD64.msi)

**Note**: They are produced by CI so they may not yet be ready.

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/881860977330880512][Tweet]]
- [[https://www.linkedin.com/feed/update/urn:li:activity:6287627272706891776/][LinkedIn]]

*** COMPLETED Implement the context class                             :story:
    CLOSED: [2017-07-06 Thu 07:25]
    CLOCK: [2017-07-06 Thu 06:53]--[2017-07-06 Thu 07:25] =>  0:32
    CLOCK: [2017-07-04 Tue 08:03]--[2017-07-04 Tue 08:43] =>  0:40

Tasks:

- create the transformation context, populate it with all the main
  objects needed by yarn at present.
- Add a method to generate the context and then unpack it to fit the
  current API.

*** COMPLETED Implement the exogenous transformation chain            :story:
    CLOSED: [2017-07-07 Fri 12:39]
    CLOCK: [2017-07-07 Fri 12:38]--[2017-07-07 Fri 12:41] =>  0:03
    CLOCK: [2017-07-07 Fri 12:27]--[2017-07-07 Fri 12:37] =>  0:10
    CLOCK: [2017-07-07 Fri 12:09]--[2017-07-07 Fri 12:26] =>  0:17
    CLOCK: [2017-07-07 Fri 11:48]--[2017-07-07 Fri 12:08] =>  0:20
    CLOCK: [2017-07-07 Fri 11:23]--[2017-07-07 Fri 11:47] =>  0:24
    CLOCK: [2017-07-07 Fri 11:03]--[2017-07-07 Fri 11:17] =>  0:14
    CLOCK: [2017-07-07 Fri 09:01]--[2017-07-07 Fri 11:02] =>  2:01
    CLOCK: [2017-07-06 Thu 19:08]--[2017-07-06 Thu 19:30] =>  0:22
    CLOCK: [2017-07-06 Thu 18:57]--[2017-07-06 Thu 19:07] =>  0:10
    CLOCK: [2017-07-06 Thu 07:26]--[2017-07-06 Thu 07:36] =>  0:10

Tasks:

- in yarn, implement:
  - model generation chain;
  - initial target chain; and
  - exogenous transforms (registration etc).
- in the frontends: implement the exogenous transforms interface.
- update knit to conditionally use the transforms code or the legacy
  code.

*** COMPLETED Implement the pre-processing chain                      :story:
    CLOSED: [2017-07-07 Fri 14:50]
    CLOCK: [2017-07-07 Fri 14:24]--[2017-07-07 Fri 14:50] =>  0:26
    CLOCK: [2017-07-07 Fri 14:16]--[2017-07-07 Fri 14:23] =>  0:07
    CLOCK: [2017-07-07 Fri 14:01]--[2017-07-07 Fri 14:15] =>  0:14
    CLOCK: [2017-07-07 Fri 13:44]--[2017-07-07 Fri 13:51] =>  0:07
    CLOCK: [2017-07-07 Fri 13:36]--[2017-07-07 Fri 13:43] =>  0:07
    CLOCK: [2017-07-07 Fri 13:28]--[2017-07-07 Fri 13:35] =>  0:07
    CLOCK: [2017-07-07 Fri 13:19]--[2017-07-07 Fri 13:27] =>  0:08
    CLOCK: [2017-07-07 Fri 12:59]--[2017-07-07 Fri 13:18] =>  0:19

This story may be too big as one story.

Tasks:

- implement all of the transforms required by the pre-processing
  chain.
- implement the pre-processing chain in terms of those transforms.
- plug in the pre-processing chain into the initial target chain.

*** COMPLETED Refactor mapping repository factory                     :story:
    CLOSED: [2017-07-07 Fri 15:23]
    CLOCK: [2017-07-07 Fri 15:11]--[2017-07-07 Fri 15:23] =>  0:12

At present we are doing a lot of work in the intermediate model
repository factory that is mapping related. It would make more sense
to just have the mapping repository factory take on all of that work.

*** COMPLETED Implement the output languages transform                :story:
    CLOSED: [2017-07-07 Fri 15:41]
    CLOCK: [2017-07-07 Fri 15:24]--[2017-07-07 Fri 15:41] =>  0:17
    CLOCK: [2017-07-07 Fri 14:51]--[2017-07-07 Fri 15:11] =>  0:20

Tasks:

- create a transform that expands an intermediate model into a number
  of models, mapped to languages.
- update the initial target chain to perform the language expansion to
  the target.

*** COMPLETED Use forward declaration for context                     :story:
    CLOSED: [2017-07-07 Fri 21:19]
    CLOCK: [2017-07-07 Fri 20:59]--[2017-07-07 Fri 21:19] =>  0:20

We've implemented a number of transforms using context
references. Now, when we change context, we end up with a massive
rebuild. We should be able to change all of the headers to include the
forward declaration.

*** COMPLETED Implement the references chain                          :story:
    CLOSED: [2017-07-08 Sat 17:17]
    CLOCK: [2017-07-08 Sat 16:06]--[2017-07-08 Sat 17:16] =>  1:10
    CLOCK: [2017-07-08 Sat 15:15]--[2017-07-08 Sat 16:05] =>  0:37
    CLOCK: [2017-07-07 Fri 21:20]--[2017-07-07 Fri 22:03] =>  0:43

Tasks:

- implement the references expansion in the references chain.
- plug in the references chain into the model generation chain.
- consider using a multi-threaded approach. If its too hard we should
  just stick to the single-threaded implementation we have at present.

Notes:

- add a reference extractor to extract all paths
- make references chain PIM - but language must match target's. this
  won't work: target LAM, converts to C#, reference is C#; reference
  gets dropped. We need to supply all of the languages (input and
  output) and if there is a match, we need to keep the reference.
- handle PSM in model generation chain, for both target and references

*** COMPLETED Implement the merge transform                           :story:
    CLOSED: [2017-07-08 Sat 18:24]
    CLOCK: [2017-07-08 Sat 17:44]--[2017-07-08 Sat 18:24] =>  0:40

We need to refactor the existing merger into a one-shot transform that
takes a list of partial models and returns the merged model.

*** COMPLETED Implement the model generation chain                    :story:
    CLOSED: [2017-07-08 Sat 18:27]
    CLOCK: [2017-07-08 Sat 17:31]--[2017-07-08 Sat 17:44] =>  0:13

Tasks:

- implement the output languages expansion, considering
  multi-threading. If its too hard we should just stick to the
  single-threaded implementation we have at present.

*** COMPLETED Implement the model assembly chain                      :story:
    CLOSED: [2017-07-08 Sat 18:37]
    CLOCK: [2017-07-08 Sat 18:44]--[2017-07-08 Sat 19:12] =>  0:28
    CLOCK: [2017-07-08 Sat 18:31]--[2017-07-08 Sat 18:37] =>  0:06
    CLOCK: [2017-07-08 Sat 18:25]--[2017-07-08 Sat 18:30] =>  0:05
    CLOCK: [2017-07-08 Sat 17:20]--[2017-07-08 Sat 17:31] =>  0:11

Tasks:

- map models;
- merge models;
- apply post processing
- convert models to their final representation.
- plug it in the model generation chain.

*** COMPLETED Implement the post-processing chain                     :story:
    CLOSED: [2017-07-09 Sun 11:41]
    CLOCK: [2017-07-09 Sun 11:17]--[2017-07-09 Sun 11:41] =>  0:24
    CLOCK: [2017-07-09 Sun 11:01]--[2017-07-09 Sun 11:16] =>  0:15
    CLOCK: [2017-07-09 Sun 10:45]--[2017-07-09 Sun 11:00] =>  0:15
    CLOCK: [2017-07-08 Sat 22:58]--[2017-07-08 Sat 23:17] =>  0:19
    CLOCK: [2017-07-08 Sat 22:30]--[2017-07-08 Sat 22:57] =>  0:27
    CLOCK: [2017-07-08 Sat 22:21]--[2017-07-08 Sat 22:29] =>  0:08
    CLOCK: [2017-07-08 Sat 21:31]--[2017-07-08 Sat 21:36] =>  0:05
    CLOCK: [2017-07-08 Sat 21:27]--[2017-07-08 Sat 21:30] =>  0:03
    CLOCK: [2017-07-08 Sat 21:25]--[2017-07-08 Sat 21:26] =>  0:01
    CLOCK: [2017-07-08 Sat 21:18]--[2017-07-08 Sat 21:24] =>  0:06
    CLOCK: [2017-07-08 Sat 21:12]--[2017-07-08 Sat 21:17] =>  0:05
    CLOCK: [2017-07-08 Sat 21:00]--[2017-07-08 Sat 21:11] =>  0:11
    CLOCK: [2017-07-08 Sat 20:54]--[2017-07-08 Sat 20:59] =>  0:05
    CLOCK: [2017-07-08 Sat 20:27]--[2017-07-08 Sat 20:53] =>  0:26
    CLOCK: [2017-07-08 Sat 20:21]--[2017-07-08 Sat 20:26] =>  0:05
    CLOCK: [2017-07-08 Sat 20:01]--[2017-07-08 Sat 20:20] =>  0:19
    CLOCK: [2017-07-08 Sat 19:13]--[2017-07-08 Sat 19:24] =>  0:11
    CLOCK: [2017-07-08 Sat 18:38]--[2017-07-08 Sat 18:44] =>  0:06

Tasks:

- implement all internal transforms required by the post-processing
  chain.
- implement the external transform chain.

Notes:

- for the external chain, we need to generate the decorations
  properties factory within the chain.

*** COMPLETED Move helpers from =transforms= namespace                :story:
    CLOSED: [2017-07-09 Sun 12:31]
    CLOCK: [2017-07-09 Sun 12:25]--[2017-07-09 Sun 12:31] =>  0:06
    CLOCK: [2017-07-09 Sun 12:12]--[2017-07-09 Sun 12:24] =>  0:12
    CLOCK: [2017-07-09 Sun 11:58]--[2017-07-09 Sun 12:11] =>  0:13
    CLOCK: [2017-07-09 Sun 11:49]--[2017-07-09 Sun 11:57] =>  0:08
    CLOCK: [2017-07-09 Sun 11:42]--[2017-07-09 Sun 11:48] =>  0:06

We should try to keep the transforms namespace clean and only have
transformation related code there. All other code that is not
meta-model types should go to a generic namespace such as "helpers".

- validator
- indexer
- resolver
- path extractor

*** COMPLETED Replace expanders with transforms                       :story:
    CLOSED: [2017-07-09 Sun 12:35]
    CLOCK: [2017-07-09 Sun 12:32]--[2017-07-09 Sun 12:35] =>  0:03

Tasks:

- use the model generated from the transforms instead of the
  expanders.
- fix all resulting errors.

*** COMPLETED Port all expander unit tests to transforms              :story:
    CLOSED: [2017-07-09 Sun 14:34]
    CLOCK: [2017-07-09 Sun 14:33]--[2017-07-09 Sun 14:34] =>  0:01
    CLOCK: [2017-07-09 Sun 14:31]--[2017-07-09 Sun 14:32] =>  0:01
    CLOCK: [2017-07-09 Sun 14:25]--[2017-07-09 Sun 14:30] =>  0:05
    CLOCK: [2017-07-09 Sun 14:08]--[2017-07-09 Sun 14:17] =>  0:09
    CLOCK: [2017-07-09 Sun 13:58]--[2017-07-09 Sun 14:07] =>  0:09
    CLOCK: [2017-07-09 Sun 13:52]--[2017-07-09 Sun 13:57] =>  0:05
    CLOCK: [2017-07-09 Sun 13:48]--[2017-07-09 Sun 13:51] =>  0:03
    CLOCK: [2017-07-09 Sun 13:41]--[2017-07-09 Sun 13:47] =>  0:06
    CLOCK: [2017-07-09 Sun 13:39]--[2017-07-09 Sun 13:40] =>  0:01
    CLOCK: [2017-07-09 Sun 13:36]--[2017-07-09 Sun 13:38] =>  0:02

We need to update all unit tests to use the transforms API.

*** COMPLETED Remove all legacy classes from yarn                     :story:
    CLOSED: [2017-07-09 Sun 15:10]
    CLOCK: [2017-07-09 Sun 14:35]--[2017-07-09 Sun 15:10] =>  0:35
    CLOCK: [2017-07-09 Sun 12:36]--[2017-07-09 Sun 12:56] =>  0:20

Remove all of the code that got moved into transforms, fixing tests
and anything else that breaks as a result.

Notes:

- test tailor

*** COMPLETED Implement the mapper as a transform                     :story:
    CLOSED: [2017-07-09 Sun 16:02]
    CLOCK: [2017-07-09 Sun 16:01]--[2017-07-09 Sun 16:02] =>  0:01
    CLOCK: [2017-07-09 Sun 15:46]--[2017-07-09 Sun 16:00] =>  0:14
    CLOCK: [2017-07-09 Sun 15:42]--[2017-07-09 Sun 15:45] =>  0:03
    CLOCK: [2017-07-09 Sun 15:40]--[2017-07-09 Sun 15:41] =>  0:01
    CLOCK: [2017-07-09 Sun 15:37]--[2017-07-09 Sun 15:39] =>  0:02
    CLOCK: [2017-07-09 Sun 15:11]--[2017-07-09 Sun 15:36] =>  0:25

We did a quick hack and reused the existing mapper. We need to move
it, and all the associated classes (repository etc) into the
transforms namespace and clean it up. Name: =map_transform=.

*** COMPLETED Move helpers from main yarn namespace                   :story:
    CLOSED: [2017-07-09 Sun 17:38]
    CLOCK: [2017-07-09 Sun 17:13]--[2017-07-09 Sun 17:37] =>  0:24
    CLOCK: [2017-07-09 Sun 17:10]--[2017-07-09 Sun 17:12] =>  0:02
    CLOCK: [2017-07-09 Sun 16:41]--[2017-07-09 Sun 17:09] =>  0:28
    CLOCK: [2017-07-09 Sun 16:22]--[2017-07-09 Sun 16:40] =>  0:18
    CLOCK: [2017-07-09 Sun 16:11]--[2017-07-09 Sun 16:21] =>  0:10
    CLOCK: [2017-07-09 Sun 16:03]--[2017-07-09 Sun 16:10] =>  0:07

Types such as name builder etc need to be moved to the helpers
namespace.

*** COMPLETED Move all data types into its own namespace              :story:
    CLOSED: [2017-07-12 Wed 20:21]
    CLOCK: [2017-07-12 Wed 19:02]--[2017-07-12 Wed 20:16] =>  1:14
    CLOCK: [2017-07-11 Tue 21:48]--[2017-07-11 Tue 23:38] =>  1:50
    CLOCK: [2017-07-11 Tue 17:34]--[2017-07-11 Tue 18:22] =>  0:48
    CLOCK: [2017-07-11 Tue 06:48]--[2017-07-11 Tue 07:36] =>  0:48
    CLOCK: [2017-07-10 Mon 18:46]--[2017-07-10 Mon 23:06] =>  4:20

Now we have placed all the transforms under namespace =transforms=,
for symmetry purposes it would be nice to have some top-level
namespace for the data types. Names:

- entities
- meta-model
- ...

If we cannot find any good names, we may need to leave these objects
at the top-level. However, we should probably also place the code
generator at the top-level as well.

Notes:

- name flattener should be in helpers
- bug in resolution: cannot refer to a top-level namespace from
  another top-level namespace

*** CANCELLED Move artefacts from formatters into meta-model          :story:
    CLOSED: [2017-07-12 Wed 21:12]
    CLOCK: [2017-07-12 Wed 20:39]--[2017-07-12 Wed 21:12] =>  0:33
    CLOCK: [2017-07-12 Wed 20:17]--[2017-07-12 Wed 20:38] =>  0:21

We originally placed artefacts in formatters. In the new
understanding, it is actually a yarn meta-model concept. Move it
across, with associated infrastructure (writers).

Actually this does not result in a cleaner model: we need artefacts
even when we do not use yarn: stitcher. Since this is not an obvious
win, we'll cancel it for now.

*** CANCELLED Use transformation context in quilt                     :story:
    CLOSED: [2017-07-12 Wed 21:33]
    CLOCK: [2017-07-12 Wed 21:24]--[2017-07-12 Wed 21:33] =>  0:09
    CLOCK: [2017-07-12 Wed 21:13]--[2017-07-12 Wed 21:24] =>  0:11

Tasks:

- add formatters decoration repository and properties factory to
  context.
- update kernel interfaces to use the context.

Actually this won't work because we need the root annotation in order
to generate the decorations property factory. This cannot be done when
context is being created.

*** COMPLETED Create an options validator                             :story:
    CLOSED: [2017-07-14 Fri 10:22]
    CLOCK: [2017-07-14 Fri 10:36]--[2017-07-14 Fri 10:38] =>  0:02
    CLOCK: [2017-07-14 Fri 10:23]--[2017-07-14 Fri 10:35] =>  0:12
    CLOCK: [2017-07-14 Fri 10:01]--[2017-07-14 Fri 10:22] =>  0:21
    CLOCK: [2017-07-14 Fri 09:57]--[2017-07-14 Fri 10:01] =>  0:04

At present we are checking that the paths are absolute in the
transforms. We should do an upfront check, perhaps when creating the
context.

Actually we already have one, so update it.

*** COMPLETED Generate windows packages with CPack                    :story:
    CLOSED: [2017-07-14 Fri 12:05]

*Rationale*: implemented on previous sprints.

We tried to generate windows packages by using the NSIS tool, but
there are no binaries available for it at present. However, it seems
CPack can now generate MSIs directly:

- [[http://stackoverflow.com/questions/18437356/how-to-generate-msi-installer-with-cmake][How to generate .msi installer with cmake?]]
- [[https://cmake.org/cmake/help/v3.0/module/CPackWIX.html][CPackWIX]]

We need to investigate how to get the build to produce MSIs using WIX.

*** COMPLETED Add an example of redis and dogen                       :story:
    CLOSED: [2017-07-14 Fri 12:06]

*Rationale*: northwind blog posts have this.

Building external project:

: cd /home/marco/Development/DomainDrivenConsulting/redis/build/output/gcc-6/Release &&
: CMAKE_PROGRAM_PATH=/home/marco/Development/DomainDrivenConsulting/dogen/build/output/gcc/Release/stage/bin
: CMAKE_INCLUDE_PATH=/usr/local/personal/include CMAKE_LIB_PATH=/usr/local/personal/lib
: cmake ../../../.. -G Ninja && Ninja -j5

Redis client:

https://github.com/nekipelov/redisclient
git@github.com:nekipelov/redisclient.git

*** COMPLETED Move odb options file into odb folder                   :story:
    CLOSED: [2017-07-14 Fri 12:07]

*Rationale*: done in previous sprint.

There is not particularly good reason for this file to exist at the
src level.

In order to implement this story we need to have a working odb setup
to test it and ensure we didn't break anything.

*** COMPLETED References to objects in package should assume package  :story:
    CLOSED: [2017-07-14 Fri 12:11]

*Rationale*: implemented in previous sprints.

#+begin_quote
*Story*: As a dogen user, I don't want to have to specify fully
qualified names when referring to types in the same package so that I
don't have to type information that can be deduced by the system.
#+end_quote

At present if we define two objects in a package =p=, say =a= and =b=,
where =b= refers to =a= it must do so using a fully qualified path,
e.g.: =p::a=. Failure to do so results in an error:

: 2014-09-10 08:27:10.662113 [ERROR] [sml.resolver] Object has property with undefined type:  { "__type__": "dogen::sml::qname", "model_name": "", "external_module_path": [ ] , "module_path": [ ] , "simple_name": "registrar" }
: 2014-09-10 08:27:10.665861 [FATAL] [knitter] Error: /home/marco/Development/DomainDrivenConsulting/dogen/projects/sml/src/types/resolver.cpp(178): Throw in function dogen::sml::qname dogen::sml::resolver::resolve_partial_type(const dogen::sml::qname &) const
: Dynamic exception type: N5boost16exception_detail10clone_implIN5dogen3sml16resolution_errorEEE
: std::exception::what: Object has property with undefined type: registrar
: [P12tag_workflow] = Code generation failure.

This should be fairly trivial to implement: all we need to do is to
add =owner= to =resolve_name= in =resolver= and add an extra
resolution step that uses the owner's location.

*** COMPLETED Update comments in C++ model                            :story:
    CLOSED: [2017-07-14 Fri 12:15]

*Rationale*: implemented in previous sprints.

We have a very large blurb in this model that is rather old, and
reflects a legacy understanding of the role of the C++ model.

*** COMPLETED Remove references to PFH in makefiles                   :story:
    CLOSED: [2017-07-14 Fri 12:16]

*Rationale*: implemented in previous sprints.

Seems like the correct way of finding libraries is to use
=CMAKE_PREFIX_PATH= as explained [[https://blogs.kde.org/2008/12/12/how-get-cmake-find-what-you-want-it][in this article]]. We should stop using
any references to PFH and let the users provide a path to local
installs via this.

We need to add a note on the read me too.

*** COMPLETED Consider renaming dependencies to references in model   :story:
    CLOSED: [2017-07-14 Fri 12:19]

*Rationale*: implemented in previous sprints.

Dependencies is a map of reference; why not call it references?

*** COMPLETED Do not copy models in merger                            :story:
    CLOSED: [2017-07-14 Fri 12:19]

*Rationale*: new implementation of merge transform fixes this.

At present we are adding the partial models into the merger by copying
them into an associative container. It would be nicer to avoid the
copying as it adds no value. This should wait until we have a way to
get performance numbers out.

In fact do we even need to have a two step process? Can we not add and
merge as we go along.

*** COMPLETED Improve cross model visitation support                  :story:
    CLOSED: [2017-07-14 Fri 12:20]

*Rationale*: implemented in previous sprints.

One of the problems we have at present is that its not possible to
define a base class in a model with a visitor and then extend it in
leaves in order
to dispatch. There seem to be some ideas in this space which may
provide a solution:

- [[http://stackoverflow.com/questions/11796121/implementing-the-visitor-pattern-using-c-templates][Implementing the visitor pattern using C++ Templates]]

One simpler but hacky way of solving this problem is perhaps to have
"model specific" visitors in each model, and have them extend the base
visitor. Clients can then decide which visitor to use. This does mean
that if two models are extending the base visitor, you will need to
visit twice, but at least for the most common case (one model
extending another) it provides a workable solution.

*** COMPLETED Knitting =quilt= does not work                          :story:
    CLOSED: [2017-07-14 Fri 12:41]

*Rationale*: removing quilt solved this problem.

When we invoke =knit_quilt= for some reason we seem to knit
=quilt.cpp=:

: $ ninja knit_quilt
: [1/1] Knitting Quilt C++ model

This seems to be some kind of ninja "feature".

For the moment we've put in a very ugly fix: we renamed the target
=knit_quiltx=.

*** STARTED Implement the code-generation chain                       :story:
    CLOCK: [2017-07-14 Fri 12:25]--[2017-07-14 Fri 12:43] =>  0:18
    CLOCK: [2017-07-14 Fri 11:51]--[2017-07-14 Fri 12:04] =>  0:13
    CLOCK: [2017-07-14 Fri 10:50]--[2017-07-14 Fri 11:50] =>  1:00
    CLOCK: [2017-07-14 Fri 09:29]--[2017-07-14 Fri 09:56] =>  0:27
    CLOCK: [2017-07-13 Thu 18:55]--[2017-07-13 Thu 19:45] =>  0:50
    CLOCK: [2017-07-13 Thu 06:31]--[2017-07-13 Thu 07:42] =>  1:11
    CLOCK: [2017-07-12 Wed 21:34]--[2017-07-12 Wed 22:02] =>  0:28

Tasks:

- implement the code generator transform interface in c++ and c#.
- implement the code generation chain, including the configuration
  factory from quilt.
- implement the code generator by binding the model generator chain
  and the code generation chain together.
- move context generation into code generator.
- update knitter to use the code generator.
- delete quilt.

*** Assorted problems to look at                                      :story:

- No flat mode: we need to be able to generate no folders at all.
- Registrar coming out even when there is no inheritance.
- No setting to add include for precompiled headers: stdafx.h
- No vcxproj for c++ and no way to add code-generated files. Ideally
  one should be able to include a code-generated file into project
  with list of items
- sort out traits.

*** Move enablement into yarn                                         :story:

It seems that the concepts around enablement are actually not kernel
specific but instead can be generalised at the meta-model level. We
need to create adequate representations in yarn to handle facets,
etc. We then need to move across the code that computes enablement
into yarn so that all kernels can make use of it.

*Previous Understanding*

We need to make use of the exact same logic as implemented in
=quilt.cpp= for enablement. Perhaps all of the enablement related
functionality can be lifted and grafted onto quilt without any major
changes.

*** Move dependencies into yarn                                       :story:

It seems all languages we support have some form of "dependencies":

- in c++ these are the includes
- in c# these are the usings
- in java these are the imports

So, it would make sense to move these into yarn. The process of
obtaining the dependencies must still be done in a kernel dependent
way because we need to build any language-specific structures that the
dependencies builder requires. However, we can create an interface for
the dependencies builder in yarn and implement it in each kernel. Each
kernel must also supply a factory for the builders.

*** Move helpers into yarn                                            :story:

Looking at helpers, it is clear that they are common to all
languages. We just need to rename the terminology slightly -
particularly wrt to streaming properties - and then move this code
across into yarn.

*** Move facet properties into yarn                                   :story:

We should be able to handle these generically in yarn.

*** Move ORM camel-case and databases into yarn                       :story:

We should handle this property at the ORM level, rather than at the
ODB level.

Similarly, we should move the ODB databases into yarn and make that a
ORM-level concept.

*** Move element segmentation into yarn                               :story:

We've added the notion that an element can be composed of other
elements in quilt, in order to handle forward declarations. However,
with a little bit of effort we can generalise it into yarn. It would
be useful for other things such as inner classes. We don't need to
actually implement inner classes right now but we should make sure the
moving of this feature into yarn is compatible with it.

Notes:

- seems like we have two use cases: a) we need all elements, master
  and extensions and we don't really care about which is which. b) we
  only want masters. However, we must be able to access the same
  element properties from either the master or the extension. Having
  said all that, it seems we don't really need all of the element
  properties for both - forward declarations probably only need:
  decoration and artefact properties.
- we don't seem to use the map in formattables model anywhere, other
  than to find master/extension elements.
- Yarn model could have two simple list containers (masters and
  all). Or maybe we don't even need this to start off with, we can
  just iterate and skip extensions where required.
- so in conclusion, we to move decoration, enablement and dependencies
  into yarn (basically decoration and artefact properties) first and
  then see where segmentation ends.

*** Start documenting the theoretical aspects of Dogen                :story:

Up to now we have more or less coded Dogen as we went along; we
haven't really spent a lot of time worrying about the theory behind
the work we were carrying out. However, as we reached v1.0, the theory
took center stage. We cannot proceed to the next phase of the product
without a firm grasp of the theory. This story is a starting point so
we can decide on how to break up the work.

*** Add support for proper JSON serialisation in C++                  :story:

We need to add support for JSON in C++. It will eventually have to
roundtrip to JSON in C# but that will be handled as two separate
stories.

Libraries:

- One option is [[https://github.com/cierelabs/json_spirit][json_spirit]].
- Another option is [[https://github.com/miloyip/rapidjson][RapidJson]].
- Actually there is a project comparing JSON libraries: [[https://github.com/miloyip/nativejson-benchmark][nativejson-benchmark]]
- One interesting library is [[https://github.com/dropbox/json11][Json11]].

When we implement this we should provide support for JSON with
roundtripping tests.

We will not replace the current IO implementation; it should continue
to exist as is, requiring no external dependencies.

We should consider supporting multiple JSON libraries: instead of
making the mistake we did with serialisation where we bound the name
=serialization= with boost serialisation, we should call it by its
real name, e.g. =json_spirit= etc. Then when a user creates a
stereotype for a profile such as =Serializable= it can choose which
serialisation codecs to enable for which language. This means that the
same stereotypes can have different meanings in different
architectures, which is the desired behaviour.

We should create a serialise / deserialise functions following the
same logic as boost:

#+begin_src c++
void serialize(Value& v, const object& o);
void serialize(Value& v, const base& b);

void deserialize(const Value& v, object& o);
base* deserialize(const Value& v);
#+end_src

Or perhaps even better, we can make the above the internal methods and
use =operator<<= and =operator>>= as the external methods:

#+begin_src c++
void operator<<(Value& v, const object& o);
void operator>>(const Value& v, object& o);
#+end_src

Notes:

- create a registrar with a map for each base type. The function
  returns a base type pointer.
- when you deserialize a base type pointer, you call the pointer
  deserialize above. Same for when you have a pointer to an object. It
  will internally call the registrar (if its a base type) and get the
  right function.
- this means we only need to look at type for inheritance. Although we
  should probably always do it for validation? However, what happens
  if we want to make a model so we can read external JSON? It won't
  contain type markings.
- =operator>>= will not be defined for pointers or base classes.
- this wont work for the case of =doc << base=. For this we need a map
  that looks up on type_index.

Merged stories:

For the previous attempt to integrate RapidJson see this commit:

b2cce41 * third party: remove includes and rapid json

*Add support for JSON serialisation*

We should have proper JSON serialisation support, for both reading and
writing. We can then implement IO in terms of JSON.

*Raw JSON vs cooked JSON*

If we do implement customisable JSON serialisation, we should still
use the raw format in streaming. We need a way to disable the cooked
JSON internally. We should also re-implement streaming in terms of
this JSON mode.

*** Use the in-memory interface of LibXml                             :story:

At present, our C++ wrappers on top of LibXml are using the file based
interface. We should do in-memory processing of the XML file. Once
this is in place, we can change the exogenous transformers to use
strings rather than paths to files.

** Deprecated
*** CANCELLED Add description to profile and value templates          :story:
    CLOSED: [2017-07-14 Fri 12:08]

*Rationale*: it won't be needed in the new implementation of profiles.

It would be nice to put some kind of comments as to what the profile
is doing and where required, the rationale behind some defaulting on
the value templates. We probably should look into supporting
descriptions in data as a whole.

*** CANCELLED Consider renaming cpp's name builder to name factory    :story:
    CLOSED: [2017-07-14 Fri 12:09]

*Rationale*: we've already have a name builder.

The name builder is just a factory so make the name reflect it.

Actually, we don't just build names either.

*** CANCELLED Names in C++ namespaces                                 :story:
    CLOSED: [2017-07-14 Fri 12:10]

*Rationale*: story bit-rotted and now makes no sense.

It appears we are not using the entity name for a C++ namespace. If
that is the case, this is wrong and needs to be fixed. We are probably
inferring the name by looking at the =front= (or =back=) of the
namespaces list. Investigate this.

*** CANCELLED Change transformation code to use a type visitor        :story:
    CLOSED: [2017-07-14 Fri 12:12]

*Rationale*: story bit-rotted and now makes no sense.

Now we have a base type, we could probably simplify some of the
transformation code:

- dia to sml
- sml to c++
- potentially merger

*** CANCELLED Add a file formatter interface to formatters            :story:
    CLOSED: [2017-07-14 Fri 12:12]

*Rationale*: this does not fit our current understanding any more.

It probably makes sense to have a top-level interface for file
formatting in the formatters model. At present we have a lot of
=quilt.cpp= specific things in there. Maybe we should just extract the
common attributes and use them to create the generic interface.

This still makes sense after the current refactor, but it requires
some thinking.

Notes:

- formattable becomes a concept at the formatters' model level, but it
  has just an id.
- it seems we should be able to also have the formatters container and
  even the formatters workflow in =formatters=; however, this would
  increase the amount of casting required.

*** CANCELLED Add WinSock definition in CMakeLists for ODB support    :story:
    CLOSED: [2017-07-14 Fri 12:13]

*Rationale*: we are using ODB without any errors so no need for this
it seems.

We did a crude implementation of finding WinSock just to get windows
to build. There should be a FindWinSock somewhere. If not create one.

Do we need this anymore? we probably need it for linking the database
model, but we should check - maybe ODB has some magic around this.

Actually this was commented out in code so removed it. Was:

: # WinSock (for database)
: # if (WIN32)
: #     find_library(WSOCK_LIB NAMES wsock32 DOC "The winsock library")
: #     if(WSOCK_LIB)
: #         list(APPEND CMAKE_REQUIRED_LIBRARIES wsock32)
: #     else()
: #         message(FATAL_ERROR "winsock not found.")
: #     endif()
:
: #     find_library(WSOCK2_LIB NAMES ws2_32 DOC "The winsock 2 library")
: #     if(WSOCK2_LIB)
: #         list(APPEND CMAKE_REQUIRED_LIBRARIES ws2_32)
: #     else()
: #         message(FATAL_ERROR "winsock2 not found.")
: #     endif()
:
: #     find_library(MSWSOCK_LIB NAMES mswsock DOC "The winsock 2 library")
: #     if(MSWSOCK_LIB)
: #         list(APPEND CMAKE_REQUIRED_LIBRARIES mswsock)
: #     else()
: #         message(FATAL_ERROR "mswsock not found.")
: #     endif()
: # endif()

*** CANCELLED Formatters' repository should be created in quilt       :story:
    CLOSED: [2017-07-14 Fri 12:17]

*Rationale*: we do not have quilt any longer.

At present we are creating the formatters' repository in
=quilt.cpp=. However it will be shared by all backends in the
kernel. Move it up to =quilt= level and supply it as a paramter to the
backends.

*** CANCELLED Comments seem to be trimmed                             :story:
    CLOSED: [2017-07-14 Fri 12:18]

*Rationale*: comments seem fine at the moment.

For some reason we seem to be munching any blank lines at the end of
comments. We should only remove the lines with the well known dogen
marker, all other lines should be left untouched.
