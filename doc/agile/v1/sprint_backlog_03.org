#+title: Sprint Backlog 03
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Continue work on moving "generic" types from the quilt models into
  yarn.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2017-07-30 Sun 18:56]
| <75>                                                                        |         |       |      |       |
| Headline                                                                    | Time    |       |      |     % |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| *Total time*                                                                | *27:52* |       |      | 100.0 |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| Stories                                                                     | 27:52   |       |      | 100.0 |
| Active                                                                      |         | 27:52 |      | 100.0 |
| COMPLETED Edit release notes for previous sprint                            |         |       | 0:19 |   1.1 |
| STARTED Sprint and product backlog grooming                                 |         |       | 3:06 |  11.1 |
| COMPLETED Create a tagging checklist                                        |         |       | 0:07 |   0.4 |
| COMPLETED Tidy-up post-processing validation                                |         |       | 3:41 |  13.2 |
| COMPLETED Allow logging during initialisation                               |         |       | 1:16 |   4.5 |
| COMPLETED Refactor =yarn.dia=                                               |         |       | 1:39 |   5.9 |
| COMPLETED Add meta-type support to yarn                                     |         |       | 9:34 |  34.3 |
| COMPLETED Use the archetype locations repository in yarn                    |         |       | 1:16 |   4.5 |
| STARTED Rename =meta_type= in JSON                                          |         |       | 0:19 |   1.1 |
| STARTED Add canonical archetype support to yarn                             |         |       | 1:11 |   4.2 |
| STARTED Move external module processing into yarn                           |         |       | 0:55 |   3.3 |
| STARTED Create an exogenous model                                           |         |       | 4:29 |  16.1 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2017-07-17 Mon 20:57]
    CLOCK: [2017-07-17 Mon 20:38]--[2017-07-17 Mon 20:57] =>  0:19

Add github release notes for previous sprint.

Title: Dogen v1.0.02, "Caminhos de Ferro"

#+begin_src markdown
![Caminhos de Ferro de Benguela](http://www.angolabelazebelo.com/wp-content/uploads/2017/03/roteiro_comboio-mala_pedro-carreno1-.jpg)
_Carriage from Caminhos de Ferro de Benguela, the Benguela Railway, Namibe. (C)  Pedro Cardoso._

Overview
=======

The core objective of this sprint was to refactor yarn to fit the structure of a code generator in the Model Driven Engineering literature, in particular [Model-Driven Software Engineering in Practice](https://www.amazon.co.uk/Model-Driven-Software-Engineering-Practice-Synthesis/dp/1608458822).

With this work, yarn now becomes the core model housing both the meta-model and most of its transformations.

User visible changes
===============
There are no user visible changes in this sprint.

For more details of the work carried out this sprint, see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/v1/sprint_backlog_02.org).

Next Sprint
===========
In the next sprint we'll resume the work on moving kernel-agnostic transformations from the kernels into yarn.

Binaries
======
You can download experimental binaries from [Bintray](https://bintray.com/domaindrivenconsulting/Dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_1.0.02_amd64-applications.deb](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.02/dogen_1.0.02_amd64-applications.deb)
- [dogen-1.0.02-Darwin-x86_64.dmg](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.02/dogen-1.0.02-Darwin-x86_64.dmg)
- [dogen-1.0.02-Windows-AMD64.msi](https://dl.bintray.com/domaindrivenconsulting/Dogen/dogen-1.0.02-Windows-AMD64.msi)

**Note**: They are produced by CI so they may not yet be ready.

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/887172610487922688][Tweet]]
- [[https://www.linkedin.com/feed/update/urn:li:activity:6292938732865617920/][LinkedIn]]
- [[https://gitter.im/DomainDrivenConsulting/dogen][Gitter]]

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2017-07-28 Fri 12:33]--[2017-07-28 Fri 12:37] =>  0:04
    CLOCK: [2017-07-28 Fri 12:21]--[2017-07-28 Fri 12:32] =>  0:11
    CLOCK: [2017-07-28 Fri 10:01]--[2017-07-28 Fri 10:33] =>  0:32
    CLOCK: [2017-07-27 Thu 06:47]--[2017-07-27 Thu 07:32] =>  0:45
    CLOCK: [2017-07-26 Wed 19:02]--[2017-07-26 Wed 19:18] =>  0:16
    CLOCK: [2017-07-23 Sun 15:32]--[2017-07-23 Sun 15:45] =>  0:13
    CLOCK: [2017-07-18 Tue 17:13]--[2017-07-18 Tue 17:47] =>  0:34
    CLOCK: [2017-07-18 Tue 05:40]--[2017-07-18 Tue 05:58] =>  0:18
    CLOCK: [2017-07-17 Mon 20:58]--[2017-07-17 Mon 21:05] =>  0:07
    CLOCK: [2017-07-17 Mon 20:31]--[2017-07-17 Mon 20:37] =>  0:06

Updates to sprint and product backlog.

*** COMPLETED Create a tagging checklist                              :story:
    CLOSED: [2017-07-18 Tue 06:43]
    CLOCK: [2017-07-18 Tue 06:36]--[2017-07-18 Tue 06:43] =>  0:07

We now have a number of things that need to be done for the tag of the
sprint. We should document these to make sure we tag the releases
correctly.

Checklist:

- make a copy of current sprint and name it current sprint + 1;
- close current sprint.
- sign tag with key. Push tag separately so we build the correct
  windows version.
- open new sprint, updating CMake version and appveyor version. This
  should all be in one commit.
- write up release notes, publish them in github.
- when tag build is finished, announce on twitter and linked in.
- update bintray with the correct release notes.

*** COMPLETED Tidy-up post-processing validation                      :story:
    CLOSED: [2017-07-23 Sun 13:10]
    CLOCK: [2017-07-23 Sun 13:11]--[2017-07-23 Sun 14:21] =>  1:10
    CLOCK: [2017-07-23 Sun 12:49]--[2017-07-23 Sun 13:10] =>  0:21
    CLOCK: [2017-07-23 Sun 12:41]--[2017-07-23 Sun 12:48] =>  0:07
    CLOCK: [2017-07-23 Sun 12:18]--[2017-07-23 Sun 12:40] =>  0:22
    CLOCK: [2017-07-23 Sun 11:51]--[2017-07-23 Sun 12:17] =>  0:26
    CLOCK: [2017-07-23 Sun 11:15]--[2017-07-23 Sun 11:50] =>  0:35
    CLOCK: [2017-07-20 Thu 07:20]--[2017-07-20 Thu 07:32] =>  0:12
    CLOCK: [2017-07-20 Thu 06:51]--[2017-07-20 Thu 07:19] =>  0:28

Tasks:

- use the traversal instead of rolling our own loop.
- validate injected types too.
- add validation for meta-model types.

*** COMPLETED Allow logging during initialisation                     :story:
    CLOSED: [2017-07-25 Tue 18:31]
    CLOCK: [2017-07-25 Tue 17:50]--[2017-07-25 Tue 18:31] =>  0:41
    CLOCK: [2017-07-25 Tue 08:11]--[2017-07-25 Tue 08:46] =>  0:35

At present we assume the log has not been initialised during
initialisation. The only reason for this is with unit testing because
each test initialises the log differently. However, one simple way
around this is to have a log file for the entire test suite and
separate log files for each test as we have now. Initialisation
logging would go in this main file.

This is a bit of a more pressing issue because we now make use of name
builders during initialisation in order to setup the formatter's
meta-type.

*** COMPLETED Refactor =yarn.dia=                                     :story:
    CLOSED: [2017-07-28 Fri 12:05]
    CLOCK: [2017-07-28 Fri 12:06]--[2017-07-28 Fri 12:20] =>  0:12
    CLOCK: [2017-07-28 Fri 11:40]--[2017-07-28 Fri 12:05] =>  0:25
    CLOCK: [2017-07-28 Fri 11:02]--[2017-07-28 Fri 11:39] =>  0:37
    CLOCK: [2017-07-28 Fri 10:35]--[2017-07-28 Fri 10:58] =>  0:23

There are a number of small issues with =yarn.dia=, which has
bit-rotted somewhat; address them.

Tasks:

- use remove reducer; use =remove_if= instead.

*** COMPLETED Add meta-type support to yarn                           :story:
    CLOSED: [2017-07-28 Fri 12:30]
    CLOCK: [2017-07-26 Wed 21:45]--[2017-07-26 Wed 22:16] =>  0:31
    CLOCK: [2017-07-25 Tue 23:43]--[2017-07-25 Tue 23:59] =>  0:16
    CLOCK: [2017-07-25 Tue 23:30]--[2017-07-25 Tue 23:42] =>  0:12
    CLOCK: [2017-07-25 Tue 23:26]--[2017-07-25 Tue 23:29] =>  0:03
    CLOCK: [2017-07-25 Tue 23:06]--[2017-07-25 Tue 23:25] =>  0:19
    CLOCK: [2017-07-25 Tue 22:15]--[2017-07-25 Tue 23:06] =>  0:51
    CLOCK: [2017-07-25 Tue 08:05]--[2017-07-25 Tue 08:11] =>  0:06
    CLOCK: [2017-07-23 Sun 18:31]--[2017-07-23 Sun 19:36] =>  1:05
    CLOCK: [2017-07-23 Sun 18:12]--[2017-07-23 Sun 18:30] =>  0:18
    CLOCK: [2017-07-23 Sun 17:56]--[2017-07-23 Sun 18:11] =>  0:15
    CLOCK: [2017-07-23 Sun 17:35]--[2017-07-23 Sun 17:56] =>  0:21
    CLOCK: [2017-07-23 Sun 15:46]--[2017-07-23 Sun 17:34] =>  1:48
    CLOCK: [2017-07-20 Thu 06:46]--[2017-07-20 Thu 06:51] =>  0:05
    CLOCK: [2017-07-19 Wed 21:08]--[2017-07-19 Wed 21:17] =>  0:09
    CLOCK: [2017-07-19 Wed 20:52]--[2017-07-19 Wed 21:07] =>  0:15
    CLOCK: [2017-07-19 Wed 20:34]--[2017-07-19 Wed 20:51] =>  0:17
    CLOCK: [2017-07-19 Wed 20:05]--[2017-07-19 Wed 20:33] =>  0:28
    CLOCK: [2017-07-19 Wed 19:49]--[2017-07-19 Wed 20:04] =>  0:15
    CLOCK: [2017-07-19 Wed 19:24]--[2017-07-19 Wed 19:48] =>  0:24
    CLOCK: [2017-07-19 Wed 18:20]--[2017-07-19 Wed 19:18] =>  0:58
    CLOCK: [2017-07-18 Tue 19:01]--[2017-07-18 Tue 19:11] =>  0:10
    CLOCK: [2017-07-18 Tue 18:06]--[2017-07-18 Tue 18:16] =>  0:10
    CLOCK: [2017-07-18 Tue 17:47]--[2017-07-18 Tue 18:05] =>  0:18

At present we are relying on type indexes to create containers of
archetype locations. This has worked so far, but it does mean that we
cannot serialise (and thus code-generate) any type using these
containers.

We could try to add support for type index serialisation, but this is
non-trivial because it involves registration of types. This facility
already exists in the guts of boost serialisation, so it does not make
sense to roll our own as well; however, it will require quite a bit of
fiddling to understand the boost serialisation implementation. It may
even required some form of mapping between the =std::type_index= and
boost's implementation.

An easier solution to this problem, which is also conceptually
sensible, is to support meta-modeling locations. Just as we have
modeling locations - i.e. positions in modeling space - one can
imagine that there are also positions in meta-modeling space, with
similar properties (external modules, internal modules and so
forth). These should by all means be static on meta-model elements
(e.g. yarn's =object= is located in =dogen::yarn::meta_model= and that
is the same for all of its instances) but given that code generation
does not support this pattern, we need to simulate it by having
instance level copies of the meta-model location. This is expensive
but its also easy to do, so we'll go with it for now.

Tasks:

- add a new concept: =MetaNameable= with one property: =meta_name=.
- create a transform to populate all of yarn's meta-types.
- add a factory in each kernel's fabric to create meta-names for
  fabric elements.
- populate model and global module meta-names.
- add validation rule to ensure meta-model name is not empty. We
  cannot use the existing validation rules since meta-types will be
  duplicated.
- update element construction in fabric to use factory.
- update formatters to return meta-name.
- update the type index maps to use the meta-name's id instead.
- update the archetype location containers that are using the type
  index to use the meta name's id.
- remove any references to type index.

Notes:

- actually this cannot be part of pre-processing as we will miss the
  injected types such as global module, visitor, etc.
- create a =meta_name_factory= in meta-model which generates names for
  elements. This can be simply hard-coded on the names,
  e.g. =make_object_name=, etc.
- update the frontends to set the meta-name when constructing the
  elements.

Problems:

- we are using meta-type and meta-name, use just one.
- c# project id's seem to have weird id's:

: Processing element: <dogen><test_models><all_path_and_directory_settings><dogen.test_models.all_path_and_directory_settings.sln>
: for archetype: quilt.csharp.visual_studio.solution

*** COMPLETED Use the archetype locations repository in yarn          :story:
    CLOSED: [2017-07-28 Fri 16:15]
    CLOCK: [2017-07-28 Fri 16:04]--[2017-07-28 Fri 16:18] =>  0:14
    CLOCK: [2017-07-28 Fri 15:35]--[2017-07-28 Fri 16:03] =>  0:28
    CLOCK: [2017-07-28 Fri 13:03]--[2017-07-28 Fri 13:13] =>  0:10
    CLOCK: [2017-07-28 Fri 12:38]--[2017-07-28 Fri 13:02] =>  0:24

Originally we created a repository for archetype locations, with
several indices. However, it seems we forgotten about it and are
passing around various containers of archetype locations. We need to
remove these and use the repository. We also need to add it to
context.

We can now have the registrar own the repository, populate it all
during registration and return it at the start, via the kernel API and
the archetype location repository factory.

Notes:

- delete all usages of the list of archetype locations, make use of
  repository instead.
- add archetype_locations_by_meta_name to repository.
- kernels should only return
  =archetype_locations_by_meta_name=. Repository factory should use
  this to build all containers. Factory should take multiple of
  these. We should have a builder instead of a factory.

*** STARTED Rename =meta_type= in JSON                                :story:
    CLOCK: [2017-07-26 Wed 22:17]--[2017-07-26 Wed 22:36] =>  0:19

Now we have meta-names we should use the same terminology for JSON
documents.

*** STARTED Add canonical archetype support to yarn                   :story:
    CLOCK: [2017-07-28 Fri 16:19]--[2017-07-28 Fri 16:43] =>  0:24
    CLOCK: [2017-07-18 Tue 07:28]--[2017-07-18 Tue 07:33] =>  0:05
    CLOCK: [2017-07-18 Tue 06:45]--[2017-07-18 Tue 07:27] =>  0:42

We need to add a new attribute in context which captures the canonical
archetypes.

Notes:

- kernel must also return canonical archetype by element type
  index. Perhaps we should have a struct that aggregates both:
  archetype locations for meta-type? Or kernel can just return a
  =std::pair=.
- at present we have placed the canonical archetype resolution as part
  of the element properties. However, we do not need to have this at
  the element level since its a meta-type property and can be
  determined up-front. However, we do need to resolve a name into a
  meta-type before we can resolve a meta-type into a concrete
  archetype.
- we need to unpick the notion of whether a formatter is "includible"
  or not from the notion of canonical archetypes. Canonical archetypes
  is meta-model concept: given a facet and a meta-model type, which
  archetype represents the "key" definition of the element. It just so
  happens that this function has a use in identifying the files to
  include.

Tasks:

- add a map from name id to meta-name id in intermediate model.
- add a map from meta name id to map of canonical archetype to
  archetype location.

*** STARTED Move external module processing into yarn                 :story:
    CLOCK: [2017-07-26 Wed 22:37]--[2017-07-26 Wed 23:32] =>  0:55

At present we have a hack in =yarn.dia= whereby we are looking for a
key =yarn.dia.external_modules= and then using it to populate the
external module path of all names read on that model, as we traverse
the graph of dia objects.

The problem is, this functionality is also required on other frontends
such as JSON. We should use the traditional annotation machinery to
populate the external modules inside of yarn pre-processing.

One thing to bear in mind is that we need to trash all containers and
re-insert all elements, because the IDs will change as part of this
exercise.

*** STARTED Create an exogenous model                                 :story:
    CLOCK: [2017-07-30 Sun 18:53]--[2017-07-30 Sun 18:56] =>  0:03
    CLOCK: [2017-07-30 Sun 18:38]--[2017-07-30 Sun 18:52] =>  0:14
    CLOCK: [2017-07-30 Sun 18:20]--[2017-07-30 Sun 18:37] =>  0:17
    CLOCK: [2017-07-30 Sun 13:25]--[2017-07-30 Sun 13:43] =>  0:18
    CLOCK: [2017-07-30 Sun 11:05]--[2017-07-30 Sun 11:30] =>  0:25
    CLOCK: [2017-07-30 Sun 10:12]--[2017-07-30 Sun 11:01] =>  0:49
    CLOCK: [2017-07-29 Sat 18:16]--[2017-07-29 Sat 18:26] =>  0:10
    CLOCK: [2017-07-29 Sat 17:31]--[2017-07-29 Sat 18:01] =>  0:30
    CLOCK: [2017-07-29 Sat 13:45]--[2017-07-29 Sat 14:41] =>  0:56
    CLOCK: [2017-07-29 Sat 08:46]--[2017-07-29 Sat 09:14] =>  0:28
    CLOCK: [2017-07-28 Fri 23:21]--[2017-07-28 Fri 23:40] =>  0:19

At present we are allowing the frontends to directly create
intermediate models. However, this doesn't make a lot of sense: there
are many properties in the intermediate models which should not be
touched by the frontends. We should have a specific model that has
only the properties that can be set by the frontends -
=exogenous_model=. The exogenous model chain is then responsible for
converting it into an intermediate model.

Tasks:

- create the exogenous model with the required attributes. Add a root
  module, remove model name. All containers should be lists of a pair
  of scribble group to concrete element.
- move annotations transform to exogenous chain. Add a transform to
  update element names by reading model modules and external modules.
- drop scribble groups from intermediate model.
- add an adaptor to convert from exogenous model to intermediate
  model.
- use some kind of reference to figure out where to place the
  documentation of a module. We can't use the IDs any longer. We could
  simply remember the list iterators. Since we are only pushing back
  into the list, the iterators should remain valid. However, for this
  to work we need to add support to iterators in dogen or manually
  create the context/repository.
- Refactor yarn.dia, splitting out the model from the repository and
  renaming repository to context.

Notes:

- we need a completely different annotations transform. In the new
  world, scribble updating and annotation updating are done in one go
  by the updater, who has the annotation group as state. The annotation
  classes need to be updated to take in just one scribble group rather
  than a map. The updater needs to be a regular element visitor. The
  transform runs on the exogenous model.

Steps:

- update scribble group with stereotypes.
- convert scribble group into annotation group.
- process element annotation.
- process attribute annotations, if stateful.

*** Enable kernel directories trait is on quilt                       :story:

When we moved the kernel logic into yarn from quilt, we did not rename
the traits.

*** Add models for the executables                                    :story:

At present the executables are all hand-crafted. However, as we want
to move the options into each executable we need them to be in a
model.

Tasks:

- create a model for each executable and add the options to the model;
- create options in yarn and stop using knitting options;
- add meta-data to generate an executable instead of a library in
  CMake.
- generate a main skeleton if one does not exist.
- remove options project.

*** Throw on unsupported stereotypes                                  :story:

In some cases we may support a feature in one language but not on
others like say ORM at present. If a user requests ORM in a C# model,
we should throw.

*** Add a property for the model modules as an annotation             :story:

We should read out the model name as an annotation instead of
inferring it from the filename on some frontends (Dia) and allowing
the user to set it internally on others (JSON).

This is not quite as trivial as it may look: we create the model
module using the model name; this is necessary because we need to read
its annotations and place it in the right element. Without a model
name, this becomes a bit tricky.

*Previous Understanding*

#+begin_quote
*Story*: As a dogen user in a constrained environment, I am forced to
use file names that are not suitable for a model name so that I need
to supply an override somewhere else.
#+end_quote

It would be nice to be able to generate a model with a name other than
the diagram file. We should have a command line option for this that
overrides the default diagram name.

This could also be supplied as part of dynamic extensions. The command
line option is useful when we want to use the same diagram to test
different aspects of the generation, as we do with the tests. The
dynamic extensions option is useful when we don't want the file name
to have the full name of the model.

We now have a use case for this: the dynamic models. See Rename
dynamic models.

*** Rename transformers to adapters                                   :story:

In the past we used the term "transformer" to mean a class that
converts types from one representation to another. However, now that
we are using domain terminology, the term "transforms" is taken to
mean a model transformation. To avoid confusion we should rename the
existing transformers to converters, adapters or some other
out-of-the-way name.

*** Add a modeline to stitch                                          :story:

It would be nice to be able to supply the mode and other emacs
properties to stitch templates. For that we just need a special KVP
used at the top that contains the modeline:

: <#@ modeline="-*- mode: poly-stitch; tab-width: 4; indent-tabs-mode: nil; -*-" #>

Stitch can read this KVP and ignore it.

*** Use namespaced stereotypes                                        :story:

Originally we added a space in the ORM stereotypes:

: orm value

This is not a particularly good idea. We should just add support for
namespaced stereotypes:

: orm::value

We should also change all of the existing stereotypes to have a
namespace:

: modeling::object

And so forth. The namespace name probably needs a bit of thinking.

*** Move enablement into yarn                                         :story:

It seems that the concepts around enablement are actually not kernel
specific but instead can be generalised at the meta-model level. We
need to create adequate representations in yarn to handle facets,
etc. We then need to move across the code that computes enablement
into yarn so that all kernels can make use of it.

Problems:

- we are checking to see if the hash facet is enabled with c++ 98; if
  so, we throw as this facet is incompatible. We cannot do this from
  yarn since we do not know what c++ standards are.
- because we do not have a mapping between a archetype location and
  the meta-type, we will be enabling/disabling all archetype locations
  across all meta-types.
- because we do not have element segmentation, the element extensions
  will be disabled. Actually this will probably work just the same,
  given that all elements exist.
- enablement must be done after external transformations so it picks
  up fabric types.
- we need to support formatting styles in order to be able to use the
  artefact properties from the meta-model.
- in quilt.cpp, someone did an upfront generation of all archetype
  properties against the archetype locations. We not doing that in
  yarn, so nothing is coming out. This was done during transformation
  in formattables.
- with a move into yarn, we seem to have broken the overwrite flag
  logic; changes no longer result in new code being generated.
- we also have borked the includes: dependency builder is looking into
  the formattables instead of element. However, we then run into
  segmentation issues because we cannot find forward declarations on
  the main element.

To do:

- kernel registrar type index map - done.
- c# formatter registrar type index map - done.
- bug in template instantiating: artefact expansions do not seem to
  take kernel into account - done.

*Previous Understanding*

We need to make use of the exact same logic as implemented in
=quilt.cpp= for enablement. Perhaps all of the enablement related
functionality can be lifted and grafted onto quilt without any major
changes.

*** Move formatting styles into yarn                                  :story:

We need to support the formatting styles at the meta-model level.

*** Move element segmentation into yarn                               :story:

We've added the notion that an element can be composed of other
elements in quilt, in order to handle forward declarations. However,
with a little bit of effort we can generalise it into yarn. It would
be useful for other things such as inner classes. We don't need to
actually implement inner classes right now but we should make sure the
moving of this feature into yarn is compatible with it.

Notes:

- seems like we have two use cases: a) we need all elements, master
  and extensions and we don't really care about which is which. b) we
  only want masters. However, we must be able to access the same
  element properties from either the master or the extension. Having
  said all that, it seems we don't really need all of the element
  properties for both - forward declarations probably only need:
  decoration and artefact properties.
- we don't seem to use the map in formattables model anywhere, other
  than to find master/extension elements.
- Yarn model could have two simple list containers (masters and
  all). Or maybe we don't even need this to start off with, we can
  just iterate and skip extensions where required.
- so in conclusion, we to move decoration, enablement and dependencies
  into yarn (basically decoration and artefact properties) first and
  then see where segmentation ends.

Tasks:

- add a concept for element extensions: =Extensible=. Contains a list
  of element pointers.
- populate it with the extensions.
- change enablement to merge all element properties of extensible
  elements.

*** Create a yarn locator                                             :story:

We need to move all functionality which is not kernel specific into
yarn for the locator. This will exist in the helpers namespace. We
then need to implement the C++ locator as a composite of yarn
locator. It will live in fabric.

*Other Notes*

At present we have multiple calls in locator, which are a bit
ad-hoc. We could potentially create a pattern. Say for C++, we have
the following parameters:

- relative or full path
- include or implementation: this is simultaneously used to determine
  the placement (below) and the extension.
- meta-model element:
- "placement": top-level project directory, source directory or
  "natural" location inside of facet.
- archetype location: used to determine the facet and archetype
  postfixes.

E.g.:

: make_full_path_for_enumeration_implementation

Interestingly, the "placement" is a function of the archetype location
(a given artefact has a fixed placement). So a naive approach to this
seems to imply one could create a data driven locator, that works for
all languages if supplied suitable configuration data. To generalise:

- project directory is common to all languages.
- source or include directories become "project
  sub-directories". There is a mapping between the artefact location
  and a project sub-directory.
- there is a mapping between the artefact location and the facet and
  artefact postfixes.
- extensions are a slight complication: a) we want to allow users to
  override header/implementation extensions, but to do it so for the
  entire project (except maybe for ODB files). However, what yarn's
  locator needs is a mapping of artefact location to  extension. It
  would be a tad cumbersome to have to specify extensions one artefact
  location at a time. So someone has to read a kernel level
  configuration parameter with the artefact extensions and expand it
  to the required mappings. Whilst dealing with this we also have the
  issue of elements which have extension in their names such as visual
  studio projects and solutions. The correct solution is to implement
  these using element extensions, and to remove the extension from the
  element name.
- each kernel can supply its configuration to yarn's locator via the
  kernel interface. This is fairly static so it can be supplied early
  on during initialisation.
- there is still something not quite right. We are performing a
  mapping between some logical space (the modeling space) and the
  physical space (paths in the filesystem). Some modeling elements
  such as the various CMakeLists.txt do not have enough information at
  the logical level to tell us about their location; at present the
  formatter itself gives us this hint ("include cmakelists" or "source
  cmakelists"?). It would be annoying to have to split these into
  multiple archetypes just so we can have a function between the
  archetype location and the physical space. Although, if this is the
  only case of a modeling element not mapping uniquely, perhaps we
  should do exactly this.
- However, we still have inclusion paths to worry about. As we done
  with the source/include directories, we need to somehow create a
  concept of inclusion path which is not language specific; "relative
  path" and "requires relative path" perhaps? These could be a
  function of archetype location.

*** Move dependencies into yarn                                       :story:

Actually the dependencies will be generated at the kernel level
because 99% of the code is kernel specific. However, we need to make
it an external transform.

Tasks:

- create the locator in the C++ external transform
- create a dependencies transform that uses the existing include
  generation code.

*Previous understanding*

It seems all languages we support have some form of "dependencies":

- in c++ these are the includes
- in c# these are the usings
- in java these are the imports

So, it would make sense to move these into yarn. The process of
obtaining the dependencies must still be done in a kernel dependent
way because we need to build any language-specific structures that the
dependencies builder requires. However, we can create an interface for
the dependencies builder in yarn and implement it in each kernel. Each
kernel must also supply a factory for the builders.

*** Generate file paths as a transform                                :story:

Add a fabric transform for file path generation.

*** Create "opaque" kernel and element properties                     :story:

As part of the element container, we can have a set of base classes
that are empty: =opaque_element_properties=. This class is then
specialised in each kernel with the properties that are specific to
it. We probably need an equivalent for:

- kernel level properties
- element level properties
- attribute level properties.

We then have to do a lot of casting in the helpers.

Once we got these opaque properties, we can then create "kernel
specific expanders" which are passed in to the yarn workflow. These
populate the opaque properties.

*** Add support for inline namespaces                                 :story:

Enable c++17. - windows requires cpp latest. Then fix inner namespaces
(e.g. a::b::c).

We still need to support the old syntax for pre c++-17.

We need to add a new standard to =quilt.cpp= and when its set to
c++-17 we should automatically use inline namespaces.

*** Move helpers into yarn                                            :story:

Looking at helpers, it is clear that they are common to all
languages. We just need to rename the terminology slightly -
particularly wrt to streaming properties - and then move this code
across into yarn.

*** Move facet properties into yarn                                   :story:

We should be able to handle these generically in yarn.

*** Move ORM camel-case and databases into yarn                       :story:

We should handle this property at the ORM level, rather than at the
ODB level.

Similarly, we should move the ODB databases into yarn and make that a
ORM-level concept.

*** Rename fabric and formattables                                    :story:

In the long run, we should use proper names for these namespaces:

- fabric is meta-model;
- formattables houses transformations.

*** Start documenting the theoretical aspects of Dogen                :story:

Up to now we have more or less coded Dogen as we went along; we
haven't really spent a lot of time worrying about the theory behind
the work we were carrying out. However, as we reached v1.0, the theory
took center stage. We cannot proceed to the next phase of the product
without a firm grasp of the theory. This story is a starting point so
we can decide on how to break up the work.

*** Assorted problems to look at                                      :story:

These need to be put into stories:

- No flat mode: we need to be able to generate no folders at all.
- Registrar coming out even when there is no inheritance.
- No setting to add include for precompiled headers: stdafx.h
- No vcxproj for c++ and no way to add code-generated files. Ideally
  one should be able to include a code-generated file into project
  with list of items
- sort out traits.

*** Add support for proper JSON serialisation in C++                  :story:

We need to add support for JSON in C++. It will eventually have to
roundtrip to JSON in C# but that will be handled as two separate
stories.

Libraries:

- One option is [[https://github.com/cierelabs/json_spirit][json_spirit]].
- Another option is [[https://github.com/miloyip/rapidjson][RapidJson]].
- Actually there is a project comparing JSON libraries: [[https://github.com/miloyip/nativejson-benchmark][nativejson-benchmark]]
- One interesting library is [[https://github.com/dropbox/json11][Json11]].

When we implement this we should provide support for JSON with
roundtripping tests.

We will not replace the current IO implementation; it should continue
to exist as is, requiring no external dependencies.

We should consider supporting multiple JSON libraries: instead of
making the mistake we did with serialisation where we bound the name
=serialization= with boost serialisation, we should call it by its
real name, e.g. =json_spirit= etc. Then when a user creates a
stereotype for a profile such as =Serializable= it can choose which
serialisation codecs to enable for which language. This means that the
same stereotypes can have different meanings in different
architectures, which is the desired behaviour.

We should create a serialise / deserialise functions following the
same logic as boost:

#+begin_src c++
void serialize(Value& v, const object& o);
void serialize(Value& v, const base& b);

void deserialize(const Value& v, object& o);
base* deserialize(const Value& v);
#+end_src

Or perhaps even better, we can make the above the internal methods and
use =operator<<= and =operator>>= as the external methods:

#+begin_src c++
void operator<<(Value& v, const object& o);
void operator>>(const Value& v, object& o);
#+end_src

Notes:

- create a registrar with a map for each base type. The function
  returns a base type pointer.
- when you deserialize a base type pointer, you call the pointer
  deserialize above. Same for when you have a pointer to an object. It
  will internally call the registrar (if its a base type) and get the
  right function.
- this means we only need to look at type for inheritance. Although we
  should probably always do it for validation? However, what happens
  if we want to make a model so we can read external JSON? It won't
  contain type markings.
- =operator>>= will not be defined for pointers or base classes.
- this wont work for the case of =doc << base=. For this we need a map
  that looks up on type_index.

Merged stories:

For the previous attempt to integrate RapidJson see this commit:

b2cce41 * third party: remove includes and rapid json

*Add support for JSON serialisation*

We should have proper JSON serialisation support, for both reading and
writing. We can then implement IO in terms of JSON.

*Raw JSON vs cooked JSON*

If we do implement customisable JSON serialisation, we should still
use the raw format in streaming. We need a way to disable the cooked
JSON internally. We should also re-implement streaming in terms of
this JSON mode.

** Deprecated
