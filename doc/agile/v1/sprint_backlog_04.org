#+title: Sprint Backlog 04
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Perform the exogenous model clean-up in yarn
- Resume and progress the work on moving "generic" types from the
  quilt models into yarn.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2017-08-20 Sun 10:49]
| <75>                                                                        |         |       |       |       |
| Headline                                                                    | Time    |       |       |     % |
|-----------------------------------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                                                | *24:42* |       |       | 100.0 |
|-----------------------------------------------------------------------------+---------+-------+-------+-------|
| Stories                                                                     | 24:42   |       |       | 100.0 |
| Active                                                                      |         | 24:42 |       | 100.0 |
| COMPLETED Edit release notes for previous sprint                            |         |       |  0:35 |   2.4 |
| STARTED Sprint and product backlog grooming                                 |         |       |  0:25 |   1.7 |
| COMPLETED Use shared pointers in all models                                 |         |       |  6:22 |  25.8 |
| COMPLETED Update repository in yarn.dia to use pointers                     |         |       |  2:50 |  11.5 |
| COMPLETED Remove support for upsilon                                        |         |       |  1:10 |   4.7 |
| COMPLETED Add a backwards compatible flag                                   |         |       |  1:27 |   5.9 |
| STARTED Create an exogenous model                                           |         |       | 11:53 |  48.1 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2017-08-01 Tue 21:25]
    CLOCK: [2017-08-01 Tue 20:50]--[2017-08-01 Tue 21:25] =>  0:35

Add github release notes for previous sprint.

Title: Dogen v1.0.03, "Pavilhão"

#+begin_src markdown
![Pavilhão Welvitchia Mirabilis](http://cdn2.portalangop.co.ao/angola/pt_pt/files/highlight/2016/9/42/0,cbf98d54-32d3-4634-b996-6dd02337f9ae.jpg)
_Pavilhão Welvitchia Mirabilis, Moçâmedes, Namibe. (C) Angola Press 2016._

Overview
=======

We continue with yet another sprint refactoring the core in yarn. Initially, the focus was on moving more code from the C++ and C# kernels into yarn, but a series of deficiencies were found on the way we are processing exogenous models and so we switched focus to fixing those. This work will continue into the next sprint.

As part of this sprint we did manage to move away from using ```std::type_index``` and using instead our own meta-meta-model, which is consistent with our conceptual model and notions of modeling spaces. In addition, we cleaned up usages of the type repository, which greatly simplified the code.

User visible changes
===============
There are no user visible changes in this sprint.

For more details of the work carried out this sprint, see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/v1/sprint_backlog_03.org).

Next Sprint
===========
In the next sprint we'll finish the work on exogenous models and resume the work on moving kernel-agnostic transformations from the kernels into yarn.

Binaries
======
You can download binaries from [Bintray](https://bintray.com/domaindrivenconsulting/Dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_1.0.03_amd64-applications.deb](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.03/dogen_1.0.03_amd64-applications.deb)
- [dogen-1.0.03-Darwin-x86_64.dmg](https://dl.bintray.com/domaindrivenconsulting/Dogen/1.0.03/dogen-1.0.03-Darwin-x86_64.dmg)
- [dogen-1.0.03-Windows-AMD64.msi](https://dl.bintray.com/domaindrivenconsulting/Dogen/dogen-1.0.03-Windows-AMD64.msi)

**Note**: They are produced by CI so they may not yet be ready.

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/887172610487922688][Tweet]]
- [[https://www.linkedin.com/feed/update/urn:li:activity:6292938732865617920/][LinkedIn]]
- [[https://gitter.im/DomainDrivenConsulting/dogen][Gitter]]

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2017-08-08 Tue 06:41]--[2017-08-08 Tue 06:53] =>  0:12
    CLOCK: [2017-08-01 Tue 20:43]--[2017-08-01 Tue 20:49] =>  0:06
    CLOCK: [2017-08-01 Tue 20:35]--[2017-08-01 Tue 20:42] =>  0:07

Updates to sprint and product backlog.

*** COMPLETED Use shared pointers in all models                       :story:
    CLOSED: [2017-08-04 Fri 14:30]
    CLOCK: [2017-08-04 Fri 13:58]--[2017-08-04 Fri 14:30] =>  0:32
    CLOCK: [2017-08-04 Fri 10:12]--[2017-08-04 Fri 13:48] =>  3:36
    CLOCK: [2017-08-03 Thu 07:36]--[2017-08-03 Thu 08:21] =>  0:45
    CLOCK: [2017-08-02 Wed 18:05]--[2017-08-02 Wed 18:52] =>  0:47
    CLOCK: [2017-08-02 Wed 07:41]--[2017-08-02 Wed 08:23] =>  0:42

We need to start using unique pointers in exogenous model, and shared
pointers in intermediate model. We should transfer the ownership as we
go along, making the transformers/adapters mutable.

*** COMPLETED Update repository in yarn.dia to use pointers           :story:
    CLOSED: [2017-08-04 Fri 17:14]
    CLOCK: [2017-08-04 Fri 17:27]--[2017-08-04 Fri 17:37] =>  0:10
    CLOCK: [2017-08-04 Fri 17:23]--[2017-08-04 Fri 17:26] =>  0:03
    CLOCK: [2017-08-04 Fri 17:14]--[2017-08-04 Fri 17:23] =>  0:09
    CLOCK: [2017-08-04 Fri 14:45]--[2017-08-04 Fri 17:13] =>  2:28

At present we are using a three-way map from dia object (child) to dia
object (parent) and then from parent to name and then from name to
element. Once the models have pointers we can simply map dia object
directly to parent (and module).

- dia id to module name.
- dia id to parent names
- model name

Notes:

- due to the way we now record parent and child relationships in the
  graph, we caused the order of parents to move. Before we used to
  keep track of all parents for a given child; we now keep track of
  all children for a given parent. When builder starts accumulating
  parents for each children, it now does so from the parent's
  perspective. This seems to have caused the order of the parents to
  change. However, since we still do things in diagram order,
  hopefully the order is stable - just different.

Tasks:

- move model out of repository, into builder.
- rename repository to context.
- create two maps for modules and parent names in context, delete existing maps.
- delete selector.

*** COMPLETED Remove support for upsilon                              :story:
    CLOSED: [2017-08-16 Wed 12:53]
    CLOCK: [2017-08-08 Tue 06:54]--[2017-08-08 Tue 08:04] =>  1:10

It seems we will no longer be using upsilon, so we should remove it as
its adding to the maintenance costs. If required in the future we can
always resurrect it.

This will also hopefully free up some time in the build machine,
solving the amount of red builds we get due to time outs.

*** COMPLETED Add a backwards compatible flag                         :story:
    CLOSED: [2017-08-17 Thu 14:37]
    CLOCK: [2017-08-17 Thu 14:18]--[2017-08-17 Thu 14:37] =>  0:19
    CLOCK: [2017-08-17 Thu 13:45]--[2017-08-17 Thu 14:03] =>  0:18
    CLOCK: [2017-08-17 Thu 10:46]--[2017-08-17 Thu 11:07] =>  0:21
    CLOCK: [2017-08-17 Thu 10:33]--[2017-08-17 Thu 10:45] =>  0:12
    CLOCK: [2017-08-17 Thu 10:15]--[2017-08-17 Thu 10:32] =>  0:17

Backwards compatibility is a problem; we should be able to ignore
types that do not exist. This could be achieved by adding a "backwards
compatibility mode" flag to the command line which tells annotations
transform to proceed regardless. This way we still get strict checking
for the common use case, but can override when required. Log can
suggest this command line option, with a warning.

*** STARTED Create an exogenous model                                 :story:
    CLOCK: [2017-08-20 Sun 10:45]--[2017-08-20 Sun 10:48] =>  0:03
    CLOCK: [2017-08-20 Sun 10:12]--[2017-08-20 Sun 10:44] =>  0:32
    CLOCK: [2017-08-18 Fri 16:48]--[2017-08-18 Fri 16:57] =>  0:09
    CLOCK: [2017-08-18 Fri 15:02]--[2017-08-18 Fri 16:47] =>  1:45
    CLOCK: [2017-08-18 Fri 13:26]--[2017-08-18 Fri 14:02] =>  0:36
    CLOCK: [2017-08-18 Fri 11:39]--[2017-08-18 Fri 11:47] =>  0:08
    CLOCK: [2017-08-18 Fri 10:52]--[2017-08-18 Fri 11:16] =>  0:24
    CLOCK: [2017-08-17 Thu 23:46]--[2017-08-18 Fri 00:15] =>  0:29
    CLOCK: [2017-08-17 Thu 20:45]--[2017-08-17 Thu 21:08] =>  0:23
    CLOCK: [2017-08-17 Thu 17:33]--[2017-08-17 Thu 17:54] =>  0:21
    CLOCK: [2017-08-17 Thu 16:45]--[2017-08-17 Thu 17:15] =>  0:30
    CLOCK: [2017-08-17 Thu 09:43]--[2017-08-17 Thu 09:44] =>  0:01
    CLOCK: [2017-08-16 Wed 22:20]--[2017-08-16 Wed 23:30] =>  1:10
    CLOCK: [2017-08-16 Wed 20:49]--[2017-08-16 Wed 21:41] =>  0:52
    CLOCK: [2017-08-16 Wed 12:23]--[2017-08-16 Wed 13:09] =>  0:46
    CLOCK: [2017-08-06 Sun 21:02]--[2017-08-06 Sun 22:34] =>  1:32
    CLOCK: [2017-08-06 Sun 11:41]--[2017-08-06 Sun 13:53] =>  2:12

At present we are allowing the frontends to directly create
intermediate models. However, this doesn't make a lot of sense: there
are many properties in the intermediate models which should not be
touched by the frontends. We should have a specific model that has
only the properties that can be set by the frontends -
=exogenous_model=. The exogenous model chain is then responsible for
converting it into an intermediate model.

Tasks:

- create the exogenous model with the required attributes. Add a root
  module, remove model name. All containers should be lists of a pair
  of scribble group to concrete element.
- move annotations transform to exogenous chain. Add a transform to
  update element names by reading model modules and external modules.
- drop scribble groups from intermediate model.
- add an adaptor to convert from exogenous model to intermediate
  model.
- use some kind of reference to figure out where to place the
  documentation of a module. We can't use the IDs any longer. We could
  simply remember the list iterators. Since we are only pushing back
  into the list, the iterators should remain valid. However, for this
  to work we need to add support to iterators in dogen or manually
  create the context/repository.
- Refactor yarn.dia, splitting out the model from the repository and
  renaming repository to context.

Notes:

- we need a completely different annotations transform. In the new
  world, scribble updating and annotation updating are done in one go
  by the updater, who has the annotation group as state. The annotation
  classes need to be updated to take in just one scribble group rather
  than a map. The updater needs to be a regular element visitor. The
  transform runs on the exogenous model.
- repository in yarn.dia must not rely on qualified names for lookups;
  instead it must have a pointer to the element, which is known to be
  owned by the model. To make life easier this could be a shared
  pointer with a custom deleter.
- if we changed the graph adding a relationship between the note and
  the package such that the package is always processed after the
  notes it contains; and if we created a map of child to note,
  including a special entry for the "root note"; we could then merge
  the processed objects of the package and the note. This would then
  result in a consistent interface for the transformer. Actually this
  must already be occurring since we are updating the documentation of
  an existing module; however, the order must be in reverse -
  i.e. first the package, then the note. We should really do the note
  first then the package. We can simply create a map of ID ->
  processed object; we then remember the module processed object. When
  the note appears we look up the module and merge it.
- we should force json models to have a model module if they want to
  provide documentation rather than support a documentation key.
- compute model name in naming transform and copy it across to
  intermediate model

Steps:

- update scribble group with stereotypes.
- convert scribble group into annotation group.
- process element annotation.
- process attribute annotations, if stateful.

*** Tailor is not handling initialisation correctly                   :story:

It seems we forgot to update tailor after the logging changes around
initialisation:

: [1/1] Tailoring boost_model.
: [2017-08-18 16:05:05.284950] [0x00007f2329d9f080] [info]    Registrered exogenous transform: yarn.json.exogenous_transform
: [2017-08-18 16:05:05.284992] [0x00007f2329d9f080] [info]    Registrered exogenous transform: yarn.dia.exogenous_transform

*** Add support for field renaming in annotations                     :story:

At present if a field changes its name between dogen releases,
diagrams stop working. For example, we renamed:

: yarn.dia.external_modules

to

: yarn.external_modules

With this change, dogen stopped working. We need some way to
"remember" the previous name before a rename so that previous versions
still work.

*** =Nameable= concept moved position on code generation              :story:

During the exogenous model work, yarn's =Nameable= concept moved
position. We need to look at how the parent changes were done to see
if they are stable or not.

*** Model naming                                                      :story:

- exogenous model: exomodel; all the models obtained externally.
- intermediate model: endogenous model, endomodel; all models used internally.
- model: final model.

*** Rename yarn object types in yarn.dia                              :story:

These are not really object types. We could name them perhaps element
types?

*** Change order of includes according to Lakos major design rule     :story:

Lakos says:

#+begin_quote
The .c file of every component should include its own .h file as the
first substantive line of code.
#+end_quote

We decided to include it as the last line. However, Lakos approach has
the side-effect of automatically detecting headers that are missing
includes. We used to do this manually by generating =.cpp= files that
just included the header but then had to remove it because it was
slowing down compilation. With Lakos approach we get the best of both
worlds.

We need to also update the generated code to follow this
approach. This will require some thinking.

*** Rename =meta_type= in JSON                                        :story:

Now we have meta-names we should use the same terminology for JSON
documents.

*** Add canonical archetype support to yarn                           :story:

We need to add a new attribute in context which captures the canonical
archetypes.

Notes:

- kernel must also return canonical archetype by element type
  index. Perhaps we should have a struct that aggregates both:
  archetype locations for meta-type? Or kernel can just return a
  =std::pair=.
- at present we have placed the canonical archetype resolution as part
  of the element properties. However, we do not need to have this at
  the element level since its a meta-type property and can be
  determined up-front. However, we do need to resolve a name into a
  meta-type before we can resolve a meta-type into a concrete
  archetype.
- we need to unpick the notion of whether a formatter is "includible"
  or not from the notion of canonical archetypes. Canonical archetypes
  is meta-model concept: given a facet and a meta-model type, which
  archetype represents the "key" definition of the element. It just so
  happens that this function has a use in identifying the files to
  include.

Tasks:

- add a map from name id to meta-name id in intermediate model.
- add a map from meta name id to map of canonical archetype to
  archetype location.

*** Move external module processing into yarn                         :story:

At present we have a hack in =yarn.dia= whereby we are looking for a
key =yarn.dia.external_modules= and then using it to populate the
external module path of all names read on that model, as we traverse
the graph of dia objects.

The problem is, this functionality is also required on other frontends
such as JSON. We should use the traditional annotation machinery to
populate the external modules inside of yarn pre-processing.

One thing to bear in mind is that we need to trash all containers and
re-insert all elements, because the IDs will change as part of this
exercise.

*** Enable kernel directories trait is on quilt                       :story:

When we moved the kernel logic into yarn from quilt, we did not rename
the traits.

*** Add models for the executables                                    :story:

At present the executables are all hand-crafted. However, as we want
to move the options into each executable we need them to be in a
model.

Tasks:

- create a model for each executable and add the options to the model;
- create options in yarn and stop using knitting options;
- add meta-data to generate an executable instead of a library in
  CMake.
- generate a main skeleton if one does not exist.
- remove options project.

*** Throw on unsupported stereotypes                                  :story:

In some cases we may support a feature in one language but not on
others like say ORM at present. If a user requests ORM in a C# model,
we should throw.

*** Add a property for the model modules as an annotation             :story:

We should read out the model name as an annotation instead of
inferring it from the filename on some frontends (Dia) and allowing
the user to set it internally on others (JSON).

This is not quite as trivial as it may look: we create the model
module using the model name; this is necessary because we need to read
its annotations and place it in the right element. Without a model
name, this becomes a bit tricky.

*Previous Understanding*

#+begin_quote
*Story*: As a dogen user in a constrained environment, I am forced to
use file names that are not suitable for a model name so that I need
to supply an override somewhere else.
#+end_quote

It would be nice to be able to generate a model with a name other than
the diagram file. We should have a command line option for this that
overrides the default diagram name.

This could also be supplied as part of dynamic extensions. The command
line option is useful when we want to use the same diagram to test
different aspects of the generation, as we do with the tests. The
dynamic extensions option is useful when we don't want the file name
to have the full name of the model.

We now have a use case for this: the dynamic models. See Rename
dynamic models.

*** Rename transformers to adapters                                   :story:

In the past we used the term "transformer" to mean a class that
converts types from one representation to another. However, now that
we are using domain terminology, the term "transforms" is taken to
mean a model transformation. To avoid confusion we should rename the
existing transformers to converters, adapters or some other
out-of-the-way name.

*** Add a modeline to stitch                                          :story:

It would be nice to be able to supply the mode and other emacs
properties to stitch templates. For that we just need a special KVP
used at the top that contains the modeline:

: <#@ modeline="-*- mode: poly-stitch; tab-width: 4; indent-tabs-mode: nil; -*-" #>

Stitch can read this KVP and ignore it.

*** Use namespaced stereotypes                                        :story:

Originally we added a space in the ORM stereotypes:

: orm value

This is not a particularly good idea. We should just add support for
namespaced stereotypes:

: orm::value

We should also change all of the existing stereotypes to have a
namespace:

: modeling::object

And so forth. The namespace name probably needs a bit of thinking.

*** Move enablement into yarn                                         :story:

It seems that the concepts around enablement are actually not kernel
specific but instead can be generalised at the meta-model level. We
need to create adequate representations in yarn to handle facets,
etc. We then need to move across the code that computes enablement
into yarn so that all kernels can make use of it.

Problems:

- we are checking to see if the hash facet is enabled with c++ 98; if
  so, we throw as this facet is incompatible. We cannot do this from
  yarn since we do not know what c++ standards are.
- because we do not have a mapping between a archetype location and
  the meta-type, we will be enabling/disabling all archetype locations
  across all meta-types.
- because we do not have element segmentation, the element extensions
  will be disabled. Actually this will probably work just the same,
  given that all elements exist.
- enablement must be done after external transformations so it picks
  up fabric types.
- we need to support formatting styles in order to be able to use the
  artefact properties from the meta-model.
- in quilt.cpp, someone did an upfront generation of all archetype
  properties against the archetype locations. We not doing that in
  yarn, so nothing is coming out. This was done during transformation
  in formattables.
- with a move into yarn, we seem to have broken the overwrite flag
  logic; changes no longer result in new code being generated.
- we also have borked the includes: dependency builder is looking into
  the formattables instead of element. However, we then run into
  segmentation issues because we cannot find forward declarations on
  the main element.

To do:

- kernel registrar type index map - done.
- c# formatter registrar type index map - done.
- bug in template instantiating: artefact expansions do not seem to
  take kernel into account - done.

*Previous Understanding*

We need to make use of the exact same logic as implemented in
=quilt.cpp= for enablement. Perhaps all of the enablement related
functionality can be lifted and grafted onto quilt without any major
changes.

*** Move formatting styles into yarn                                  :story:

We need to support the formatting styles at the meta-model level.

*** Move element segmentation into yarn                               :story:

We've added the notion that an element can be composed of other
elements in quilt, in order to handle forward declarations. However,
with a little bit of effort we can generalise it into yarn. It would
be useful for other things such as inner classes. We don't need to
actually implement inner classes right now but we should make sure the
moving of this feature into yarn is compatible with it.

Notes:

- seems like we have two use cases: a) we need all elements, master
  and extensions and we don't really care about which is which. b) we
  only want masters. However, we must be able to access the same
  element properties from either the master or the extension. Having
  said all that, it seems we don't really need all of the element
  properties for both - forward declarations probably only need:
  decoration and artefact properties.
- we don't seem to use the map in formattables model anywhere, other
  than to find master/extension elements.
- Yarn model could have two simple list containers (masters and
  all). Or maybe we don't even need this to start off with, we can
  just iterate and skip extensions where required.
- so in conclusion, we to move decoration, enablement and dependencies
  into yarn (basically decoration and artefact properties) first and
  then see where segmentation ends.

Tasks:

- add a concept for element extensions: =Extensible=. Contains a list
  of element pointers.
- populate it with the extensions.
- change enablement to merge all element properties of extensible
  elements.

*** Create a yarn locator                                             :story:

We need to move all functionality which is not kernel specific into
yarn for the locator. This will exist in the helpers namespace. We
then need to implement the C++ locator as a composite of yarn
locator. It will live in fabric.

*Other Notes*

At present we have multiple calls in locator, which are a bit
ad-hoc. We could potentially create a pattern. Say for C++, we have
the following parameters:

- relative or full path
- include or implementation: this is simultaneously used to determine
  the placement (below) and the extension.
- meta-model element:
- "placement": top-level project directory, source directory or
  "natural" location inside of facet.
- archetype location: used to determine the facet and archetype
  postfixes.

E.g.:

: make_full_path_for_enumeration_implementation

Interestingly, the "placement" is a function of the archetype location
(a given artefact has a fixed placement). So a naive approach to this
seems to imply one could create a data driven locator, that works for
all languages if supplied suitable configuration data. To generalise:

- project directory is common to all languages.
- source or include directories become "project
  sub-directories". There is a mapping between the artefact location
  and a project sub-directory.
- there is a mapping between the artefact location and the facet and
  artefact postfixes.
- extensions are a slight complication: a) we want to allow users to
  override header/implementation extensions, but to do it so for the
  entire project (except maybe for ODB files). However, what yarn's
  locator needs is a mapping of artefact location to  extension. It
  would be a tad cumbersome to have to specify extensions one artefact
  location at a time. So someone has to read a kernel level
  configuration parameter with the artefact extensions and expand it
  to the required mappings. Whilst dealing with this we also have the
  issue of elements which have extension in their names such as visual
  studio projects and solutions. The correct solution is to implement
  these using element extensions, and to remove the extension from the
  element name.
- each kernel can supply its configuration to yarn's locator via the
  kernel interface. This is fairly static so it can be supplied early
  on during initialisation.
- there is still something not quite right. We are performing a
  mapping between some logical space (the modeling space) and the
  physical space (paths in the filesystem). Some modeling elements
  such as the various CMakeLists.txt do not have enough information at
  the logical level to tell us about their location; at present the
  formatter itself gives us this hint ("include cmakelists" or "source
  cmakelists"?). It would be annoying to have to split these into
  multiple archetypes just so we can have a function between the
  archetype location and the physical space. Although, if this is the
  only case of a modeling element not mapping uniquely, perhaps we
  should do exactly this.
- However, we still have inclusion paths to worry about. As we done
  with the source/include directories, we need to somehow create a
  concept of inclusion path which is not language specific; "relative
  path" and "requires relative path" perhaps? These could be a
  function of archetype location.

*** Move dependencies into yarn                                       :story:

Actually the dependencies will be generated at the kernel level
because 99% of the code is kernel specific. However, we need to make
it an external transform.

Tasks:

- create the locator in the C++ external transform
- create a dependencies transform that uses the existing include
  generation code.

*Previous understanding*

It seems all languages we support have some form of "dependencies":

- in c++ these are the includes
- in c# these are the usings
- in java these are the imports

So, it would make sense to move these into yarn. The process of
obtaining the dependencies must still be done in a kernel dependent
way because we need to build any language-specific structures that the
dependencies builder requires. However, we can create an interface for
the dependencies builder in yarn and implement it in each kernel. Each
kernel must also supply a factory for the builders.

*** Generate file paths as a transform                                :story:

Add a fabric transform for file path generation.

*** Create "opaque" kernel and element properties                     :story:

As part of the element container, we can have a set of base classes
that are empty: =opaque_element_properties=. This class is then
specialised in each kernel with the properties that are specific to
it. We probably need an equivalent for:

- kernel level properties
- element level properties
- attribute level properties.

We then have to do a lot of casting in the helpers.

Once we got these opaque properties, we can then create "kernel
specific expanders" which are passed in to the yarn workflow. These
populate the opaque properties.

*** Add support for inline namespaces                                 :story:

Enable c++17. - windows requires cpp latest. Then fix inner namespaces
(e.g. a::b::c).

We still need to support the old syntax for pre c++-17.

We need to add a new standard to =quilt.cpp= and when its set to
c++-17 we should automatically use inline namespaces.

*** Move helpers into yarn                                            :story:

Looking at helpers, it is clear that they are common to all
languages. We just need to rename the terminology slightly -
particularly wrt to streaming properties - and then move this code
across into yarn.

*** Move facet properties into yarn                                   :story:

We should be able to handle these generically in yarn.

*** Move ORM camel-case and databases into yarn                       :story:

We should handle this property at the ORM level, rather than at the
ODB level.

Similarly, we should move the ODB databases into yarn and make that a
ORM-level concept.

*** Rename fabric and formattables                                    :story:

In the long run, we should use proper names for these namespaces:

- fabric is meta-model;
- formattables houses transformations.

*** Start documenting the theoretical aspects of Dogen                :story:

Up to now we have more or less coded Dogen as we went along; we
haven't really spent a lot of time worrying about the theory behind
the work we were carrying out. However, as we reached v1.0, the theory
took center stage. We cannot proceed to the next phase of the product
without a firm grasp of the theory. This story is a starting point so
we can decide on how to break up the work.

*** Assorted problems to look at                                      :story:

These need to be put into stories:

- No flat mode: we need to be able to generate no folders at all.
- Registrar coming out even when there is no inheritance.
- No setting to add include for precompiled headers: stdafx.h
- No vcxproj for c++ and no way to add code-generated files. Ideally
  one should be able to include a code-generated file into project
  with list of items
- sort out traits.

*** Add support for proper JSON serialisation in C++                  :story:

We need to add support for JSON in C++. It will eventually have to
roundtrip to JSON in C# but that will be handled as two separate
stories.

Libraries:

- One option is [[https://github.com/cierelabs/json_spirit][json_spirit]].
- Another option is [[https://github.com/miloyip/rapidjson][RapidJson]].
- Actually there is a project comparing JSON libraries: [[https://github.com/miloyip/nativejson-benchmark][nativejson-benchmark]]
- One interesting library is [[https://github.com/dropbox/json11][Json11]].

When we implement this we should provide support for JSON with
roundtripping tests.

We will not replace the current IO implementation; it should continue
to exist as is, requiring no external dependencies.

We should consider supporting multiple JSON libraries: instead of
making the mistake we did with serialisation where we bound the name
=serialization= with boost serialisation, we should call it by its
real name, e.g. =json_spirit= etc. Then when a user creates a
stereotype for a profile such as =Serializable= it can choose which
serialisation codecs to enable for which language. This means that the
same stereotypes can have different meanings in different
architectures, which is the desired behaviour.

We should create a serialise / deserialise functions following the
same logic as boost:

#+begin_src c++
void serialize(Value& v, const object& o);
void serialize(Value& v, const base& b);

void deserialize(const Value& v, object& o);
base* deserialize(const Value& v);
#+end_src

Or perhaps even better, we can make the above the internal methods and
use =operator<<= and =operator>>= as the external methods:

#+begin_src c++
void operator<<(Value& v, const object& o);
void operator>>(const Value& v, object& o);
#+end_src

Notes:

- create a registrar with a map for each base type. The function
  returns a base type pointer.
- when you deserialize a base type pointer, you call the pointer
  deserialize above. Same for when you have a pointer to an object. It
  will internally call the registrar (if its a base type) and get the
  right function.
- this means we only need to look at type for inheritance. Although we
  should probably always do it for validation? However, what happens
  if we want to make a model so we can read external JSON? It won't
  contain type markings.
- =operator>>= will not be defined for pointers or base classes.
- this wont work for the case of =doc << base=. For this we need a map
  that looks up on type_index.

Merged stories:

For the previous attempt to integrate RapidJson see this commit:

b2cce41 * third party: remove includes and rapid json

*Add support for JSON serialisation*

We should have proper JSON serialisation support, for both reading and
writing. We can then implement IO in terms of JSON.

*Raw JSON vs cooked JSON*

If we do implement customisable JSON serialisation, we should still
use the raw format in streaming. We need a way to disable the cooked
JSON internally. We should also re-implement streaming in terms of
this JSON mode.

*** Add support for object cloning                                    :story:

#+begin_quote
*Story*: As a dogen user, I want to be able to clone object state so
that I don't have to do this manually.
#+end_quote

We should have a clone method which copy constructs all non-pointer
types, and then creates new objects for pointer types.

Ideally users should be able to mark specific object as "cloneable"
rather than generate clone methods for all objects in a model since it
only makes sense for objects which have pointers. We need some
meta-data knob to control the generation of the clone method.

** Deprecated
*** CANCELLED Map upsilon primitives to intrinsics                    :story:
    CLOSED: [2017-08-08 Tue 06:51]

*Rationale*: Upsilon is to be removed.

Upsilon allows users to create "strong typedefs" around primitve
types. We need to unpack these into their intrinsic counterparts and
them map the intrinsics to native types.

Slight mistake: we mapped the primitive types themselves but in
reality what needs to be mapped are the fields making references to
the primitive types. We should just filter out all primitives.

Additional wrinkle: what the end users want is to unpack "real
primitives" into intrinsics, but "other" primitives should be mapped
to objects. This can be achieved by hard-coding =Plaform= primitives
into the mapping layer. However, some non-platform primitives may also
be candidates too. We need to create a list of these to see how
widespread the problem is.

Another alternative is to apply hard-coded regexes:

- if the name matches any of the intrinsic names

Finally, the last option may be to have yet another mapping data file
format that lists the primitives to unbox.

*** CANCELLED Add mapping support between upsilon and LAM             :story:
    CLOSED: [2017-08-08 Tue 06:51]

*Rationale*: Upsilon is to be removed.

At present we map upsilon directly to a language-specific model
(C++/C#), which gets code-generated. However, from a tailor
perspective, this is not ideal; we would end up with N different
models. Ideally, we should get a LAM representation of the JSON model
which could then be used to code-generate multiple languages.

This is probably not too hard, given the mapper knows how to convert
between upsilon and LAM. We just need to finish LAM support and then
try mapping them and see what breaks. Tailor would have to somehow
tell yarn to set the output language to LAM.

Notes:

- if output is more than one language, change it to LAM. Otherwise
  leave it as language specific.
- we need to inject via meta-data the annotations for the output
  languages.
- We only need to perform mapping if input language is upsilon. For
  all other languages we can leave it as is. But for upsilon, tailor
  needs to do a full intermediate model workflow.
- unparsed type needs to be recomputed as part of mapping.
- we are not adding the LAM mapping to the upsilon id container.
- we need to add support for "default mappings"

*** CANCELLED Enumerations coming out of Upsilon are empty            :story:
    CLOSED: [2017-08-08 Tue 06:51]

*Rationale*: Upsilon is to be removed.

We don't seem to be translating the enumerators into yarn
enumerators.

*** CANCELLED Do not generate upsilon proxy models                    :story:
    CLOSED: [2017-08-08 Tue 06:51]

*Rationale*: Upsilon is to be removed.

At present we are marking all types in an upsilon config as target. In
practice, only one of the models is the target.
