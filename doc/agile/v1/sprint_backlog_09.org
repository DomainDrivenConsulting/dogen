#+title: Sprint Backlog 09
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Start the planning towards v2: get a good idea of what we think is
  in and what should be out. Make the product backlog reflect this
  triage.
- Address build issues; the build must work reliably and the tests
  must give us confidence that we did not break the code generator
  across the entire feature set.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2018-10-05 Fri 11:36]
| <75>                                                                        |         |       |      |       |
| Headline                                                                    | Time    |       |      |     % |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| *Total time*                                                                | *20:14* |       |      |   0.0 |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| Stories                                                                     | 20:14   |       |      |   0.0 |
| Active                                                                      |         | 20:14 |      |   0.0 |
| Edit release notes for previous sprint                                      |         |       | 1:30 |   0.0 |
| Sprint and product backlog grooming                                         |         |       | 2:30 |   0.0 |
| Update readme to reflect org move                                           |         |       | 1:58 |   0.0 |
| Create project for C# test model                                            |         |       | 5:23 |   0.0 |
| Fix boost path serialisation errors                                         |         |       | 0:47 |   0.0 |
| Create project for C++ test model                                           |         |       | 6:55 |   0.0 |
| Update readme with information on reference models                          |         |       | 0:10 |   0.0 |
| Remove test models from dogen project                                       |         |       | 1:01 |   0.0 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2018-10-02 Tue 17:51]
    :LOGBOOK:
    CLOCK: [2018-10-02 Tue 15:30]--[2018-10-02 Tue 17:00] =>  1:30
    :END:

Add github release notes for previous sprint.

Title: Dogen v1.0.08, "Caminhada"

#+begin_src markdown
![Caminhada](https://i2.wp.com/cookthebeans.com/wp-content/uploads/2017/03/img_5465.jpg) _Long walk towards a traditional village, Huambo, Angola. [(C) Ana Rocha 2017](https://cookthebeans.com/2017/03/09/benguela-huambo-bie-in-the-route-of-angolas-up-country)_.

# Overview

After a rather long hiatus of some nine months, Dogen development resumes once more. In truth, the break was only related to the open source aspect of the Dogen project; behind the scenes I have been hard at work on my PhD, which has morphed into an attempt to lay the theoretical foundations for all the software engineering that has been done with Dogen. Sadly, I cannot perform that work out in the open until the thesis or papers are published, so it is expected to remain closed for at least another year or two.

On the bright side, after performing an extensive literature review of the field of [Model Driven Engineering](https://en.wikipedia.org/wiki/Model-driven_engineering) - the technical name used in academia for the field Dogen is in - a lot of what we have been trying to do has finally become clear. The down side is that, as a result of all of this theoretical work, very little has changed with regards to the code during this period. As such, this sprint contains only some minor analysis work that was done in parallel, and I am closing it just avoid conflating it with the new work going forward.

The future for Dogen is bright, though. We are now starting the long road towards the very ambitious release that will be Dogen 2.0. The objective is to sync the code to match all of the work done on the theory side. This work as already started; you will not fail to notice that the repository has been moved to the _MASD project_ - Model Assisted Software Development.

User visible changes
================

There are no user visible changes this sprint.

Next Sprint
===========

The next few sprints will be extremely active, addressing a number of long standing issues such as moving test models outside of the main repo and concluding ongoing refactorings.

Binaries
======

Due to the transition of organisations, we did not generate any binaries for this release. As there are no code changes, please use the binaries for the previous release ([v1.0.07](https://github.com/MASD-Project/dogen/releases/tag/v1.0.07)) or build Dogen from source. Source downloads are available at the top.
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/948594830267043840][Tweet]]
- [[https://www.linkedin.com/feed/update/urn:li:activity:6354361007493775361][LinkedIn]]
- [[https://gitter.im/DomainDrivenConsulting/dogen][Gitter]]

*** STARTED Sprint and product backlog grooming                       :story:
    :LOGBOOK:
    CLOCK: [2018-10-05 Fri 10:14]--[2018-10-05 Fri 11:25] =>  1:11
    CLOCK: [2018-10-05 Fri 09:06]--[2018-10-05 Fri 10:13] =>  1:07
    CLOCK: [2018-10-04 Thu 17:44]--[2018-10-04 Thu 17:56] =>  0:12
    :END:

Updates to sprint and product backlog.

*** COMPLETED Update readme to reflect org move                       :story:
    CLOSED: [2018-10-03 Wed 10:39]
    :LOGBOOK:
    CLOCK: [2018-10-03 Wed 10:02]--[2018-10-03 Wed 10:38] =>  0:36
    CLOCK: [2018-10-03 Wed 09:54]--[2018-10-03 Wed 10:01] =>  0:07
    CLOCK: [2018-10-03 Wed 09:15]--[2018-10-03 Wed 09:53] =>  0:38
    CLOCK: [2018-10-02 Tue 17:52]--[2018-10-02 Tue 18:29] =>  0:37
    :END:

Now that dogen is under MASD, we have a number of links that are
pointing to the old Domain Driven Consulting org. Update those.

*** COMPLETED Analysis on reducing build times to avoid timeouts      :story:
    CLOSED: [2018-10-03 Wed 10:40]

Refactoring at the moment is painful because every time we change
CMakeFiles we end up rebuilding everything. At 2K plus ninja targets,
it is a long wait. In addition, we have been getting really close to
the maximum travis time, resulting in lots of manual fiddling to get
things to work. However, there is one very easy win: split test models
from production code. This is more than just a quick hack, really:

- we are compiling the test models with every build at present, but
  since they are not production code, we only really need to validate
  them whenever they change. That is - for a given OS, compiler, etc -
  once a test model compiles, links and its tests run, nothing else
  needs to be said until the test model changes.
- test models change very infrequently; only when we do a breaking
  change on Dogen and we rebase.
- test models by definition do not reference production code (or at
  least, /should/ not).

As a first step we should try to isolate the two builds (production,
test models) via variables so that we can create separate
travis/appveyor builds for them. In the future we should make the
separation even more explicit, by moving the folder away from the
production code.

*Previous Understanding*

At present we get random build time violations on travis due to builds
taking longer than 50 mins. We need to think of ways to reduce the
build time. Things to try:

- remove all of the hashing etc for the types we don't need to hash.
- get rid of the warnings for boost.

*** COMPLETED Create project for C# test model                        :story:
    CLOSED: [2018-10-03 Wed 16:18]
    :LOGBOOK:
    CLOCK: [2018-10-04 Thu 13:45]--[2018-10-04 Thu 13:56] =>  0:11
    CLOCK: [2018-10-04 Thu 08:47]--[2018-10-04 Thu 09:02] =>  0:15
    CLOCK: [2018-10-04 Thu 08:15]--[2018-10-04 Thu 08:46] =>  0:31
    CLOCK: [2018-10-03 Wed 15:46]--[2018-10-03 Wed 16:18] =>  0:32
    CLOCK: [2018-10-03 Wed 15:40]--[2018-10-03 Wed 15:45] =>  0:05
    CLOCK: [2018-10-03 Wed 12:45]--[2018-10-03 Wed 14:59] =>  2:14
    CLOCK: [2018-10-03 Wed 10:45]--[2018-10-03 Wed 12:18] =>  2:20
    CLOCK: [2018-10-03 Wed 10:42]--[2018-10-03 Wed 10:44] =>  0:02
    :END:

We need to create a separate repo for the C# test model. This also
means we need to generate the LAM model in two different locations.

*** COMPLETED Fix boost path serialisation errors                     :story:
    CLOSED: [2018-10-04 Thu 13:11]
    :LOGBOOK:
    CLOCK: [2018-10-04 Thu 12:47]--[2018-10-04 Thu 13:11] =>  0:24
    CLOCK: [2018-10-04 Thu 11:02]--[2018-10-04 Thu 11:25] =>  0:23
    :END:

When we use boost path outside of dogen, the code fails to compile:

: /home/marco/Development/DomainDrivenConsulting/hedgr/projects/hedgr.personae.comms.llcp_server/src/serialization/options_ser.cpp:27:10: fatal error: dogen.utility/serialization/path.hpp: No such file or directory
: #include "dogen.utility/serialization/path.hpp"

Dogen has hard-coded the serialisation to its own utilities. We should
be using a helper instead.

*** COMPLETED Create project for C++ test model                       :story:
    CLOSED: [2018-10-04 Thu 16:01]
    :LOGBOOK:
    CLOCK: [2018-10-04 Thu 16:20]--[2018-10-04 Thu 16:41] =>  0:21
    CLOCK: [2018-10-04 Thu 13:57]--[2018-10-04 Thu 16:01] =>  2:04
    CLOCK: [2018-10-04 Thu 13:13]--[2018-10-04 Thu 13:44] =>  0:31
    CLOCK: [2018-10-04 Thu 09:29]--[2018-10-04 Thu 11:01] =>  1:32
    CLOCK: [2018-10-04 Thu 09:03]--[2018-10-04 Thu 09:28] =>  0:25
    CLOCK: [2018-10-03 Wed 16:18]--[2018-10-03 Wed 18:20] =>  2:02
    :END:

Create a separate repo for the C++ test model.

Notes on testing:

- some tests do not make sense in a reference implementation:
  - class without a name, package without a name: these are just
    validation tests so we should do it as a unit test.
  - disable all kernels: doesn't generate anything. Not sure where it
    should go.
  - empty and two empty layers: not even valid any more as we must
    supply model modules. Can be done as a unit test once defaulting
    is in place.
- we have failures on hasing on both OSX and Windows. However, its
  very difficult to debug these due to the heavy use of templates in
  tests. We should probably wait until tests become facets and then
  ensure the boost log message contains a dump of the object state for
  each test.

Problems to fix:

- at present we have oracle support on ODB. Oracle libs are not
  distributed with debian. If we do not find oracle we do not compile
  northwind. This is not ideal. We should remove oracle support from
  northwind, and install odb support in the build machine (hopefully
  available as debs).
- all path and directories is a LAM model. Move the C# part into C#.
- models are under external module path =dogen::test_models=. Move
  them to =cpp_ref_impl=.
- path serialisation depends on dogen utility. Fix code generation so
  that it doesn't.
- some models have the postfix "model". Remove it.
- rename =cpp_model= to =cpp_11=.
- rename =std_model= to =stl=.
- we are generating solutions and VC projects but not testing
  these. We should probably have a separate build on AppVeyor that
  uses the solutions instead of CMake. However, as we do not have
  project level support yet, this will be hard to do (e.g. we generate
  one solution per component).
- not clear what the seam model does.

Notes:

- remove story about not building all the tests.

*** COMPLETED Add flat directory model to C#                          :story:
    CLOSED: [2018-10-04 Thu 16:01]

It seems this model is also a LAM model. Add it to C#.

*** COMPLETED Update readme with information on reference models      :story:
    CLOSED: [2018-10-05 Fri 11:36]
    :LOGBOOK:
    CLOCK: [2018-10-05 Fri 11:26]--[2018-10-05 Fri 11:36] =>  0:10
    :END:

We need to add some minor blurb about MASD and refer to the reference
implementation.

*** STARTED Remove test models from dogen project                     :story:
    :LOGBOOK:
    CLOCK: [2018-10-04 Thu 16:42]--[2018-10-04 Thu 17:43] =>  1:01
    :END:

Once we have created projects for both C# and C++, we need to delete
all references to test models:

- delete source code from projects;
- delete test data sets;
- remove environment variables (WITH_CSHARP, WITH_CPP etc);
- comment out generation tests for now (JSON and Dia).

*** Split dogen testing from core                                     :story:

At present we have tests in modeling that perform "code generation";
that is, regenerate all dogen test models from JSON and Dia. These are
boost unit tests. Due to this, we have welded the test models with the
core models, which means that we cannot easily separate repos without
a lot of hacks. However, if we were to generalise the problem: there
is no reason why test models should be coupled with the core or
treated specially; they are just an instance of a project with dogen
models which can be used to validate dogen. A better approach is to
move all this work to "system testing", done using the dogen binary
rather than within unit tests. This would work as follows:

- add a mode in dogen called "validation mode" or diagnostics, etc. In
  this mode, dogen does not write files to the file system but instead
  produces a number of "reports":
  - a list of all validation errors, if any, in GCC format, pointing
    to the original models.
  - a set of diff files with all the differences, if any.
  - a benchmark report.
  - a top-level report with the project name, its git repo and the git
    commit.
- projects that wish to help dogen must have a well-defined target to
  generate the reports for all models under test.
- dogen project contains a script with a list of such projects and
  their git repos. Every time we build dogen core we install the
  package into the travis VM and run the reports.
- a environment variable containing the path into which to write the
  reports must be set before running dogen.
- a git repo is created with all the reports, and a structure as
  follows:
  /repo
      /branch
          /dogen_commit
              /summary for this commit
              /project_a
                  /summary for this commit
                  /diffs
                  /errors
                  /benchmark data
              /project_b
 ...
- to avoid clashes, make the branches named after the build,
  e.g. travis osx etc.
- git clones are shallow (1 commit)
- once all reports are generated into the git report repo, the build
  commits the report. The comment is the dogen commit.
- a travis build is triggered on the back of the commit. It checks the
  latest commit. If the report is a pass the build is green, if its a
  fail the build is red.
- in an ideal world the system tests build is separate from the dogen
  core build, and triggered from a bintray upload. However, as we do
  not know how to do this yet, we can just run the system tests at the
  end of the dogen build.
- we should split the reporting work from the build separation. We
  could have a simple build that just fails if there are any diffs to
  start off with and worry about reporting later.

With this approach we can have any number of projects contributing to
validate dogen (including dogen itself). The only slight downside is
that the models must always be up-to-date (e.g. if the user has
changed the model but not regenerated, system tests will
fail). Perhaps we could have different categories of test models:
mandatory and optional. Mandatory must pass, optional do not
contribute to the build failing. However, they still show up in the
report.

Links:

- https://github.com/cubicdaiya/dtl

*** Add basic "diff mode"                                             :story:

We need a very simple way of checking all generated files in memory
against what's in the file system and returning a flag if they are
different. We can then use these flags to determine if tests pass. In
the future we can extend this approach to include a proper diff of the
files, but for now we just need a reliable way to run system tests
again.

*** Rework the tests using diff mode                                  :story:

Once we have diff mode, we need to find some kind of workflow for
tests:

- each product is composed of a git URL and a list of models.
- we git clone all repos as part of the build process.
- directories and model locations are hard-coded in each test.
- test runs against the model and hard-coded location, produces the
  diff. Test asserts of the diff being non-zero.

*** Fix the northwind model                                           :story:

There are numerous problems with this model:

- at present we have oracle support on ODB. Oracle libs are not
  distributed with debian. If we do not find oracle we do not compile
  northwind. This is not ideal. We should remove oracle support from
  northwind, and install odb support in the build machine (hopefully
  available as debs).
- the tests are commented out and require a clean up.
- the tests require a database to be up.

Notes:

- it is possible to setup [[https://docs.travis-ci.com/user/database-setup/#postgresql][postgres on travis]]

*** Simplify split configuration configuration                        :story:

At present we have two separate command line parameters to configure
the main output directory and the directory for header files. The
second parameter is used for split configurations. The problem is that
we now need to treat split configuration projects specially because of
this. It makes more sense to force the header directory to be relative
to the output path and make it a meta-data parameter.

*** Update all stereotypes to masd                                    :story:

We need to start distinguishing MASD from dogen. The profile for UML
is part of MASD rather than dogen, so we should update all stereotypes
to match. We need to make a decision regarding the "dia extensions" -
its not clear if its MASD or dogen.

*** Make "ignore regexes" a model property                            :story:

At present we have a command line option:
=--ignore-files-matching-regex=. It is used to ignore files in a
project. However, the problem is, because it is a command line option,
it must be supplied with each invocation of Dogen. This means that if
we want to run dogen from outside the build system, we need to know
what options were set in the build scripts or else we will have
different results. This is a problem for testing. We should make it a
meta-data option, which is supplied with each model and even more
interesting, can be used with profiling. This means we can create
profiles for specific purposes (ODB, lisp, etc) and then reuse them in
different projects.

*** Incorrect generation when changing external modules               :story:

When fixing the C# projects, we updated the external modules, from
=dogen::test_models= to =CSharpRefImpl=. Regenerating the model
resulted in updated project files but the rest of the code did not
change. It worked by using =-f=. It should have worked without forcing
the write.

*** Code coverage does not work for C#                                :story:

It seems that using NUnit and OpenCov does not work. The main reason
appears to be the use of shadow copying, which is no longer optional
on NUnit 3.

Links:

- https://github.com/Ullink/gradle-opencover-plugin/issues/1
- https://github.com/codecov/example-csharp/blob/master/appveyor.yml
- https://www.appveyor.com/blog/2017/03/17/codecov/

*** Improve comments on reference implementation                      :story:

At present it is very difficult to understand what each model and/or
each type does in the reference implementations. We need to add some
comments to make it more obvious.

*** Code generate C# models using msbuild                             :story:

At present we did a quick hack to code generate in C#: a simple bash
script that runs dogen. However, this is not how we expect the end
user to consume it; there should be a msbuild target that:

- detects the code generator;
- contains the configuration (e.g. options, location of models);'
- runs the code generator - possibly every time models change;
- has a tailor target to generate JSON.

*** Add project documentation                                         :story:

We should be able to create a simple set of docs following on from the
[[https://ned14.github.io/outcome/][outcome project]]. They seem to be using Hugo.

Links:

- https://github.com/foonathan/standardese
- https://github.com/ned14/outcome/tree/develop/doc/src

*** Create the =generation= model                                     :story:

Create a new model called =generation= and move all code-generation
related class to it.

We need to create classes for element properties and make model have a
collection that is a pair of element and element properties. We need a
good name for this pair:

- extended element
- augmented element
- decorated element: though not using the decorator pattern; also, we
  already have decoration properties so this is confusing.

Alternatively we could just call it =element= and make it contain a
modeling element.

Approach:

- create a new generation model, copying across all of the meta-model
  and transform classes from yarn. Get the model to transform from
  endomodel to generation model.
- augment formattables with the new element properties. Supply this
  data via the context or assistant.

Problems:

- all of the transforms assume access to the modeling element means
  access to the generation properties. However, with the introduction
  of the generation element we now have a disconnect. For example, we
  sometimes sort and bucket the elements, and then modify them; this
  no longer works with generation elements because these are not
  pointers. It would be easier to make the generation properties a
  part of the element. This is an ongoing discussion we've had since
  the days of formattables. However, in formattables we did write all
  of the transforms to take into account the formattable contained
  both the element and the formattable properties, whereas now we need
  to update all transforms to fit this approach. This is a lot more
  work. The quick hack is to slot in the properties directly into the
  element as some kind of "opaque properties". We could create a base
  class =opaque_properties= and then have a container of these in
  element. However, to make it properly extensible, the only way is to
  make it a unordered set of pointers.

*** Create a =ci= folder in build                                     :story:

We should use the same approach as nupic for organising the scripts: a
top-level =ci= folder with folders per CI system. We should also
follow their naming convention for the build scripts which seem to
follow the CI events.

Links:

- https://github.com/numenta/nupic.core/tree/master/ci

** Deprecated
*** CANCELLED Create a build script just for C#                       :story:
    CLOSED: [2018-10-04 Thu 17:50]

*Rationale*: no longer needed after the split of reference models.

At the moment we are doing C++ and C# on the same build script, making
it really complex. It would be much easier to have a separate C# build
script. We should also have a separate install script for C# so we
don't have to waste time installing packages if we're not going to use
them.

*** CANCELLED Create a new exoelement chain                           :story:
    CLOSED: [2018-10-04 Thu 17:54]

*Rationale*: given the amount of churn the refactor stories have had,
this story is no longer relevant.

We need to create a new exoelement chain that uses the new exoelements
to bootstrap a endomodel.

*** CANCELLED Start documenting the theoretical aspects of Dogen      :story:
    CLOSED: [2018-10-05 Fri 10:28]

*Rationale*: this will be taken care of by the thesis.

Up to now we have more or less coded Dogen as we went along; we
haven't really spent a lot of time worrying about the theory behind
the work we were carrying out. However, as we reached v1.0, the theory
took center stage. We cannot proceed to the next phase of the product
without a firm grasp of the theory. This story is a starting point so
we can decide on how to break up the work.

*** CANCELLED Sections to add to manual                               :story:
    CLOSED: [2018-10-05 Fri 10:29]

*Rationale*: this will be taken care of by the thesis.

Random list of things that we need to have in manual:

- Drivers/frontends: The importance of drivers to allow existing
  frameworks to interoperate; eCore, MSVC, Dia, JSON.  Structural
  variability at modeling level. Dia frontend: use of colours,
  validation (checking of stereotypes), "on the impact of layout
  quality to understanding UML diagrams", this constrains the size of
  a model.
- Stitch. Variability regions vs aspects (Oberweis paper "modeling
  variability in template-based code generators"). Why we need both
  feature modeling and variability regions / aspects: because features
  are a high-level concept that is implemented using variability
  regions. We need to map layers to facets and to our generation
  model. Dependencies between features and variability regions.
- External integration and its importance, cartridges. integration
  with Clang, ODB, XML tool.
- Agile and MDD: tight integration. Lightweight MDD with agile

*** CANCELLED Use the in-memory interface of LibXml                   :story:
    CLOSED: [2018-10-05 Fri 10:30]

*Rationale*: we should just drop libxml altogether and use XSD tool.

At present, our C++ wrappers on top of LibXml are using the file based
interface. We should do in-memory processing of the XML file. Once
this is in place, we can change the exogenous transformers to use
strings rather than paths to files.

*** CANCELLED Consider simplifying frontend testing                   :story:
    CLOSED: [2018-10-05 Fri 11:01]

*Rationale*: this will be resolved with the new diff based tests.

At present we are outputting code for every supported frontend, and
then checking they are binary identical. This is fine given that we
only have two frontends. Once we had a visual studio frontend, it may
make more sense to stop generating code for all frontends and simply
diff the middle-end to ensure we generate an identical yarn model. We
can continue to test end to end one of the frontends (dia).

We had command line options available in the past that generated only
a merged model. We need to look into the backlog for these.

This is a problem specially in light of adding new backends because
now we are code-generating the cross product of frontends and
backends.

*** CANCELLED Update dynamic section in manual                        :story:
    CLOSED: [2018-10-05 Fri 11:08]

*Rationale*: this will be taken care of by the thesis.

We need to talk about the new fields, field templates, etc.

*** CANCELLED Some test models do not build on run all specs          :story:
    CLOSED: [2018-10-05 Fri 11:09]

*Rationale*: should no longer be a problem after the repo splitting.

For some reason we are not building some of the test models when doing
a run all specs, in particular:

- exception
- comments

this may be because we have no specs for them. We need to find a way
to build them somehow.

Merged stories:

*Add test model sanitizer to test models target*

At present if we build test models we don't seem to build the
sanitizer.

*** CANCELLED C++ workflow should perform a consistency check         :story:
    CLOSED: [2018-10-05 Fri 11:11]

*Rationale*: this will no longer be required when we implement proper
feature model support.

We should ensure that all facets and formatters available in the
registrar have corresponding field definitions and vice-versa. This
was originally to be done by some kind of "feature graph" class, but
since we need to use this data for other purposes, the main workflow
could take on this responsibility - or we could create some kind of
"validator" class to which the workflow delegates.

*** CANCELLED Implement module expander test                          :story:
    CLOSED: [2018-10-05 Fri 11:14]

*Rationale*: code has changed quite a bit since then.

We copied across the code for the module expander test from yarn json
but didn't actually finished implementing it.

*** CANCELLED Consider using the same API as boost property tree in selector :story:
    CLOSED: [2018-10-05 Fri 11:14]

*Rationale*: no longer required once we have proper feature support.

At present we have the type of the value in the method names in the
selector, e.g. =get_text_content=. It would be better to have a =get=
that takes in a template parameter, e.g. =get<text>=. However, in
order to do this we need to have some kind of mapping between the
schema value (=text=) and the raw value (=std::string=). This requires
some template magic.

Once this is done we can also make the API a bit more like the
property tree API such as for example returning =boost::optional= for
the cases where the field may not exist.

We have started introducing =try_select...=. This was preferred to
=get_optional= because we are not getting an optional but instead
trying to get.

*** CANCELLED Add dynamic consistency validation                      :story:
    CLOSED: [2018-10-05 Fri 11:15]

*Rationale*: no longer required once we have proper feature support.

We need to check that the default values supplied for a field are
consistent with the field's type. This could be done with a
=validate()= method in workflow.

Actually since we can only create fields from JSON, we should just add
a check there.

*** CANCELLED Update manual with detailed model descriptions           :epic:
    CLOSED: [2018-10-05 Fri 11:18]

*Rationale*: this will be taken care of by the thesis.

#+begin_quote
*Story*: As a dogen developer, I want to read about the architecture
of the application so that I don't have to spend a lot of time trying
to understand the source code.
#+end_quote

We should add CRCs for the main classes, with an explanation of what
each class does; we should also explain the separation of the
transformation logic between the core model (e.g. =dia=) and the
transformation model (e.g. =dia_to_sml=). We should describe what the
workflow does in each model.

We should only implement this story when all of the major refactoring
has been done.

*** CANCELLED Add tests for general settings factory                  :story:
    CLOSED: [2018-10-05 Fri 11:21]

*Rationale*: once these become part of the meta-model, most of these
won't make any sense.

Some simple tests come to mind:

- empty data files directory results in empty factory;
- valid data files directory results in non-empty factory;
- invalid data files directory results in exception;
- more than one data files directory results in expected load;
- creating annotation for test model types works as expected.
- missing fields result in expected exceptions.

*** CANCELLED Add tests for =general_settings_factory=                :story:
    CLOSED: [2018-10-05 Fri 11:21]

*Rationale*: once these become part of the meta-model, most of these
won't make any sense.

Tests:

- missing licence
- missing modeline
- empty marker
- different marker for two objects
- consider moving generate preamble into annotation
