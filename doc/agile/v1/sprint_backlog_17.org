#+title: Sprint Backlog 17
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Refactor all feature related code to use code generation and the
  meta-model instead of hand-crafted code.

* Stories

** Active
#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2019-05-14 Tue 19:24]
| <75>                                                       |         |       |       |       |
| Headline                                                   | Time    |       |       |     % |
|------------------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                               | *58:11* |       |       | 100.0 |
|------------------------------------------------------------+---------+-------+-------+-------|
| Stories                                                    | 58:11   |       |       | 100.0 |
| Active                                                     |         | 58:11 |       | 100.0 |
| Edit release notes for previous sprint                     |         |       |  2:41 |   4.6 |
| Create a video demo for the previous sprint's features     |         |       |  2:11 |   3.8 |
| Sprint and product backlog grooming                        |         |       |  1:26 |   2.5 |
| Defining profiles directly on a target model does not work |         |       |  0:30 |   0.9 |
| Inner modules need to be qualified                         |         |       |  0:22 |   0.6 |
| Create namespaces for model elements                       |         |       |  8:59 |  15.4 |
| Leaves in internal modules are not captured correctly      |         |       |  1:33 |   2.7 |
| Try to add relational tracing support                      |         |       |  2:51 |   4.9 |
| Linux and OSX binaries are not stripped                    |         |       |  1:23 |   2.4 |
| Fix issues with nightly build and CI                       |         |       |  0:05 |   0.1 |
| Initial analysis to code generate feature infrastructure   |         |       |  7:13 |  12.4 |
| Replace JSON based feature templates with generated code   |         |       | 16:15 |  27.9 |
| Make a clear separation between dogen and masd             |         |       |  5:17 |   9.1 |
| Update the MASD UML profile to reflect the latest changes  |         |       |  0:05 |   0.1 |
| Add a method in enumeration that converts it from strings  |         |       |  7:20 |  12.6 |
#+TBLFM: $5='(org-clock-time%-mod @3$2 $2..$4);%.1f
#+end:

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2019-05-06 Mon 17:51]
    :LOGBOOK:
    CLOCK: [2019-05-06 Mon 18:01]--[2019-05-06 Mon 18:12] =>  0:11
    CLOCK: [2019-05-06 Mon 12:24]--[2019-05-06 Mon 12:31] =>  0:07
    CLOCK: [2019-05-06 Mon 12:16]--[2019-05-06 Mon 12:23] =>  0:07
    CLOCK: [2019-05-06 Mon 10:34]--[2019-05-06 Mon 12:15] =>  1:41
    CLOCK: [2019-05-05 Sun 22:10]--[2019-05-05 Sun 22:45] =>  0:35
    :END:

Add github release notes for previous sprint.

Title: Dogen v1.0.16, "São Pedro"

#+begin_src markdown
![Paróquia de São Pedro, Moçamedes](https://2.bp.blogspot.com/-P8MHQArl_fA/VzCYm9epI0I/AAAAAAAAl1g/CPkRiD5ZhGwgcqjTQoxEyRAcQNTHYuz2QCLcB/s1600/Igreja%2BS%2BPedro%2BNamibe.jpg)

_Paróquia de São Pedro, Moçamedes, Namibe. Do [blog de Maria Jardim](http://mossamedes-do-antigamente.blogspot.com/2016/05/a-igreja-de-s-pedro-de-mocamedes-namibe.html)._

# Introduction

This sprint achieved the long standing objective of moving profiles into the meta-model. We've also continued the work on cleaning up models to better align them to [MDE](https://en.wikipedia.org/wiki/Model-driven_engineering) terminology.

# User visible changes

This section covers stories that affect end users. The sprint demo provides a quick demonstration of the user visible changes, whereas the below sections provide more detail.

[![Sprint 1.0.16 Demo](https://img.youtube.com/vi/3XrHSFkdVps/0.jpg)](https://youtu.be/3XrHSFkdVps)

## Profiles as meta-model elements

The key story of the sprint was to move variability profiles into the meta-model. For those less familiar with Dogen's variability profiles, the basic idea is that you can create "canned" sets of configurations and then apply them to modeling elements via UML stereotypes.

We had alread made decorations metamodel elements in [sprint 14](https://github.com/MASD-Project/dogen/releases/tag/v1.0.14); now that we are also treating profiles as a regular meta-model elements,  we have the core features in place to allow users to start defining [SPLs](https://en.wikipedia.org/wiki/Software_product_line). You can create an SPL by creating a shared model containing all of the required configuration such as profiles, decorations etc and then make use of these in the models that make up the product line. As an example, in Dogen we created the ["profiles" model](https://github.com/MASD-Project/dogen/tree/master/projects/masd.dogen.models/dia) ```masd.dogen.profiles.dia```.

![Dogen's Profiles Model](https://github.com/MASD-Project/dogen/raw/master/doc/blog/images/profiles_model.png)

The name is not exactly ideal as the model can contain more than just profiles, so we are still searching for a more fitting denomination. The fundamental idea is clear, though: to have a central place where all the configuration of the product is stored, and use to create "a language" at the product level, imbued with product specific meaning. For example, one could define profiles such as ```hashable```, ```serialisable``` and so forth and then configure these with specific features. ```hashable``` could be mapped to the ```std::hash``` facet, serialisable to the Boost Serialisation facet and so forth. All of the mapping and naming is defined by the end user. In Dogen we define ```masd::pretty_printable``` as follows (using JSON notation):

```json
    {
      "name": "composable::pretty_printable",
      "parents": [
        "composable::code_generated"
      ],
      "documentation": "The element has the ability to dump itself to a stream.\n",
      "stereotypes": [
        "masd::variability::profile_template"
      ],
      "tagged_values": {
        "masd.variability.binding_point": "element",
        "masd.variability.labels": "masd::pretty_printable"
      },
      "attributes": [
        {
          "name": "masd.generation.cpp.io.enabled",
          "type": "",
          "value": "true",
          "tagged_values": {
            "masd.variability.archetype_location.kernel": "masd",
            "masd.variability.archetype_location.backend": "masd.generation.cpp",
            "masd.variability.template_kind": "instance"
          }
        }
      ]
    },
```

Any modeling element with the stereotype of ```masd::pretty_printable``` will now have the ability to dump itself into a stream via the ```masd.generation.cpp.io``` facet.

There are a couple of caveats to this feature. Firstly, we are yet to find a good domain based name for what are are calling thus far "profiles". The name is somewhat confusing, because Dogen's variability profiles are entirely unrelated to UML profiles. Our search through the literature continues, so in the future it is entirely possible that profiles will be renamed to a more fitting term.

Secondly, this release only adds the _foundational_ infrastructure for SPL. Many domain elements still need to be added to complete the SPL story, such as the concept of a product, build systems, etc. However, these features are already useful enough, and simplified Dogen's internals considerably.

## Removal of "stand-alone" weaving

In the past it was possible to instantiate stitch templates directly from Dogen, using the weaving command, e.g.:

```
$ masd.dogen.cli weave -t model.dia
```

However, due to the changes done in variability management, stitch templates are no longer instantiable without going through the entire processing pipeline for models. As such, the feature no longer makes sense, so it was removed.

The long term plan is to remove variability support from stitch templates; once that is in place, we can add weaving once more - though its usefulness in this fashion is somewhat debatable. We shall await for concrete use cases before working on this feature; for now, the story was moved to the bottom of the [product backlog](https://github.com/MASD-Project/dogen/blob/master/doc/agile/product_backlog.org#consider-adding-weaving-support-as-a-command).

# Development Matters

In this section we cover topics that are mainly of interest if you follow Dogen development, such as details on internal stories that consumed significant resources, important events, etc. As usual, for all the gory details of the work carried out this sprint, see the [sprint log](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_16.org).

## Significant Internal Stories

Rather unusually, this sprint was _extremely_ delivery focused, so there were no significant internal stories to speak of.

## Resourcing

Amazingly, over 87% of the total ask was taken by stories directly related to the sprint's mission -  probably a first in Dogen's development history. The remaining 13% of the time was spent as follows. Release related activities for the previous sprint cost around 5%, including activities such editing the release notes and creating the demo. Backlog grooming was shy of 5%, and around 1.3% of the total ask was spent on reading the academic literature on variability. Spikes had a cost of less than 2%, with the nursing of builds taking 0.8% and Emacs related work only 0.4%. Overall, it was an extremely efficient sprint.

![Story Pie Chart](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_16_pie_chart.jpg)

## Planning

The plan is proceeding as expected. At the end of sprint 16, the plan looks like this:

![Project Plan](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_16_project_plan.png)

![Resource Allocation Graph](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_16_resource_allocation_graph.png)

# Next Sprint

The focus on Sprint 17 is to address the other side of variability: the definition of new features. At present we are manually creating features, involving both the creation of the feature definition on its own JSON file and then the source code to implement the reading of the feature from a modeling element. The vision is that the code generator should create code for all of this, off the back of a modeling element (say ```masd::feature_group```). Work has started on this in sprint 16, so hopefully it will be completed in sprint 17.

# Binaries

You can download binaries from [Bintray](https://bintray.com/masd-project/main/dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_1.0.16_amd64-applications.deb](https://dl.bintray.com/masd-project/main/1.0.16/dogen_1.0.16_amd64-applications.deb)
- [dogen-1.0.16-Darwin-x86_64.dmg](https://dl.bintray.com/masd-project/main/1.0.16/DOGEN-1.0.16-Darwin-x86_64.dmg)
- [dogen-1.0.16-Windows-AMD64.msi](https://dl.bintray.com/masd-project/main/DOGEN-1.0.16-Windows-AMD64.msi)

For all other architectures and/or operative systems, you will need to build Dogen from source. tps://twitter.com/MarcoCraveiro/status/1125447976418193412][twitter]]
- [[https://www.linkedin.com/feed/update/urn:li:activity:6531213559836270592][LinkedIn]]
- [[https://gitter.im/MASD-Project/Lobby][Gitter]]

*** COMPLETED Create a video demo for the previous sprint's features  :story:
    CLOSED: [2019-05-06 Mon 17:51]
    :LOGBOOK:
    CLOCK: [2019-05-06 Mon 17:49]--[2019-05-06 Mon 18:00] =>  0:11
    CLOCK: [2019-05-06 Mon 15:48]--[2019-05-06 Mon 17:48] =>  2:00
    :END:

Time spent creating the demo.

*** STARTED Sprint and product backlog grooming                       :story:
    :LOGBOOK:
    CLOCK: [2019-05-13 Mon 18:31]--[2019-05-13 Mon 18:47] =>  0:16
    CLOCK: [2019-05-13 Mon 08:14]--[2019-05-13 Mon 08:18] =>  0:04
    CLOCK: [2019-05-13 Mon 08:02]--[2019-05-13 Mon 08:07] =>  0:05
    CLOCK: [2019-05-10 Fri 20:42]--[2019-05-10 Fri 20:48] =>  0:06
    CLOCK: [2019-05-10 Fri 11:35]--[2019-05-10 Fri 11:45] =>  0:10
    CLOCK: [2019-05-10 Fri 11:17]--[2019-05-10 Fri 11:34] =>  0:17
    CLOCK: [2019-05-09 Thu 06:25]--[2019-05-09 Thu 06:34] =>  0:09
    CLOCK: [2019-05-06 Mon 08:50]--[2019-05-06 Mon 09:09] =>  0:19
    :END:

Updates to sprint and product backlog.

*** COMPLETED Defining profiles directly on a target model does not work :story:
    CLOSED: [2019-05-07 Tue 09:55]
    :LOGBOOK:
    CLOCK: [2019-05-07 Tue 09:25]--[2019-05-07 Tue 09:55] =>  0:30
    :END:

We seem to have made some mistake when processing profile templates:
when we define them directly on a target model we fail with an
error. The problem is probably to do with the fact that we do not set
the meta-model information on these new types. We should try something
similar for all meta-types such as decorations, etc.

*** COMPLETED Inner modules need to be qualified                      :story:
    CLOSED: [2019-05-07 Tue 14:15]
    :LOGBOOK:
    CLOCK: [2019-05-07 Tue 13:53]--[2019-05-07 Tue 14:15] =>  0:22
    :END:

At present we cannot make a reference to a type in a "inner"
module. Take type T defined in namespace N. Assume N::M with type
R. In T we should be able to refer to M::R without any further
qualification because N contains both T and M. However, at present the
resolver cannot find M::R unless we specify N::M::R.

*** COMPLETED Create namespaces for model elements                    :story:
    CLOSED: [2019-05-07 Tue 16:17]
    :LOGBOOK:
    CLOCK: [2019-05-09 Thu 05:01]--[2019-05-09 Thu 06:12] =>  1:11
    CLOCK: [2019-05-08 Wed 19:40]--[2019-05-08 Wed 19:43] =>  0:03
    CLOCK: [2019-05-08 Wed 19:28]--[2019-05-08 Wed 19:39] =>  0:11
    CLOCK: [2019-05-08 Wed 18:54]--[2019-05-08 Wed 19:06] =>  0:12
    CLOCK: [2019-05-08 Wed 18:45]--[2019-05-08 Wed 18:53] =>  0:08
    CLOCK: [2019-05-08 Wed 17:01]--[2019-05-08 Wed 18:01] =>  1:53
    CLOCK: [2019-05-08 Wed 13:34]--[2019-05-08 Wed 14:40] =>  1:06
    CLOCK: [2019-05-08 Wed 09:31]--[2019-05-08 Wed 10:28] =>  0:57
    CLOCK: [2019-05-07 Tue 15:53]--[2019-05-07 Tue 16:17] =>  0:24
    CLOCK: [2019-05-07 Tue 15:38]--[2019-05-07 Tue 15:52] =>  0:14
    CLOCK: [2019-05-07 Tue 14:45]--[2019-05-07 Tue 15:37] =>  0:52
    CLOCK: [2019-05-07 Tue 14:16]--[2019-05-07 Tue 14:44] =>  0:28
    CLOCK: [2019-05-07 Tue 13:41]--[2019-05-07 Tue 13:53] =>  0:12
    CLOCK: [2019-05-07 Tue 09:56]--[2019-05-07 Tue 11:57] =>  2:01
    :END:

At present we have a flat namespace for all elements in coding. This
had served us well up to recently, but with the proliferation of
metamodel elements, it is becoming a bit unwieldy. This will get a lot
worse once we move the fabric types. Its probably best if we partition
elements into their own namespaces, such as:

- decoration
- variability
- cpp
- csharp
- build
- etc.

Actually we now have only the "core" elements outside a namespace. In
reality, these are "structural" elements. Create a namespace for them
as well.

*** COMPLETED Leaves in internal modules are not captured correctly   :story:
    CLOSED: [2019-05-08 Wed 12:05]
    :LOGBOOK:
    CLOCK: [2019-05-08 Wed 11:55]--[2019-05-08 Wed 12:04] =>  0:09
    CLOCK: [2019-05-08 Wed 10:30]--[2019-05-08 Wed 11:54] =>  1:24
    :END:

It seems we are not adding leaves to parents if they are located in
internal modules. It could also be because the generalisation
relationship comes about via meta-data rather than UML generalisation.

Actually the problem is related to how we were bucketing the leaves
when generating the visitor: we were splitting them by internal
modules, resulting in multiple visitors per model. We now bucket them
by model instead.

*** POSTPONED Try to add relational tracing support                   :story:
    CLOSED: [2019-05-09 Thu 11:55]
    :LOGBOOK:
    CLOCK: [2019-05-09 Thu 11:48]--[2019-05-09 Thu 11:55] =>  0:07
    CLOCK: [2019-05-09 Thu 09:03]--[2019-05-09 Thu 11:47] =>  2:44
    :END:

Whenever we bump into a problem we seem to spend a lot of time going
through the log files and trace files trying to figure out where the
problem is happening. Have a quick go in trying to implement a
relational model for tracing to see if we can transfer the bulk of the
data into a relational format which we can query via SQL.

We've created a basic relational model for tracing. The relational
part of it seems straightforward (ish); the problem is the integration
of the tracer with the relational model. At present we rely on the
fact that all traceable objects have IO enabled; this works because
the code generator creates the IO facet, which is then used by the
write method in utility to convert any model type into a
string. However, we now need to change the approach: we need multiple
tracing backends:

- file tracer
- database tracer.

The file tracer is more or less the current tracer. The database
tracer needs to decompose the objects in existing models into a
relational representation. In an ideal world, the user would configure
the tracer to use one of the two backends and the remaining usage
would be transparent. However, we cannot have an interface for the
tracer backend that uses template methods because then we'd need
virtual template functions, it seems.

Another alternative is to make the tracer aware of the model objects
it is tracing. This is also not ideal because we would create cycles
int he design.

In effect we need to somehow implement a similar approach to the existing
tracer: rely on global template functions a-la =operator<<= to
decompose objects into their relational representations and then
supply those to the backend. It is not very clear how this would
work. For now we've postponed this approach as it seems its not going
to be a quick win.

We should approach this incrementally. Next time we have a bit of
spare time, we need to generate the model and then create the adapters
from existing models. Finally we can look at how it will be integrated
with tracing.

*** STARTED Linux and OSX binaries are not stripped                   :story:
    :LOGBOOK:
    CLOCK: [2019-05-09 Thu 16:25]--[2019-05-09 Thu 17:20] =>  0:55
    CLOCK: [2019-05-09 Thu 15:56]--[2019-05-09 Thu 16:24] =>  0:28
    :END:

At present our Linux and OSX build is much bigger than our windows
builds (3.8 MB on Windows vs 31 MB OSX and 15 MB on Linux). The
problem appears to be that we are not stripping the binaries on Linux.

We tried manually stripping:

:     # strip the binaries in release
:    set(CMAKE_C_FLAGS_RELEASE "${CMAKE_C_FLAGS_RELEASE} -s")
:    set(CMAKE_CXX_FLAGS_RELEASE "${CMAKE_CXX_FLAGS_RELEASE} -s")

However clang does not support this.

This may be related to the CMake build type of MinRelSize. Try doing a
build with this and see if the binaries are smaller. Actually this
does not work. We also tried:

: CMAKE_INSTALL_DO_STRIP

Which seems to have some effect but not exactly the same as a command
line =strip=. Supposedly this is a install level strip.

The only solution that appears to work is to add a custom command to
all targets in the build to strip:

: add_custom_command(TARGET ${target} POST_BUILD
:        COMMAND ${EMBREE_SIGN_FILE} $<TARGET_FILE:${target}>)

However we need to be careful because stripping shared libraries may
cause problems. Also this is done for every build.

Links:

- [[https://www.technovelty.org/linux/stripping-shared-libraries.html][Stripping shared libraries]]
- [[https://cmake.org/pipermail/cmake/2012-March/049741.html][make install/strip does not strip static libraries]]

*** STARTED Fix issues with nightly build and CI                      :story:
    :LOGBOOK:
    CLOCK: [2019-05-13 Mon 08:08]--[2019-05-13 Mon 08:13] =>  0:05
    :END:

Time spent fixing build issues with either nightlies and/or CI.

*** COMPLETED Initial analysis to code generate feature infrastructure :story:
    CLOSED: [2019-05-10 Fri 11:19]
    :LOGBOOK:
    CLOCK: [2019-05-10 Fri 10:24]--[2019-05-10 Fri 11:16] =>  0:52
    CLOCK: [2019-05-10 Fri 10:16]--[2019-05-10 Fri 10:23] =>  0:07
    CLOCK: [2019-05-10 Fri 09:29]--[2019-05-10 Fri 10:15] =>  0:46
    CLOCK: [2019-05-10 Fri 09:05]--[2019-05-10 Fri 09:29] =>  0:24
    CLOCK: [2019-05-09 Thu 17:21]--[2019-05-09 Thu 18:14] =>  0:53
    CLOCK: [2019-05-09 Thu 13:59]--[2019-05-09 Thu 14:25] =>  0:26
    CLOCK: [2019-05-09 Thu 13:10]--[2019-05-09 Thu 13:45] =>  0:35
    CLOCK: [2019-05-09 Thu 08:38]--[2019-05-09 Thu 09:02] =>  0:59
    CLOCK: [2019-05-09 Thu 07:04]--[2019-05-09 Thu 07:06] =>  0:02
    CLOCK: [2019-05-09 Thu 06:35]--[2019-05-09 Thu 07:03] =>  0:28
    CLOCK: [2019-05-09 Thu 06:13]--[2019-05-09 Thu 06:24] =>  0:11
    CLOCK: [2019-05-08 Wed 19:07]--[2019-05-08 Wed 19:27] =>  0:20
    CLOCK: [2019-05-08 Wed 09:27]--[2019-05-08 Wed 09:31] =>  0:04
    CLOCK: [2019-05-07 Tue 16:54]--[2019-05-07 Tue 18:01] =>  1:07
    CLOCK: [2019-05-07 Tue 16:26]--[2019-05-07 Tue 16:53] =>  0:27
    CLOCK: [2019-05-07 Tue 16:18]--[2019-05-07 Tue 16:25] =>  0:07
    :END:

Dogen should generate code for the following:

- definition of a feature template, as per the existing data
  files. The approach should be very similar to what we did with
  profiles. With this we have features as a meta-model element.
- a concrete class to represent the feature group.
- code to read the concrete class out of the dynamic configuration
  (e.g. a "feature deserialiser" if you like).

Problems:

- we are defining a new binding point rather than binding; this means
  that the logic for checking the bindings no longer works. For
  example, we could be creating a new global binding point in a
  property.

: #DOGEN masd.variability.binding_point=global

Notes:

- create a feature template list with the feature templates defined in
  the meta-model.
- find a way to retrieve all of the feature template lists created in
  each model from engine.
- find a way to supply the list of lists to the variability subsystem
  in the feature model production chain.
- the user creates a feature group. On construction, it will query the
  feature model for all of its features and setup its feature group.
- users can then call =read= on a dynamic configuration to create
  static configurations.
- variability needs a feature template registrar that keeps track of
  all the available feature templates. It is supplied into the feature
  model production chain from the engine.
- all models that make use of features need a feature template
  initialiser. It calls the registrar with all the features in that
  model.

*** COMPLETED Replace JSON based feature templates with generated code :story:
    CLOSED: [2019-05-13 Mon 10:18]
    :LOGBOOK:
    CLOCK: [2019-05-13 Mon 10:15]--[2019-05-13 Mon 10:18] =>  0:03
    CLOCK: [2019-05-13 Mon 10:11]--[2019-05-13 Mon 10:14] =>  0:03
    CLOCK: [2019-05-13 Mon 09:54]--[2019-05-13 Mon 10:10] =>  0:16
    CLOCK: [2019-05-13 Mon 09:33]--[2019-05-13 Mon 09:53] =>  0:20
    CLOCK: [2019-05-13 Mon 09:22]--[2019-05-13 Mon 09:32] =>  0:10
    CLOCK: [2019-05-13 Mon 09:11]--[2019-05-13 Mon 09:21] =>  0:10
    CLOCK: [2019-05-13 Mon 08:53]--[2019-05-13 Mon 09:10] =>  0:17
    CLOCK: [2019-05-12 Sun 21:27]--[2019-05-12 Sun 21:41] =>  0:14
    CLOCK: [2019-05-12 Sun 21:16]--[2019-05-12 Sun 21:26] =>  0:10
    CLOCK: [2019-05-12 Sun 19:09]--[2019-05-12 Sun 19:27] =>  0:18
    CLOCK: [2019-05-12 Sun 18:59]--[2019-05-12 Sun 19:07] =>  0:08
    CLOCK: [2019-05-12 Sun 18:50]--[2019-05-12 Sun 18:58] =>  0:08
    CLOCK: [2019-05-12 Sun 18:38]--[2019-05-12 Sun 18:49] =>  0:11
    CLOCK: [2019-05-12 Sun 18:30]--[2019-05-12 Sun 18:37] =>  0:07
    CLOCK: [2019-05-12 Sun 15:43]--[2019-05-12 Sun 15:55] =>  0:12
    CLOCK: [2019-05-12 Sun 15:37]--[2019-05-12 Sun 15:42] =>  0:05
    CLOCK: [2019-05-12 Sun 15:30]--[2019-05-12 Sun 15:36] =>  0:06
    CLOCK: [2019-05-12 Sun 15:24]--[2019-05-12 Sun 15:29] =>  0:05
    CLOCK: [2019-05-12 Sun 15:00]--[2019-05-12 Sun 15:23] =>  0:23
    CLOCK: [2019-05-12 Sun 14:52]--[2019-05-12 Sun 14:59] =>  0:07
    CLOCK: [2019-05-12 Sun 14:41]--[2019-05-12 Sun 14:51] =>  0:10
    CLOCK: [2019-05-12 Sun 13:37]--[2019-05-12 Sun 13:42] =>  0:05
    CLOCK: [2019-05-12 Sun 13:21]--[2019-05-12 Sun 13:36] =>  0:15
    CLOCK: [2019-05-12 Sun 13:00]--[2019-05-12 Sun 13:20] =>  0:20
    CLOCK: [2019-05-12 Sun 12:56]--[2019-05-12 Sun 12:59] =>  0:03
    CLOCK: [2019-05-12 Sun 12:52]--[2019-05-12 Sun 12:55] =>  0:03
    CLOCK: [2019-05-12 Sun 12:40]--[2019-05-12 Sun 12:51] =>  0:11
    CLOCK: [2019-05-12 Sun 10:27]--[2019-05-12 Sun 10:36] =>  0:09
    CLOCK: [2019-05-12 Sun 10:05]--[2019-05-12 Sun 10:26] =>  0:21
    CLOCK: [2019-05-12 Sun 09:25]--[2019-05-12 Sun 09:29] =>  0:04
    CLOCK: [2019-05-12 Sun 09:05]--[2019-05-12 Sun 09:24] =>  0:19
    CLOCK: [2019-05-11 Sat 22:32]--[2019-05-11 Sat 22:57] =>  0:25
    CLOCK: [2019-05-11 Sat 22:21]--[2019-05-11 Sat 22:31] =>  0:10
    CLOCK: [2019-05-11 Sat 22:06]--[2019-05-11 Sat 22:20] =>  0:14
    CLOCK: [2019-05-11 Sat 22:02]--[2019-05-11 Sat 22:05] =>  0:03
    CLOCK: [2019-05-11 Sat 21:57]--[2019-05-11 Sat 22:01] =>  0:04
    CLOCK: [2019-05-11 Sat 21:54]--[2019-05-11 Sat 21:56] =>  0:02
    CLOCK: [2019-05-11 Sat 21:45]--[2019-05-11 Sat 21:53] =>  0:08
    CLOCK: [2019-05-11 Sat 21:40]--[2019-05-11 Sat 21:44] =>  0:04
    CLOCK: [2019-05-11 Sat 21:29]--[2019-05-11 Sat 21:39] =>  0:10
    CLOCK: [2019-05-11 Sat 21:18]--[2019-05-11 Sat 21:28] =>  0:10
    CLOCK: [2019-05-11 Sat 20:54]--[2019-05-11 Sat 21:04] =>  0:10
    CLOCK: [2019-05-11 Sat 13:25]--[2019-05-11 Sat 13:36] =>  0:11
    CLOCK: [2019-05-11 Sat 13:14]--[2019-05-11 Sat 13:24] =>  0:10
    CLOCK: [2019-05-11 Sat 09:01]--[2019-05-11 Sat 09:30] =>  0:29
    CLOCK: [2019-05-11 Sat 07:08]--[2019-05-11 Sat 07:41] =>  0:33
    CLOCK: [2019-05-11 Sat 06:52]--[2019-05-11 Sat 07:07] =>  0:15
    CLOCK: [2019-05-11 Sat 06:42]--[2019-05-11 Sat 06:51] =>  0:09
    CLOCK: [2019-05-11 Sat 06:10]--[2019-05-11 Sat 06:41] =>  0:31
    CLOCK: [2019-05-10 Fri 20:38]--[2019-05-10 Fri 20:41] =>  0:03
    CLOCK: [2019-05-10 Fri 20:17]--[2019-05-10 Fri 20:37] =>  0:20
    CLOCK: [2019-05-10 Fri 20:06]--[2019-05-10 Fri 20:16] =>  0:10
    CLOCK: [2019-05-10 Fri 19:51]--[2019-05-10 Fri 20:05] =>  0:14
    CLOCK: [2019-05-10 Fri 18:59]--[2019-05-10 Fri 19:05] =>  0:06
    CLOCK: [2019-05-10 Fri 18:28]--[2019-05-10 Fri 18:58] =>  0:30
    CLOCK: [2019-05-10 Fri 17:47]--[2019-05-10 Fri 18:27] =>  0:40
    CLOCK: [2019-05-10 Fri 17:32]--[2019-05-10 Fri 17:46] =>  0:14
    CLOCK: [2019-05-10 Fri 16:35]--[2019-05-10 Fri 17:31] =>  0:56
    CLOCK: [2019-05-10 Fri 16:10]--[2019-05-10 Fri 16:34] =>  0:24
    CLOCK: [2019-05-10 Fri 15:23]--[2019-05-10 Fri 16:09] =>  0:46
    CLOCK: [2019-05-10 Fri 15:08]--[2019-05-10 Fri 15:22] =>  0:14
    CLOCK: [2019-05-10 Fri 14:47]--[2019-05-10 Fri 15:07] =>  0:20
    CLOCK: [2019-05-10 Fri 14:21]--[2019-05-10 Fri 14:46] =>  0:25
    CLOCK: [2019-05-10 Fri 14:06]--[2019-05-10 Fri 14:20] =>  0:14
    CLOCK: [2019-05-10 Fri 13:40]--[2019-05-10 Fri 14:05] =>  0:25
    CLOCK: [2019-05-10 Fri 13:27]--[2019-05-10 Fri 13:39] =>  0:12
    CLOCK: [2019-05-10 Fri 12:55]--[2019-05-10 Fri 13:26] =>  0:31
    :END:

Tasks:

- rename =feature_template_group_registrar= to
  =feature_template_initializer=.
- rename =feature_template_group= to =feature_bundle=. The feature
  bundle gives rise to: feature templates, feature group, static
  configuration.
- create a registrar in variability that keeps track of the feature
  templates (=feature_template_registrar=?).
- create a variability type mapper that returns the dynamic type
  (e.g. from =masd::variability::text= returns the text enumeration)
  or the C++ type (returns =std::string=).
- create a static method in the =feature_bundle= that returns a list
  of feature templates (=make_templates=?).
- create a static method in the initializer that calls all feature
  bundles and retrieves the list of all feature templates, and
  populates the registrar.
- in engine, call all feature template initializers.
- update the variability feature model chain to receive the feature
  registrar as input.
- update all models to define features in the meta-model.
- remove all JSON files.

Notes:

- the formatter is a feature. The postfix, enabled etc should be with
  the formatter itself and it should register the feature. However,
  the problem is then with the static representation of the
  configuration. But perhaps this is not needed?
- why are there multiple decoration related fields? some are
  =masd.decoration= others are
  =masd.generation.decoration=. Investigate how they are used.
- archetype location properties are not useful for instance templates.
  We should not require them in this case. We could make the location
  optional on the template.

*** COMPLETED Make a clear separation between dogen and masd          :story:
    CLOSED: [2019-05-13 Mon 16:32]
    :LOGBOOK:
    CLOCK: [2019-05-13 Mon 16:16]--[2019-05-13 Mon 16:28] =>  0:12
    CLOCK: [2019-05-13 Mon 16:05]--[2019-05-13 Mon 16:15] =>  0:10
    CLOCK: [2019-05-13 Mon 14:39]--[2019-05-13 Mon 16:04] =>  1:25
    CLOCK: [2019-05-13 Mon 13:56]--[2019-05-13 Mon 14:38] =>  0:42
    CLOCK: [2019-05-13 Mon 12:45]--[2019-05-13 Mon 13:55] =>  1:10
    CLOCK: [2019-05-13 Mon 11:44]--[2019-05-13 Mon 12:05] =>  0:21
    CLOCK: [2019-05-13 Mon 11:34]--[2019-05-13 Mon 11:37] =>  0:03
    CLOCK: [2019-05-13 Mon 10:19]--[2019-05-13 Mon 11:33] =>  1:14
    :END:

At the moment we are confusing Dogen quite a lot with MASD. There
should be a clear separation between these two:

- MASD provides a theoretical framework, together with a meta-model
  and a feature model.
- Dogen is a reference implementation of this framework.

We should not use the prefix =masd= on anything unless it belongs to
the MASD framework. The question to ask is: "if we had a second
implementation of MASD, would it have to know about this concept?" If
the answer is no, then the concept should not be under the MASD
namespace.

Tasks:

- drop =masd= namespace from all dogen models.
- drop =masd= namespace from all test models.
- drop =masd= namespace from all profiles.

*Previous Understanding*

At present we have stereotypes such as =masd::handcrafted::typeable=
etc. However, the namespace =masd= in this context is not meant to
imply these are defined inside the MASD public UML profile. In fact,
should we really call dogen =masd::dogen=?

Whilst dogen is an implementation of MASD, it is not inside the MASD
namespace - in the sense that things defined in dogen are
implementation specific. If we has simply =dogen=, we could then
reserve the =masd= namespace for things that are actually in the MASD
spec. Similarly for the reference models. The question is whether
reference implementations should exist under the MASD umbrella or
not. Say for example a third party implements the MASD spec; we
wouldn't expect them to place it under the MASD namespace.

In a somewhat similar vein, we have the =masd= model in library. This
contains elements which are directly usable by end users (licences for
example) and others which are less so - generation markers are more of
an example rather than what we expect users to use. Modelines are
somewhere in between.

*** STARTED Update the MASD UML profile to reflect the latest changes :story:
    :LOGBOOK:
    CLOCK: [2019-05-13 Mon 11:38]--[2019-05-13 Mon 11:43] =>  0:05
    :END:

The UML profile is now a fair bit out of date. Take advantage of the
down time waiting for builds to sync it.

*** STARTED Add a method in enumeration that converts it from strings :story:
    :LOGBOOK:
    CLOCK: [2019-05-14 Tue 18:42]--[2019-05-14 Tue 18:52] =>  0:10
    CLOCK: [2019-05-14 Tue 17:46]--[2019-05-14 Tue 18:02] =>  0:16
    CLOCK: [2019-05-14 Tue 17:13]--[2019-05-14 Tue 17:33] =>  0:20
    CLOCK: [2019-05-14 Tue 16:01]--[2019-05-14 Tue 17:12] =>  1:11
    CLOCK: [2019-05-14 Tue 15:16]--[2019-05-14 Tue 16:00] =>  0:44
    CLOCK: [2019-05-14 Tue 15:02]--[2019-05-14 Tue 15:15] =>  0:13
    CLOCK: [2019-05-14 Tue 09:25]--[2019-05-14 Tue 12:05] =>  2:40
    CLOCK: [2019-05-14 Tue 09:21]--[2019-05-14 Tue 09:24] =>  0:03
    CLOCK: [2019-05-14 Tue 08:40]--[2019-05-14 Tue 09:20] =>  0:40
    CLOCK: [2019-05-13 Mon 17:21]--[2019-05-13 Mon 18:02] =>  0:41
    CLOCK: [2019-05-13 Mon 16:29]--[2019-05-13 Mon 16:51] =>  0:22
    :END:

- =from_simple_string=;
- =from_qualified_string=.

For symmetry:

- =to_simple_string=;
- =to_qualified_string=.

Actually we cannot call the method =from_simple_string= as we cannot
overload based on return types. In addition, with C++ 98 we may also
have problems overloading based on plain enums - needs
investigation. The names will have to reflect the enum name
too. Perhaps:

- =simple_string_to_technical_space=
- =qualified_string_to_technical_space=
- =simple_string_to_technical_space=
- =qualified_string_to_technical_space=

In addition, the conversion to string requires a bit of thinking. We
don't want to create strings on the heap needlessly, but supporting
C++98 means we can't just use string view. Besides we don't even know
how string view will integrated with the existing code.

A slightly better approach may be to rely on lexical cast. We can
create a new facet specifically for this and specialise it only for
enums for now. We could try to make no allocations as well using
=char*= and =strncmp=.

Notes:

- problems with c++ 98 model: tests are running on c++ 17. This is not
  a huge problem normally, but we now have some header only code which
  is actually only being validated for c++ 17. We need to remove all
  autos from the tests plus fix semi-colons, etc.
- need a way to obtain a qualified name to the enumerator in C++ 98
  style (e.g. skipping the enumeration).

Links:

- [[http://www.cplusplus.com/reference/cstring/strncmp/][strncmp]]
- [[https://stackoverflow.com/questions/1250795/very-poor-boostlexical-cast-performance][Very poor boost::lexical_cast performance]]

*** Add logging support to generated tests                            :story:

At present generated tests are not writing to the log file. This is
because we wanted to keep them clean so that users could generate
tests for their models without having to pull in dogen
headers. However, for dogen tests this is a bit painful; if a test
fails we can't just look at the log file to see why. We could have a
flag to generate tests with logging.

The other problem is we need to move utility into its own library as a
PDM before we can do this because otherwise the logging will be in
different locations (i.e. dogen vs reference model).

*** Postfix and directory fields should be templates                  :story:

We need to understand why we didn't templatise these fields. It is
very painful to have to add these manually for each facet and
formatter.

Most likely it is because each formatter/facet needs to "override" a
base value with its own value. For example, we almost always want a
blank postfix, but occasionally need to set it (=fwd= for forward
declarations and so forth). Our variability implementation does not
cope with this type of overrides. We would have to have some kind of
way of allowing instance templates even though a facet/archetype
template already exists, and then use the instance template as the
override. Alternatively, we could simply check for postfix/directory;
if not present default to empty string.

For extra bonus points, we could allow variables: =${facet.name}=
could expand to the current facet name on the facet template.

Merged stories:

*Postfix and directory fields in annotations look weird*

Why are we manually instantiating postfix and directory for each
formatter/facet instead of using templates? This is one of the main
reasons for breaks/errors when adding a new formatter.

*** Formatter dependencies and model processing                       :story:

At present we are manually adding the includes required by a formatter
as part of the "inclusion_dependencies" building. There are several
disadvantages to this approach:

- we are quite far down the pipeline. We've already passed all the
  model building checks, etc. Thus, there is no way of knowing what
  the formatter dependencies are. At present this is not a huge
  problem because we have so few formatters and their dependencies are
  mainly on the standard library and a few core boost models. However,
  as we add more formatters this will become a bigger problem. For
  example, we've added formatters now that require access to
  variability headers; in an ideal world, we should now need to have a
  reference to this model (for example, so that when we integrate
  package management we get the right dependencies, etc).
- we are hard-coding the header files. At present this is not a big
  problem. To be honest, we can't see when this would be a big
  problem, short of models changing their file names and/or
  locations. Nonetheless, it seems "unclean" to depend on the header
  file directly.
- the dependency is on c++ code rather than expressed via a model.

In an ideal world, we would have some kind of way of declaring a
formatter meta-model element, with a set of dependencies declared via
meta-data. These are on the model itself. They must be declared
against a specific archetype. We then would process these as part of
resolution. We would then map the header files as part of the existing
machinery for header files.

However one problem with this approach is that we are generating the
formatter code using stitch at present. For this to work we would need
to inject a fragment of code into the stitch template somehow with the
dependencies. Whilst this is not exactly ideal, the advantage is that
we could piggy-back on this mechanism to inject the postfix fields as
well, so that we don't need to define these manually in each
model. However, this needs some thinking because the complexity of
defining a formatter will increase yet again. When there are problems,
it will be hard to troubleshoot.

*** Add =structural= namespace to core elements                       :story:

We've created a namespace inside the coding meta-model for the core
entities but we did not update the MASD profile.

Actually structural is not a very good name - all of the meta-model
elements are structural elements, really. We need to find a good name
before we update the stereotypes.

*** Remove empty default values                                       :story:

At present we have a number of default values in feature bundles set
to the empty string =""=. It makes more sense not to have a default
value and have the client code handle its absence.

*** Make labels a plain text field not a collection                   :story:

At present it is possible to label a profile with multiple
labels. This is not a good idea. Make it a plain text field so we can
only apply a single label.

*** Create a code-generated static configuration reader               :story:

Tasks:

- add a configuration class to the feature bundle. Investigate how we
  handle the archetype and facet expansion.
- add a feature group class to the feature bundle. On construction get
  the feature group to find all of its fields.
- add a =read= method that uses the feature group to create the static
  configuration.
- add support in enumerations to convert a string to the enumeration
  (simple and qualified name). Calling code can use this method when
  reading an enumeration.
- replace calling code with new static features.
- add io support for the static configuration if the io facet is
  enabled.

*** Read variability papers                                           :story:

Time spent reading the literature on variability.

*** Emacs maintenance and exploration work                            :story:

Any time spent improving emacs, exploring new modes, fixing snags, etc.

** Deprecated
*** CANCELLED Consider adding enumerations in dynamic                 :story:
    CLOSED: [2019-05-10 Fri 11:45]

*Rationale*: we do not want to further complicate the variability
model. Instead, we shall code generate the conversion into the static
type via the enumeration "from string" methods.

This story is bound to already exist in backlog so do another
search. The idea is that we should be able to define a field and all
of its valid values. For extra bonus points, we should be able to
assign an enumeration and get the string conversion done
automatically; for example by having a string to enum code generated,
and supplying that function as a type parameter into dynamic. Then
dynamic's field selector would create the instances of the enumeration.

Previous stories:

*Create a domain field definitions*

In addition to default values, it should be possible to supply a list
of possible values for a field definition - a domain. When processing
the values we can then check that it is part of the domain and if not
throw. This is required for the include types and for the family
types. At present this is only applicable to string fields.

In this sense, =boolean= is just a special case where the list is know
up front. We should re-implement =boolean= this way. Possibly even add
synonyms (e.g. =true=, =false=, =0=, =1=)?
