#+title: Sprint Backlog 71
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) spike(p) }

* Mission Statement

- Perform the main refactors to tack and yarn;
- Simplify templates;
- Integrate Clang.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75
#+CAPTION: Clock summary at [2015-08-04 Tue 21:57]
| <75>                                                                        |         |       |      |
| Headline                                                                    | Time    |       |      |
|-----------------------------------------------------------------------------+---------+-------+------|
| *Total time*                                                                | *18:34* |       |      |
|-----------------------------------------------------------------------------+---------+-------+------|
| Stories                                                                     | 18:34   |       |      |
| Active                                                                      |         | 18:34 |      |
| STARTED Sprint and product backlog grooming                                 |         |       | 0:43 |
| STARTED Compile dogen in Windows using Visual Studio 2015                   |         |       | 8:13 |
| COMPLETED Rename SML to =tack=                                              |         |       | 4:33 |
| COMPLETED Merge frontend with =tack=                                        |         |       | 4:38 |
| COMPLETED Rename dia to tack to tack dia                                    |         |       | 0:27 |
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2015-08-03 Mon 17:42]--[2015-08-03 Mon 17:59] =>  0:17
    CLOCK: [2015-07-20 Mon 14:30]--[2015-07-20 Mon 14:56] =>  0:26

Updates to sprint and product backlog.

*** Add support for pulling dependencies from biicode                 :story:

[[https://www.biicode.com/][Biicode]] is a nuget-like repo for c++. We should look into both
consuming dependencies from it and pushing dogen into it. In addition
there are associated emblems:

https://github.com/Manu343726/snail

We should also look into [[https://www.biicode.com/biicode-open-source-challenge][the challenge]].

We should push both the C++ libraries as well as the dogen binary.

We should take the least intrusive possible approach to start with, by
creating a split setup for biicode.

*** Create a blog post on biicode                                     :story:

Investigate adding biicode support since we need to add a RapidJson
dependency. Create a blog post about it.

Post has [[https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/blog/biicode.org][already been started]].

*** STARTED Compile dogen in Windows using Visual Studio 2015         :story:
    CLOCK: [2015-08-04 Tue 14:26]--[2015-08-04 Tue 14:39] =>  0:13
    CLOCK: [2015-08-01 Mon 09:00]--[2015-08-01 Mon 17:00] =>  8:00

Using our "SoC" resources, we need to setup a Dogen development
environment on Windows using VS 2015. We need to also create a blog
post about it.

Issues:

- is polymorphic in instrinsics for microsoft, remove comment. see
  patch in github.
- add string to enum io
- update exception classes: remove default in base constructor, and
  add explicit to base and derived as well as by ref.
- update find boost with MSVC version

File with instructions:

0. cd c:\DEVELOPEMENT\output
1. (only once - as admin) update version of msvc in cmake C:\Program
  Files (x86)\CMake\share\cmake-3.3\Modules\FindBoost.cmake
  look for msvc-140 and update it to msvc-150
2. set CMAKE_INCLUDE_PATH=C:\boost\include;C:\DEVELOPEMENT\libxml2-2.7.8.win32\include
   set CMAKE_LIBRARY_PATH=C:\boost\lib;C:\DEVELOPEMENT\libxml2-2.7.8.win32\lib
3. cmake ..\dogen -G "Visual Studio 14 2015" -Wno-dev (CONFIGURATION COMMAND)

if you need to re-run: delete the cache:

del CMakeCache.txt

4. msbuild dogen.sln /t:config

5.msbuild dogen.sln /t:dia /fileLogger   => used to create log for
  errors- called msbuild.log in output directory

Links:

- [[http://dominoc925.blogspot.co.uk/2013/04/how-i-build-boost-for-64-bit-windows.html][How I build Boost for 64 bit Windows]]
- [[https://svn.boost.org/trac/boost/ticket/11449][C++11 - is_polymorphic doesn't work with final-ed class in MSVC.]]
- [[https://github.com/boostorg/type_traits/blob/04a8a9ecc2b02b7334a4b3f0459a5f62b855cc68/include/boost/type_traits/intrinsics.hpp][type_traits/include/boost/type_traits/intrinsics.hpp]]
- [[http://stackoverflow.com/questions/20800166/cmake-compile-with-mt-instead-of-md][CMake - compile with /MT instead of /MD]]
- [[http://www.cmake.org/cmake/help/v3.1/manual/cmake-generators.7.html][CMake Generators]]
- [[http://choorucode.com/2014/06/06/how-to-build-boost-for-visual-studio-2013/][How to build Boost for Visual Studio 2013]]

*** COMPLETED Rename SML to =tack=                                    :story:
    CLOSED: [2015-08-03 Mon 17:32]
    CLOCK: [2015-08-03 Mon 17:33]--[2015-08-03 Mon 17:42] =>  0:09
    CLOCK: [2015-08-03 Mon 14:32]--[2015-08-03 Mon 17:32] =>  3:00
    CLOCK: [2015-07-31 Fri 18:44]--[2015-07-31 Fri 19:25] =>  0:41
    CLOCK: [2015-07-31 Fri 08:04]--[2015-07-31 Fri 08:47] =>  0:43

This will now be the name to reflect its "intermediate" state.

#+begin_quote
In sewing, to tack or baste is to make quick, temporary stitching
intended to be removed.
#+end_quote

**** Comments from SML that need to be moved to new model

@section sml_0 Core Ideas

SML has at its core the ideas explained by Eric Evans in Domain Driven
Design (DDD), and it is mainly a domain model to model the DDD domian.
However, it also contains some influences from Java's EMF - more precisely
eCore, which was the first meta-model we looked at. eCore is itself rooted
in UML. We also took some ideas from Stepanov and Jones, in Programming
Elements (those which we could just about understand).

In more general terms, SML is a meta-model - that is a model that models
models - but we are not too hang-up on the classic terminology of meta-modeling
because a lot of people find it confusing. Instead, we chose to use the
@e ubiquitous @e language defined in th DDD book because its very clear, but
avoids the complexity of the terms usually associated with meta-modeling.

The objective of SML is to provide the required scaffoling to represent domain
models, and to do so in a way that is programming language neutral. Thus is
should provide a representation that is suitable for further transformations
into models representing programing languages, and from there, to code
generation.

At the root of SML is the @ref model, short for domain model. It is the root
of an aggregate containing a number of @e modeling @elements which together
make up the software representation of a given domain model. The key types of
modeling elements in SML are:

@li @b model: the model itself, modeling domain models
@li @b modules: packaging unit; logical sub-division of the model.
@li @b concepts: not present in DDD; models the C++ notion of a concept.
@li @b enumeration: value type that models enumerations
@li @b primitive: value type that models primitive types such as int, etc.
@li @b object: models the notion of an @e object as defined in object oriented
languages.

The remaining ideas are refinements of these core concepts.

**** Comments from SML that may be applicable to Tack but need refactoring

@section sml_1 Merging and Resolving

Tack models begin their life as disjointed models with lots of missing
references to types. This expectation arises from the fact that we
have most likely transformed some kind of external model into Tack - a
dia diagram, say - and that the tools used for working on that model
are not aware of Tack or Dogen in general.

Thus, in order to become useful, a Tack model needs to be merged with
all of its dependencies. This is done by providing the @e target model
- i.e. that which one intends to really work on - and its @e
references - i.e. any models which are picked up due to being
referenced from within the tatget model - and pass them over to the
@ref merger. It is the merger's job to create a @e merged model.

A further step is still required, which is to @e resolve all of the references,
to ensure we do not have any missing dependencies. This is the job of the
@ref resolver.

All of these steps are encompassed in the SML @ref workflow.

*** COMPLETED Merge frontend with =tack=                              :story:
    CLOSED: [2015-08-04 Tue 21:29]
    CLOCK: [2015-08-04 Tue 20:57]--[2015-08-04 Tue 21:28] =>  0:31
    CLOCK: [2015-08-04 Tue 17:54]--[2015-08-04 Tue 18:04] =>  0:10
    CLOCK: [2015-08-04 Tue 17:28]--[2015-08-04 Tue 17:53] =>  0:25
    CLOCK: [2015-08-04 Tue 16:34]--[2015-08-04 Tue 17:25] =>  0:51
    CLOCK: [2015-08-04 Tue 14:41]--[2015-08-04 Tue 16:33] =>  1:52
    CLOCK: [2015-08-03 Mon 21:15]--[2015-08-03 Mon 22:04] =>  0:49

Combine the two models performing the necessary renames. Notes:

- merge frontend with tack. Rename frontend interface to something
  like model source or just source. Remove the dia frontend class,
  moving the code into the dia transformer.
- consider creating a top-level workflow that unites the frontend
  workflow with the "merging" workflow.
- Find good names for all workflows. A good name for the current SML
  workflow is =assembler= because it assembles a complete model from
  all the parts.
- consider creating a "file opener" that takes an input descriptor and
  returns a stream. This way the source interface can just be an
  ostream. This probably makes no sense for certain sources like dia
  though.
- create tack_json. this is in preparation for =tack.dia=, etc.
- use pointer map in registrar rather than shared pointers.

*** COMPLETED Rename dia to tack to tack dia                          :story:
    CLOSED: [2015-08-04 Tue 21:57]
    CLOCK: [2015-08-04 Tue 21:30]--[2015-08-04 Tue 21:57] =>  0:27

- rename dia to tack to tack_dia. this is in preparation for
  =tack.dia=, etc.

*** Remove saving preprocessing input support                         :story:

We seem to have the ability of saving dia diagrams etc when importing
a tack model but this is not used any where. It was borked with the
latest refactor. Remove this functionality.

*** Create the =yarn= model                                           :story:

We need to create a meta-model with the following characteristics:

- rename frontend to middle end workflow to yarn generation workflow
  or some such name.
- have a look at eCore/MOF type names for inspiration.
- single top-level type for all types with a container. Use boost
  pointer container. add a visitor for the type.
- consider not having a top-level entity called model but instead use
  a top-level package.
- wherever we are using qnames to refer to external types, use a
  reference instead. Use reference wrapper where required.
- we could probably merge backends with yarn and call these
  "sinks". This way we could have "sources" in tack and "sinks" in
  yarn.
- we do not need a qname. We need a name that is made up of just a
  string (the actual name of the object) plus a reference to the
  containing module. The containing module has a structure of paths
  similar to =qname=.

*** Split model name from "contributing model name" in qname          :story:

We need to find a way to model qnames such that there are two model
names: one which contributes to the namespaces and another which
doesn't. The specific use case is the primitives model where the model
has to have a name but we don't want the type names to have the model
name. Perhaps we need some kind of flag: model name contributes to
namespacing.

With this we can then remove the numerous hacks around the primitives
model name such as:

- // FIXME: mega hack to handle primitive model.

*** Update copyright notices                                          :story:

We need to update all notices to reflect personal ownership until DDC
was formed, and then ownership by DDC.

*** Rename types in =tack= using MOF/eCore terms                      :story:

Rename the types in =tack= to make them a bit more inline with
MOF/eCore. As much as possible but without going overboard. Ensure we
do not pick up meta-meta-model concepts by mistake. Rename nested
qname to something more sensible from MOF/eCore. Review all concept
names in this light.

*** Create a set of definitions for tagging and meta-data             :story:

We still use these terms frequently. We should define them in dynamic
to have specific meanings.

*** Refactor code around model origination                            :story:

- remove origin types and generation types, replacing it with just a
  boolean for is target.

*Previous Understanding*

In the past we added a number of knobs around generation, all with
their own problems:

- =origin_types=: was the model/type created by the user or the
  system. in reality this means did the model come from Dia or
  JSON. this is confusing as the user can also add JSON files (their
  own model library) and in the future the user can use JSON
  exclusively without needed Dia at all.

- =generation_types=: if the model is target, all types are to be
  generated /unless/ they are not properly supported, in which case
  they are to be "partially" generated (as is the case with
  services). This is a formatter decision and SML should not know
  anything about it.

These can be replaced by a single enumeration that indicates if the
type/model is target or not.

This work should be integrated with the model types story.

*** Models should have an associated language                          :epic:

#+begin_quote
*Story*: As a dogen user, I want to make sure I only use valid system
models so that I don't generate models that code generate but do not
compile.
#+end_quote

Certain models (e.g. system / library models) can only be used in a
give language; for example =boost= and =std= only make sense in C++. A
.Net library model would only make sense in .Net, etc. These are
Language Specific Models (LSM). Once a model depends on a LSM it
itself becomes an LSM and it should not be able to then make use of
models of other languages nor should one be able to request a code
generation for other languages.

However, one day we will have a system model which is a Language
Agnostic Model (LAM). The system model will provide a base set of
functionality across languages such as containers, and for each type
it will have mappings to language specific types. The mapping is
declared as dynamic extensions in the appropriate section
(i.e. =tags::cpp::mapped_type= or something of that ilk). If a model
depends only on LAMs, it is itself a LAM and can be used to generate
code on any supported language (presumably a supported language is
defined to be that for which we have both mappings and a code
generation backend).

A first step for this would be to have a language enumeration in SML
which is a property of the model, and one entry of which is "language
agnostic".

*** Set enumeration underlying type in SML                            :story:

In cpp transformer we have hacked the underlying type of the
enumeration. Remove this hack and set it in SML. Still a hack, but
a tad better.

Actually this could be the first case where LAM/PIM is used: we could
call this something like integer.

*** Add support for Language Agnostic Models (LAM)                    :story:

When we start supporting more than one language, one interesting
feature would be to be able to define a model once and have it
generated for all supported languages. This would be achieved by
having a system model (or set of system models) that define all the
key types in a language agnostic manner. For example:

: lam::string
: lam::int
: lam::int16

Each of these types then has a set of meta-data fields that map them
to a type in a supported language:

: lam:string: cpp.concrete_type_mapping = std::string
: lam:string: csharp.concrete_type_mapping = string

And so on. We load the user model that makes use of LAM, we generate
the merged model still with LAM types and then we perform a
translation for each of the supported and enabled languages: for every
LAM type, we replace all its references with the corresponding
concrete type. We need to split the supplied mapping into a QName, use
the QName to load the system models for that language, look up the
type and replace it. After the translation no LAM types are left. We
end up with N SML merged models where N is the number of supported and
enabled languages.

Each of these models is then sent down to code generation. This should
be equivalent to manually generating models per language - we could
use this as a test.

Once we have LAM, it would be great to be able to exchange data
between languages. This could be done as follows:

- XML: create a "LAM" XML schema, and a set of formatters that read
  and write from it. This is kind of like reverse mapping the types
  back to LAM types when writing the XML.
- JSON: similar approach to XML, minus the schema.
- POF: use the coherence libraries to dump the models into POF.

FIXME: we believed this story was already backloged but could not find
it on a quick search. Do a more thorough search.

*** Thoughts on simplifying the formattables generation               :story:

We have a problem in the way which we are doing the formattables:
because we are doing model traversals for each of the factories, we
cannot easily introduce a set of manually generated qnames such as the
registrar and includers. However, if we started off the main workflow
by creating a structure like so:

- qname
- optional entity (new base class in SML); if null we need to create
  extensions as an empty object.

We then need a list of these that get passed in to all repository
factories. These use a visitor of entity to resolve to a type (where
required).

We can inject types to this list that have a qname but no entity. For
these we generate some parts of the formatter properties. Actually, we
still need to generate inclusion lists even when there is no
entity. Perhaps we need to create a new method in the provider that
does not take an SML entity but still generates the inclusion list.

Actually this should all be done in SML. We should have zero qname
look-ups coming out of SML, just follow references. This story is a
variation of the split between "partial" models and "full" models.

Well not everything should be done in SML. We still need to create a
structure with the properties above, but that is done by iterating
through a list in the SML model.

One slight problem with this approach: sometimes we need to preserve
some relationships in the newly generated objects. For registrar we
need to preserve the model leaves. For the includers / master headers
we need to express somehow the inclusion relationship at the formatter
level. The latter is definitely a special case because it is a pure
C++ concept: include files cannot be modeled in SML. However,
registrar is slightly different because we still need to compute the
includes based on the leaves. This means that the above approach will
not provide a clean solution, unless we synthesise an SML object when
providing the includes. And of course we need to be careful taking
that route or else we will end up generating the object across all
facets.

*** Consider reducing the number of qname lookups in cpp model        :story:

At present we are using qnames all over the place in CPP. Nothing
stops us from using strings instead of qnames if that is more
efficient.

What is worse is that we seem to be doing a ridiculous amount of qname
lookups. It would be much nicer if we could somehow have all the data
in the right shape to avoid doing so many lookups.

*** Handling of managed directories is incorrect                      :story:

At present we are querying the dia to sml transformer to figure out
what the managed directories are. These are basically the top-level
directories from where we want the housekeeper to operate. In reality
this is (or can be placed) in the meta-data. We should be able to
extract the managed directories from the meta-data as a step in one of
the workflows.

This can be done by the backend. It does mean that we should be
returning a composite type from generation:

- list of files;
- list of managed directories.

Alternatively we could have a =managed_directories= method that takes
in an SML model and then internally reads in the meta-data for a given
model to produce the list.

*Merged with previous story*

Compute managed directories from knitting options

At present the backend is returning empty managed directories. This
means housekeeping will fail in the new world. We need to change the
interface of this method to take in the knitting options and return
the managed directories.

This is not entirely trivial. At present the managed directories are
computed in the locator. It takes into account split project, etc to
come up with all the directories used by the backend. We need to make
these decisions during path expansion, expect we only need manged
directories for the root object. However we do not know which object
is the root object at present, during the expansion. We could identify
it via the QName and the SML model in context thought. We could then
populate the managed directories as a text collection. We then need
some settings and a factory to pull out the managed directories from
the root object. This could be done in =managed_directories=, by
having an SML model as input.

*** Add include providers for all types                               :story:

We need to implement the provider container support for primitives,
modules and concepts.

Update:

- inclusion dependencies factory
- provider container

*** Implement all formatter interfaces                                :story:

We still have a couple of skeleton interfaces:

- primitve
- concepts

*** Factor all =housekeeping_required= methods into one               :story:

In knit model we seem to have several of these: =housekeeping_required=.

*** Do not compute inclusion directives for system models             :story:

It seems we are computing inclusion directives and other path
derivatives for system models:

: {
:   "__type__": "dogen::cpp::expansion::path_derivatives",
:   "file_path": "/home/marco/Development/DomainDrivenConsulting/output/dogen/clang-3.5/stage/bin/../test_data/all_primitives/actual/std/include/std/serialization/unique_ptr_fwd_ser.hpp",
:   "header_guard": "STD_SERIALIZATION_UNIQUE_PTR_FWD_SER_HPP",
:   "inclusion_directive": "<quote>std/serialization/unique_ptr_fwd_ser.hpp<quote>"
: }

This comes out of the workflow, so we possibly are then ignoring it
for the non-target types. So:

- can we avoid computing these altogether?
- are we ignoring it?

Actually this is the usual problem with the "origin" of the type. We
need a way to determine if this type needs computations or not. We
need to create a story to clean up the =origin_type= and
=generation_type= and then we can make use of it to determine if we
need to compute inclusion, path etc or not.

*** Header guard in formatters should be optional                     :story:

At present we are relying on empty header guards to determine what to
do in boilerplate. We should use boost optional.

*** Remove complete name and use qualified name                       :story:

At present we have both complete name and qualified name in
formatables. Qualified name is blank. We should remove complete name
and populate qualified name.

This is in nested type info.

*** Consider renaming registrar in boost serialisation                :story:

At present we have a registrar formatter that does the boost
serialisation work. However, the name =registrar= is a bit too
generic; we may for example add formatters for static registrars. We
should rename this formatter to something more meaningful. Also the
name registrar is already well understood to mean static registrar.

This is a big problem now that we cannot add a type with the name
registrar to the main model as it clashes with the serialisation
registrar.

** Deprecated
