#+title: Sprint Backlog 76
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) spike(p) }

* Mission Statement

- wrap things up with yarn refactor and start quilt refactor.
- get continuous builds working again.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75
#+CAPTION: Clock summary at [2015-12-10 Thu 07:31]
| <75>                                                                        |        |      |      |
| Headline                                                                    | Time   |      |      |
|-----------------------------------------------------------------------------+--------+------+------|
| *Total time*                                                                | *5:15* |      |      |
|-----------------------------------------------------------------------------+--------+------+------|
| Stories                                                                     | 5:15   |      |      |
| Active                                                                      |        | 5:15 |      |
| STARTED Sprint and product backlog grooming                                 |        |      | 0:39 |
| STARTED Remove =service= stereotype                                         |        |      | 0:18 |
| STARTED Create visitor and exception yarn types                             |        |      | 3:59 |
| STARTED Update copyright notices                                            |        |      | 0:19 |
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2015-12-08 Tue 23:36]--[2015-12-08 Tue 23:47] =>  0:11
    CLOCK: [2015-12-08 Tue 22:46]--[2015-12-08 Tue 22:54] =>  0:08
    CLOCK: [2015-12-08 Tue 22:07]--[2015-12-08 Tue 22:27] =>  0:20

Updates to sprint and product backlog.

*** COMPLETED Improvements to project layout                          :story:
    CLOSED: [2015-12-08 Tue 22:23]

*Rationale*: the bits we want to implement of this story have been
implemented, the rest we won't be implementing.

This story keeps track of general ideas around project layout.

Given all of the ideals floating around (mutli-language needle, model
groups, etc), there is a general direction in which the projects
layout seems to be evolving. This story captures that direction.

: / projects
:   / config -> not the best of names, still needs some thinking.
:   / dynamic
:   / sanity
:   / dia -> whilst we use it for the frontend, this is not frontend specific.
:   / formatting -> rename of the formatters model. Generic formatting code.
:   / tack
    / tack.json
:   / tack.dia
:   / tack.xsd -> XML schema support (vision)
:    / <all other tack importers>
:   / backend
:     / common -> current backend model. all code common across backends.
:     / quilt -> model group for "native models"
:       / cpp
:       / csharp (vision)
:       / java (vision)
:       / <all other languages>
:     / pleat -> model group for "cross-language compatible" models
:       / cpp (vision)
:       / csharp (vision)
:       / java (vision)
:       / <all other languages>
:   / test_models
:     / knit -> consider splitting them by tool?
:       / all_primitives
:       / <all other knit test models>
:     / stitch -> consider splitting them by tool?
:       / seam
:   / utility -> consider renaming to common? or find a sewing term for this?
:   / knit
:   / knitter
:   / stitch
:   / stitcher

*Notes*:

- We settled on =common= for models to house shared code; =core= was
  also considered, but its not always the case that the shared code is
  "core code".
- note that when we say =backend=, =frontend= and =middle-end= we are
  implicitly talking about =knit=. Its not very elegant to have the
  knit internals so prominent at the top, but its not obvious how else
  to organise the code.
- it would be nice to have top-level folders for tools (e.g. =knit=)
  that would contain both the =knit= library and the =knitter=
  tool. However we haven't found a good way of structuring the folders
  that way.

*** COMPLETED Create a blog post on pull request driven development   :story:
    CLOSED: [2015-12-11 Fri 13:32]
    CLOCK: [2015-12-11 Fri 12:12]--[2015-12-11 Fri 13:32] =>  1:20

Pen some ideas down on the advantages of the PR process.

*** CANCELLED Remove =is_root_parent_visitable=                       :story:
    CLOSED: [2015-12-08 Tue 22:57]

*Rationale*: this is an optimisation to stop us from having to query
the container. As such it is legitimate. Same with is visitable.

We should just use the =visits=, =visited_by=, etc relationships. The
existing flag will break with multiple inheritance.

*** STARTED Implement formattables in terms of yarn types             :story:

At present formattables are just a shadow copy of yarn types plus
additional =cpp= specific types. In practice:

- for the types that are shadow copies, we could have helper utilities
  that do the translation on the fly (e.g. for names).
- for additional information which cannot be translated, we could have
  containers indexed by qualified name and query those just before we
  call the transformer. This is the case with formatter properties. We
  need something similar to house "type properties" such as
  =requires_stream_manipulators=. These could be moved into aspect
  settings.
- for types that do not exist in yarn, we could inherit from element;
  this is the case for registrar, forward declarations, cmakelists and
  odb options. Note that with this we are now saying that element
  space contains anything which can be modeled, regardless of if they
  are part of the programming language type system, or build system,
  etc. This is not ideal, but its not a problem just yet. We could
  update the factory to generate these types and then take a copy of
  the model and inject them in it.

*** STARTED Add relationship types to handle "requires"               :story:

*New Understanding*

- we could solve this problem if in dynamic fields could have a
  "propagation type" that results in propagating field instances
  across the element graph.
- this can only be done as the last step in yarn because we need all
  properties to have been indexed, merging, resolution etc.
- at this point we could generate a graph. Vertices are the dynamic
  objects; edges are obtained by looking at the relevant
  relationships: regular associations, weak associations, parents. We
  perhaps should have one graph per relationship type to make things
  easier.
- the graph starts at a root, and the next vertex is the first dynamic
  object that needs to be "computed". We look at all the fields in
  that object that require "computation" and at the "computation
  type".
- cycles are the big problem. However, it seems one cannot have cycles
  in C++ as this would cause inclusion problems. This is normally
  resolved by weak relationships. We need to confirm this for cycles
  with more than 2 edges. If this is true, we could force all
  languages to declare relationships as weak when there is a cycle
  somehow (note that we do not have the concept of pointers in java/c#
  so perhaps the relationship itself would have to be annotated). We
  could then have a default behaviour for weak relationships such as
  never follow, etc.

*Previous Understanding*

This story needs to be named properly, once we actually understand
what it is that it is about.

Moment of realisation: we could describe all relationships between
types as relations in the form a R b. We are already doing these, its
just that we model them in a variety of ways (properties, relationship
types, etc). This is fine because the driver for the modeling is the
"language" model (e.g. =cpp=). However, there is a class of use cases
that we have yet failed to solve. The general form of these use cases
is as follows:

- type b has some meta-data m;
- type b is related to type a via some relation R;
- type a should also be treated as having m.

Another variation is where a is related to multiple types b0, b1, bn
and we want to perform some computation on m0, m1, mn to determine the
value for a.

It seems that both of these use cases could be solved if only we had a
way to represent a R b in =tack::model=. We have spotted the following
Rs:

- non-transitive aggregation, not "expanding" generics: all types
  aggregated with a type; if a type is a generic type, we ignore the
  type parameters. It is non-transitive in the following sense: if
  type a aggregates type b and type b aggregates type c, it does not
  mean that type a aggregates type c. Use cases: requires manual move
  constructor, requires manual default constructor.
- non-transitive aggregation, "expanding" generics: all types
  aggregated with a type; if a type is a generic type, then all of the
  type parameters are considered to also be associated. Use cases:
  requires stream manipulators.
- transitive association, "expanding" generics: all types aggregated
  to a type and all types that those types aggregate to; all types
  that this type inherits from and their parents. Use cases:
  enablement.

Note that we still haven't solved the fundamental enablement problem,
as we can still have cycles on the graph (e.g. a is related to
a). However, we can now create the traversal with cycles algorithm: it
follows R and remembers the original type (e.g. a); when we spot that
type again (e.g. y depends on a and a depends on y) we add all types
that depend on it (y) to a "blocked" pile. We do process all other
dependencies of y. The pile would have the form of: a blocks y. Even
though y is blocked, we can still answer a. Once we answered a we can
then answer all types blocked by a (they may have more than one block
though). The key thing here is if a type has a cycle on itself its not
a problem, we can just skip it. If a type has a dependency on a type
which has a cycle, we must first sort out the type with the cycle.

This story still needs a lot of work but its just a dump of all of the
ideas at this point in time.

Notes:

- we need a "requires" repository, factory etc in formattables that
  handles all of the "requires xyz" cases. We may need two of these,
  per relation type.
- we need to expand enablement to perform the algorithm above.
- we need to expand relationship management in tack, adding these new
  relationship types and populating them.
- includes builder needs access to the "requires" data in order to
  compute includes.

Merged stories:

*Add support for the relationships graph in enabler*

*Note*: this story needs refactoring. It is basically here to cover
the support for a graph with cycles in enabler but has not yet been
updated.

This needs a bit more analysis. The gist of it is that not all types
support all formatters. We need a way to determine if a formatter is
not supported. This probably should be inferred by a "is dogen model"
property (see backlog); e.g. non-dogen models need their types to have
an inclusion setup in order to be "supported", otherwise they should
default to "not-supported". However the "supported" flag is populated,
we then need to take into account relationships and propagate this
flag across the model such that, if a type =A= in a dogen model has a
property of a type =B= from a non-dogen model which does not support a
given formatter =f=, then =A= must also not support =f=.

In order to implement this feature we need to:

- update the SML grapher to take into account relationships
  (properties that the class has) as well as inheritance.
- we must only visit related types if we ourselves do not have values
  for all supported fields.
- we also need a visitor that detects cycles; when a cycle is found we
  simply assume that the status of the revisited class is true (or
  whatever the default value of "supported" is) and we write a warning
  to the log file. We should output the complete path of the cycle.
- users can override this by setting supported for all formatters
  where there are cycles.
- we could perhaps have a bitmask by qname; we could start by
  generating all bitmasks for all qnames and setting them to default
  value. We could then find all qnames that have supported set to
  false and update the corresponding bitmasks. Then we could use the
  graph to loop through the qnames and "and" the bitmasks of each
  qname with the bitmasks of their related qnames. The position of
  each field is allocated by the algorithm (e.g. the first "supported"
  field is at position 0 and so on). Actually the first position of
  the bitmask could be used to indicate if the bitmask has already
  been processed or not. In the presence of a cycle force it to true.
- we need a class that takes the SML model and computes the supported
  bitmasks for each qname; the supported expander then simply takes
  this (perhaps as part of the expansion context), looks up for the
  current qname and uses the field list to set the flags
  appropriately.
- we should remove all traces of supported from a settings
  perspective; supported and multi-level enabled are just artefacts of
  the meta-data. From a settings perspective, there is just a
  formatter level (common formatter settings) enabled which determines
  whether the formatter is on or off. How that flag came to be
  computed is not relevant outside the expansion process. This also
  means we can have simpler or more complex policies as time allows us
  improve on this story; provided we can at least set all flags to
  enabled we can move forward.

Solution for cycles:

- detect the cycle and then remember the pair (a, b) where b is the
  start of the cycle and a is the last vertex before the cycle. We
  should assume that a is (true, true) for the edge (a, b) and compute
  all other edges. Finally, once the graph has been processed we
  should check all of the pairs in a cycle; for these we should simply
  look at the values of b, and update a accordingly.

Other notes:

- we need some validation to ensure that some types will be generated
  at all. The existing "generatable types" logic will have to be
  removed or perhaps updated; we should take the opportunity to make
  it reflect whether a type belongs to the target model or not. This
  has no bearing on generatability (other that non-target types are
  always not generated). So at the middle-end level we need to check
  if there are any target types at all, and if not, just want the user
  and exit. Then, a second layer is required at the model group /
  language level to determine if there are any types to generate. It
  is entirely possible that we end up not generating anything at all
  because once we went through the graph everything got
  disabled. Users will have to somehow debug this when things go
  wrong.
- following on from this, we probably need a "dump info" option that
  explains the enabled/supported decisions for a given model, for all
  target types; possibly, users could then supply regexes to filter
  this info (e.g. why did you not generate =hash= for type =xyz=? can
  I see all types for formatter =abc=?). It may be useful to have an
  option to toggle between "target only types" and "all types",
  because the system types may be the ones causing the problem.
- the enabled supported logic applies to all formatters across all
  model groups.

*Capture enablement validation rules*

Enablement requires some validation. This story captures all the rules
we need to check for.

- integrated IO must not be enabled if IO is enabled and vice-versa
  (opaque settings validator). actually it seems this is possible, we
  need to investigate the current implementation.
- types must be enabled
- if serialisation is enabled, types forward declaration of the
  serialisation classes must be enabled

*** STARTED Yarn minor tidy-ups                                       :story:

Go through all files in yarn and do all the minor tidy-ups we haven't
yet done:

- remove context, use model references directly
- add comments: purpose of the class, explanation of algorithms,
  whether the class is expected to work on a partial or merged model,
  etc.
- break long functions.

Classes done:

- assembler, association indexer, building error, concept, concept
  indexer, element, element traversal, enumerator, expander, frontend
  registrar, frontend workflow , frontend interface.

*** STARTED Remove =service= stereotype                               :story:
    CLOCK: [2015-12-08 Tue 22:27]--[2015-12-08 Tue 22:45] =>  0:18

This really just means non-generatable, or do not generate. We already
have a stereotype for this. Remove =service= and any other stereotype
which is not being used such as =value_object= etc.

Actually, non-generatable is not a stereotype really. We should
instead have some meta-data that can affect generation:

- do not generate: do nothing at all. For references only. If a file
  exists with this file name, it will be deleted as part of
  housekeeping.
- generate blank file if it doesn't exist: we don't even want a
  template.
- generate with content if it doesn't exist, do not touch otherwise:
  what we call services at the moment. Generate a "template" that then
  gets filled in manually.
- generate and merge: merge the contents of the generated file with
  the current contents in the file system. When we support merging.
- generate and overwrite: generate the file and overwrite whatever
  exists in the file system.

This could be called "generation policy".

The second behaviour we get for free with services is that we disable
all facets except for types. A few points:

- we may want to have io, serialisation, etc. This is not possible at
  present. If a state of a service is made up of supported types, we
  could even use existing code generation.
- in order for this to be implemented correctly we need to hook in to
  the enablement management somehow. In addition, it seems each facet
  can have its own generation policy. For example we may want to
  manually create types but automatically generate io.
- the best way to handle this may be to setup "enablement profiles"
  that the user can hook up to. For example we could have a "default"
  profile that enables all facets (or uses facet defaults), a second
  "service" profile that enables types with partial generation and io
  with full generation and so on. We probably also need "generation
  profiles" to go with "enablement profiles".

*** STARTED Create visitor and exception yarn types                   :story:
    CLOCK: [2015-12-10 Thu 07:11]--[2015-12-10 Thu 07:31] =>  0:20
    CLOCK: [2015-12-09 Wed 21:04]--[2015-12-09 Wed 23:38] =>  2:34
    CLOCK: [2015-12-08 Tue 23:48]--[2015-12-09 Wed 00:13] =>  0:25
    CLOCK: [2015-12-08 Tue 22:55]--[2015-12-08 Tue 23:35] =>  0:40

We should not have object types for these two cases; these are
actually full blown entities. For exceptions we should have
inheritance support but not for visitors. Add only the properties that
make sense for the type.

- create a new concept to model the ability to have relationships with
  other elements: relatable?
- move relationships, is final, is parent, is child, is visitable, is
  root parent visitable to relatable.
- move is immutable, is fluent to stateful.
- remove stateful element.
- make object a relatable, statuful element.
- add visitor as an element.
- add exception as a relatable element. Actually we probably should
  add it as an element for now and update the inheritance story for
  exceptions.
- considered making concept Generalisable, but it becomes quite
  confusing because refinement is not quite the same thing as
  inheritance. Cancelled the change in the end.

*** STARTED Update copyright notices                                  :story:
    CLOCK: [2015-12-10 Thu 06:51]--[2015-12-10 Thu 07:10] =>  0:19

We need to update all notices to reflect personal ownership until DDC
was formed, and then ownership by DDC.

- first update to personal ownership has been done, but we need to
  test if multiple copyright entries is properly supported.

*** Improve helper methods implementation                             :story:

When a formatter relies on the helper methods, we have a problem: we
need to determine the required includes from the main formatter
without knowing what the helper methods may need. We have hacked this
with things like the "special includes" but there must be a cleaner
way of doing this. For example, we could ask the helper methods
formatter to provide its includes and it would be its job to either
delegate further or to compute the includes. This would at least
remove the duplication of code between io and types.

However, its important to bear in mind that helper methods are a hack
anyways so we don't want to spend too much time fixing them. Actually,
as we failed with the needle implementation, these may be here to stay
for quite a bit so we need to make sure the implementation is
maintainable. This means adding new helpers should be easy, as well as
binding existing helpers to new types.

For this we need a way to allow helper methods to bind dynamically to
types. This can be done by using meta-data. The helper method
registers a name and the type uses that name it its key for helper
method. Where possible the helper method should use the name of the
STL concept it is binding to.

We should also find a nicer way to package helper methods, maybe
aligned to a model and type or concept.

Once this is done we need to remove the object types that exist in
yarn just to figure out what helper methods to use.

*** Add "field propagation" support to dynamic                        :story:

- add a graph to yarn that allows external users to set
  dependencies. The graph is not known to be acyclic. Normally we keep
  track of all the orphans and link those to the root. This won't work
  for cycles. We need a way to arbitrarily define one "end" of the
  cycle as the starting point.
- graph must distinguish between vertices that arise by expanding
  generics from those that arise by other means.
- add propagation type to fields and add enumeration.
- add a "propagator" that is responsible for walking the graph and
  setting the fields accordingly. The propagator is used from yarn's
  workflow. We need to have the ability of sending in references to
  dynamic objects into the graph so that the propagator can update
  them.

*** Handle registration of services properly                          :story:

We need a way to determine if a type which is part of a generalisation
should be added to the registrar or not. In =generalisation_indexer=:

:     // FIXME: massive hack. must not add leafs for services.

One way would be to check if serialisation is enabled for that type
and if not, skip the type.

*** Refactor code around model origination                            :story:

- remove origin types and generation types, replacing it with just a
  boolean for is target. Actually we need something like:
  proxy_reference, non_proxy_reference, target. We also need a good
  name for this enumeration:
- at present we are using origin type to determine whether to create a
  registrar, etc in cpp model. There is no other use case for
  this. This is done in several places due to the bad handling of C++
  specific types. Grep for =references= in =cpp= to find all
  locations. We could split references into two (dogen, non-dogen).
- we should also replace has generatable types with something more
  like "target model has types" or "is target model empty". The idea
  we are trying to capture is that the target model contained at least
  one type. This could be set by the merger when it processes the
  target model.

*Previous Understanding*

In the past we added a number of knobs around generation, all with
their own problems:

- =origin_types=: was the model/type created by the user or the
  system. in reality this means did the model come from Dia or
  JSON. this is confusing as the user can also add JSON files (their
  own model library) and in the future the user can use JSON
  exclusively without needed Dia at all.
- =generation_types=: if the model is target, all types are to be
  generated /unless/ they are not properly supported, in which case
  they are to be "partially" generated (as is the case with
  services). This is a formatter decision and yarn should not know
  anything about it. Actually this is not quite true; users may want
  to stop generation.

These can be replaced by a single enumeration that indicates if the
type/model is target or not.

This work should be integrated with the model types story.

Merged stories:

*Split references into dogen and non-dogen models*

If we had two containers of references, one for dogen models and
another one for non-dogen models - which we could give a nice name, to
imply its foreign origin - we could then use the dogen references for
registrar, etc. This is a replacement for the origin type.

We need a good name for these. Candidates:

- proxy model: represents something that exists in the outside
  world. e.g. =is_proxy=.

*** Add =interface= stereotype                                        :story:

Even though we can't generate much outside of plain types, we should
already have support for a stereotype of =interface= which for now
behaves just like =service=. In the future we may be able to code
generate the interface. This should be implemented in yarn as a type
on its own right.

- add an interface which is: element, operatable, relatable. Not
  stateful. We should also have a "is abstract" flag
  somewhere. Perhaps in relatable?

*** Implement module expander test                                    :story:

We copied across the code for the module expander test from yarn json
but didn't actually finished implementing it.

*** Create =src= and =include= facets                                 :story:

At present we have some formatters that are not in the traditional
facets such as =types=, etc. We should make facets for them. We need
to check what the current facet name is. There should only be one case
of this, the CMakeLists formatters.

*** Move all properties in =cpp= to a properties namespace            :story:

Once all formattables are gone, we should have only properties left in
the formattables namespace. We should then rename it to
properties.

Merged stories:

*Split formatter properties and associated classes from formattables*

We have two kinds of data: the formattables themselves (mapped from
yarn) and associated data (formatter properties). The latter is
totally independent. We should create a namespace for all of these
classes and a workflow that produces the data ready for consumption. A
tentative name is =manifest=.

*** Consider renaming nested name                                     :story:

*New understanding*:

This story requires further analysis. Blindly following the composite
pattern was tried but it resulted in a lot of inconsistencies because
we then had to follow MEC-33 and create =abstract_qname=; however, the
nested qname does not really behave like a composite qname; its more
like the difference between a type in isolation and a type
instantiated as an argument of a function. For example, whilst the
type in isolation may have unknown template parameters, presumably, as
an argument of a function these have been instantiated with real
types.

One way to solve this is just to make the type name a bit more
explicit rather than try to imply the composite pattern
(e.g. "nested"). We need a name that signifies "instantiated
type". Look at the C++ standard for the difference between defining a
generic type and instantiating a generic type.

No good names yet (type reference, type instantiation, instantiated
name). What are we trying to represent: an identifier which points to
a complete definition of a name such that the name can be instantiated
as a type in the underlying language. By "instantiated" we mean used
to define variables of this type. In this light: instantiable name,
definable name? If we choose instantiable name, we could then rename
"children" to type arguments.

Other notes:

- there is such a thing as a element instance identifier. We call it
  nested name at present. The element instance identifier identifies
  instantiations of types. It models two cases: for the case where the
  type has no type parameters, the instance identifier is equal to the
  element identifier; for all other cases, it is a hierarchical
  collection of element identifiers, modeling the type parameter
  structure.

*Previous understanding*:

We should just follow the composite pattern in the naming.

*** Copyright holders is scalar when it should be an array            :story:

At present its only possible to specify a single copyright holder. It
should be handled the same was as odb parameters, but because that is
done with a massive hack, we are not going to extend the hack to
copyright holders.

*** Filter out unused types from final model                          :story:

When we finished assembling the model we should be able to determine
which supporting types are in use and drop those that are not. This
can be done just before building the final model (or as part of that
task).

We should have a class responsible for removing all types from a model
which are not in use. This could be done as part of model assembly.

One way this could be achieved is by adding a "usages" property,
computed during resolution. Resolver could keep track of the
non-target names that are in use and return those.

*** Handle enumeration type dynamically                               :story:

- add some enumeration post-processing that assigns it a underlying
  type. Should be done with merged model (look for a primitive type with
  property =is_default_enumeration_type=).

*** Services and leaves are not properly handled                      :story:

We are manually ignoring services when calculating leaves.

*** Use dots in data files extensions                                 :story:

At the moment we use extensions such as =xmlyarn=. It should really be
=.xml.yarn= or something of the kind.

*** Consider renaming includers                                       :story:

Its very confusing to have header files that include lots of other
header files called "includers". There is too much overloading. We
should consider calling them "master header files" as per Schaling
terminology in the [[http://theboostcpplibraries.com/boost.spirit][boost book]].

*** Update Linux CDash agent                                          :story:

We need to get the build green on the Linux agent again.

*** Update Windows CDash agent                                        :story:

We need to get the build green on the Windows agent again.

*** Add tests to identifier parser with invalid names                 :story:

We need to handle properly the following cases:

- totally blank name.
- template with angle brackets but nothing inside: =a<>=.
- template with angle brackets, type and then a comma: =a<b,>=.

** Deprecated
