#+title: Sprint Backlog 89
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- finish refactoring quilt.cpp.
- tidy-up services, origin types and generation types.
- start work on wale templates.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2016-10-05 Wed 22:14]
| <75>                                                                        |         |       |      |       |
| Headline                                                                    | Time    |       |      |     % |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| *Total time*                                                                | *68:01* |       |      | 100.0 |
|-----------------------------------------------------------------------------+---------+-------+------+-------|
| Stories                                                                     | 68:01   |       |      | 100.0 |
| Active                                                                      |         | 68:01 |      | 100.0 |
| STARTED Sprint and product backlog grooming                                 |         |       | 5:15 |   7.7 |
| COMPLETED Edit release notes for previous sprint                            |         |       | 0:07 |   0.2 |
| COMPLETED Generation of formattable is incorrect                            |         |       | 2:30 |   3.7 |
| COMPLETED Visitor includes are incorrect                                    |         |       | 0:20 |   0.5 |
| COMPLETED Add includer to quilt.cpp                                         |         |       | 1:46 |   2.6 |
| COMPLETED Add reducer to quilt.cpp                                          |         |       | 0:22 |   0.5 |
| COMPLETED Add new index to formtter container                               |         |       | 0:19 |   0.5 |
| COMPLETED Add path expander to quilt.cpp                                    |         |       | 0:49 |   1.2 |
| COMPLETED Add guard expander to quilt.cpp                                   |         |       | 0:27 |   0.7 |
| COMPLETED Investigate borked travis build                                   |         |       | 0:37 |   0.9 |
| COMPLETED Add decoration expander to quilt.cpp                              |         |       | 0:23 |   0.6 |
| COMPLETED Add aspect expander to quilt.cpp                                  |         |       | 1:26 |   2.1 |
| COMPLETED Run tests that are passing on windows                             |         |       | 0:10 |   0.2 |
| COMPLETED Add helper expander to quilt.cpp                                  |         |       | 1:26 |   2.1 |
| COMPLETED Merge pre and post workflows                                      |         |       | 0:16 |   0.4 |
| COMPLETED Fix bug in aspect and helper generation                           |         |       | 0:15 |   0.4 |
| COMPLETED Investigate element annotation support                            |         |       | 2:05 |   3.1 |
| CANCELLED Add streaming settings expander                                   |         |       | 0:36 |   0.9 |
| COMPLETED Create the formattables model                                     |         |       | 1:32 |   2.3 |
| COMPLETED Hook formattables into formatters                                 |         |       | 3:58 |   5.8 |
| COMPLETED Remove empty context                                              |         |       | 1:09 |   1.7 |
| COMPLETED Review main classes in quilt.cpp                                  |         |       | 3:42 |   5.4 |
| COMPLETED Clean up element segmentation                                     |         |       | 1:20 |   2.0 |
| COMPLETED Get OSX build to compile code                                     |         |       | 7:05 |  10.4 |
| COMPLETED Add a banner to readme                                            |         |       | 1:29 |   2.2 |
| COMPLETED Remove formatter group                                            |         |       | 0:23 |   0.6 |
| COMPLETED Add more types to =quilt::cpp= canned tests                       |         |       | 0:15 |   0.4 |
| CANCELLED Remove formatter id                                               |         |       | 0:04 |   0.1 |
| COMPLETED Analysis around terminology in formatting space                   |         |       | 3:24 |   5.0 |
| COMPLETED Remove =original_model_name=                                      |         |       | 0:16 |   0.4 |
| COMPLETED Refactor code around model origination                            |         |       | 4:08 |   6.1 |
| COMPLETED Remove formatter level facet folders                              |         |       | 0:06 |   0.1 |
| COMPLETED Consider removing the "fake" primitive formatters                 |         |       | 0:01 |   0.0 |
| COMPLETED Expander refactor in =quilt.cpp=                                  |         |       | 3:03 |   4.5 |
| COMPLETED Create the notion of a formatter alias                            |         |       | 3:15 |   4.8 |
| COMPLETED Remove enabled formatters from formatter configuration            |         |       | 0:22 |   0.5 |
| COMPLETED Handle registration of services properly                          |         |       | 3:41 |   5.4 |
| COMPLETED Move stereotypes to element                                       |         |       | 0:21 |   0.5 |
| STARTED Add support for profiles                                            |         |       | 8:50 |  13.0 |
| STARTED Generate formatter interfaces                                       |         |       | 0:28 |   0.7 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2016-10-05 Wed 20:20]--[2016-10-05 Wed 20:45] =>  0:25
    CLOCK: [2016-10-04 Tue 19:06]--[2016-10-04 Tue 19:19] =>  0:13
    CLOCK: [2016-10-03 Mon 10:17]--[2016-10-03 Mon 10:21] =>  0:04
    CLOCK: [2016-10-03 Mon 09:00]--[2016-10-03 Mon 10:16] =>  1:16
    CLOCK: [2016-10-02 Sun 21:25]--[2016-10-02 Sun 21:40] =>  0:15
    CLOCK: [2016-10-02 Sun 20:15]--[2016-10-02 Sun 21:24] =>  1:09
    CLOCK: [2016-10-02 Sun 10:50]--[2016-10-02 Sun 11:54] =>  1:04
    CLOCK: [2016-09-27 Tue 10:04]--[2016-09-27 Tue 10:13] =>  0:09
    CLOCK: [2016-09-26 Mon 15:36]--[2016-09-26 Mon 15:39] =>  0:03
    CLOCK: [2016-09-26 Mon 09:49]--[2016-09-26 Mon 10:00] =>  0:11
    CLOCK: [2016-09-26 Mon 09:22]--[2016-09-26 Mon 09:48] =>  0:26

Updates to sprint and product backlog.

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2016-09-26 Mon 10:08]
    CLOCK: [2016-09-26 Mon 10:01]--[2016-09-26 Mon 10:08] =>  0:07

Add github release notes for v88.

Text:

#+begin_src markdown
Overview
=======

We continue our long road of internal refactorings, focusing on the ```quilt.cpp``` model. There are no user visible changes in this release.

For more details see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_88.org).
#+end_src

*** COMPLETED Generation of formattable is incorrect                  :story:
    CLOSED: [2016-09-26 Mon 13:03]
    CLOCK: [2016-09-26 Mon 12:50]--[2016-09-26 Mon 13:03] =>  0:13
    CLOCK: [2016-09-26 Mon 12:30]--[2016-09-26 Mon 12:49] =>  0:19
    CLOCK: [2016-09-26 Mon 11:51]--[2016-09-26 Mon 12:16] =>  0:25
    CLOCK: [2016-09-26 Mon 11:42]--[2016-09-26 Mon 11:51] =>  0:09
    CLOCK: [2016-09-26 Mon 10:09]--[2016-09-26 Mon 11:33] =>  1:24

The new formattable type is generating an invalid header file. It is
missing the forward declaration of the yarn element.

Note: to login to postgres from emacs, [[http://emacs.1067599.n8.nabble.com/sql-postgresql-authentication-failure-td71620.html][leave server empty]].

Load relevant data into postgres for querying:

: grep dogen.knitter.quilt.cpp.log -e "Finished inclusion directives repository" > crap.txt
: cut -b142- crap.txt > ~/inclusion.json
: create table inclusion_directives_json (values jsonb);
: \copy inclusion_directives_json from '~/inclusion.json';

Now create a row per entry in the container:

: create table inclusion_directives2_json (values jsonb);
: insert into inclusion_directives2_json
: select jsonb_array_elements(values->'by_name')
: from inclusion_directives_json;

Now find out type:

: select values as val
: from inclusion_directives2_json
: where values::text like '%<dogen><quilt><cpp><formattables><formattable>%';

And dump it to a file:

: \copy (select values as val from inclusion_directives2_json
: where values::text like '%<dogen><quilt><cpp><formattables><formattable>%')
: to 'out.json';

Actually this was for the directives. We need the same but for the dependencies:

: grep dogen.knitter.quilt.cpp.log -e "Finished creating inclusion dependencies: " > crap.txt
: cut -b144- crap.txt > ~/inclusion_deps.json
: create table inclusion_deps2_json (values jsonb);
: \copy inclusion_deps_json from '~/inclusion_deps.json';

Split objects:

: insert into inclusion_deps2_json
: select jsonb_array_elements(values->'by_name')
: from inclusion_deps_json;

Find our object:

: select values from inclusion_deps2_json
: where values::text like '%<dogen><quilt><cpp><formattable>%';

Save it:

: copy (select values from inclusion_deps2_json where values::text
: like '%<dogen><quilt><cpp><formattables><formattable>%')
: to '~/deps.json';

Actually the problem really was with the inclusion directives! It
seems we are not generating the forward declarations for element:

: select values as val
: from inclusion_directives2_json
: where values::text like '%<dogen><yarn><element>%';

No mention of forward declarations. The problem is fabric is only
injecting forward declarations for the target model. we need to relax
this and do it for all models.

When we do this we seem to overwrite the helper configuration for
types such as =boost::filesystem::path=.

*** COMPLETED Visitor includes are incorrect                          :story:
    CLOSED: [2016-09-26 Mon 13:25]
    CLOCK: [2016-09-26 Mon 13:17]--[2016-09-26 Mon 13:25] =>  0:08
    CLOCK: [2016-09-26 Mon 13:04]--[2016-09-26 Mon 13:16] =>  0:12

We are adding an include to the descendants' header for no
reason. Remove it.

*** COMPLETED Add includer to quilt.cpp                               :story:
    CLOSED: [2016-09-26 Mon 15:13]
    CLOCK: [2016-09-26 Mon 14:43]--[2016-09-26 Mon 15:13] =>  0:30
    CLOCK: [2016-09-26 Mon 13:26]--[2016-09-26 Mon 14:42] =>  1:16

Responsible for computing the inclusion dependencies.

- add a flag in builder to choose new or old API. Supply formattables
  container by ID and new directives repository. When using old API,
  these are default initialised. With new API the other parameters are
  default initialised. Actually a better approach is to create two
  builder impls and to decide which one to use based on the
  constructor of the builder.

*** COMPLETED Do not compute inclusion directives for system models   :story:
    CLOSED: [2016-09-26 Mon 15:23]

*Rationale*: Fixed with new inclusion expander. We only compute
directives as a last resort.

It seems we are computing inclusion directives and other path
derivatives for system models:

: {
:   "__type__": "dogen::cpp::expansion::path_derivatives",
:   "file_path": "/home/marco/Development/DomainDrivenConsulting/output/dogen/clang-3.5/stage/bin/../test_data/all_primitives/actual/std/include/std/serialization/unique_ptr_fwd_ser.hpp",
:   "header_guard": "STD_SERIALIZATION_UNIQUE_PTR_FWD_SER_HPP",
:   "inclusion_directive": "<quote>std/serialization/unique_ptr_fwd_ser.hpp<quote>"
: }

This comes out of the workflow, so we possibly are then ignoring it
for the non-target types. So:

- can we avoid computing these altogether?
- are we ignoring it?

Actually this is the usual problem with the "origin" of the type. We
need a way to determine if this type needs computations or not. We
need to create a story to clean up the =origin_type= and
=generation_type= and then we can make use of it to determine if we
need to compute inclusion, path etc or not.

*** COMPLETED Add reducer to quilt.cpp                                :story:
    CLOSED: [2016-09-26 Mon 15:36]
    CLOCK: [2016-09-26 Mon 15:14]--[2016-09-26 Mon 15:36] =>  0:22

Removes all types that are non-generatable.

Merged stories:

*Add filter to quilt.cpp*

Removes the non-target formattables.

*** COMPLETED Add new index to formtter container                     :story:
    CLOSED: [2016-09-26 Mon 17:48]
    CLOCK: [2016-09-26 Mon 16:56]--[2016-09-26 Mon 17:15] =>  0:19

It is actually quite useful to look for a formatter by formatter
name. We should provide this in formatter container and use it from
inclusion expander.

*** COMPLETED Add path expander to quilt.cpp                          :story:
    CLOSED: [2016-09-26 Mon 17:49]
    CLOCK: [2016-09-26 Mon 17:16]--[2016-09-26 Mon 17:49] =>  0:33
    CLOCK: [2016-09-26 Mon 16:39]--[2016-09-26 Mon 16:55] =>  0:16

Generates the full paths.

*** COMPLETED Add guard expander to quilt.cpp                         :story:
    CLOSED: [2016-09-26 Mon 18:17]
    CLOCK: [2016-09-26 Mon 17:50]--[2016-09-26 Mon 18:17] =>  0:27

Generates the header guards. Merged with path generator.

*** COMPLETED Investigate borked travis build                         :story:
    CLOSED: [2016-09-26 Mon 18:38]
    CLOCK: [2016-09-26 Mon 20:43]--[2016-09-26 Mon 21:05] =>  0:22
    CLOCK: [2016-09-26 Mon 18:18]--[2016-09-26 Mon 18:33] =>  0:15

We seem to have borked the build some how:

https://travis-ci.org/DomainDrivenConsulting/dogen/builds/162785692
https://travis-ci.org/DomainDrivenConsulting/dogen/builds/162801645

Hopefully this is just due to not running tests locally. Checkout a
worktree and check.

: git worktree add ../dogen_1fd4399 origin/master
: cd ../dogen_1fd4399/
: mkdir build/output
: build/scripts/build.linux.sh Release gcc /usr/local/personal run_knit.tests

Problem reproduced locally, must have forgotten to run the tests.

: Running 33 test cases...
: ../../../../projects/knit/tests/workflow_tests.cpp(203): error: in "workflow_tests/trivial_inheritance_model_generates_expected_code": check generate_and_diff(target) has failed
: ../../../../projects/knit/tests/workflow_tests.cpp(233): error: in "workflow_tests/std_model_generates_expected_code": check generate_and_diff(target) has failed
: ../../../../projects/knit/tests/workflow_tests.cpp(239): error: in "workflow_tests/boost_model_generates_expected_code": check generate_and_diff(target) has failed
: ../../../../projects/knit/tests/workflow_tests.cpp(245): error: in "workflow_tests/stereotypes_model_generates_expected_code": check generate_and_diff(target) has failed
:
: *** 4 failures are detected in the test module "knit_tests"
: ninja: build stopped: subcommand failed.

Actually, the problem persists. It seems this is related to clean
builds. We seem to have lost service forward declarations.

*** COMPLETED Add decoration expander to quilt.cpp                    :story:
    CLOSED: [2016-09-26 Mon 21:24]
    CLOCK: [2016-09-26 Mon 21:19]--[2016-09-26 Mon 21:24] =>  0:05
    CLOCK: [2016-09-26 Mon 18:34]--[2016-09-26 Mon 18:52] =>  0:18

Generates the decoration.

Merged stories:

*Add file properties generator to to quilt.cpp*

We need to generate the file properties for each formattable. The
formatter must supply the modeline name. At present we have a hack in
element properties to determine the modeline.

*** COMPLETED Add aspect expander to quilt.cpp                        :story:
    CLOSED: [2016-09-26 Mon 22:51]
    CLOCK: [2016-09-26 Mon 21:25]--[2016-09-26 Mon 22:51] =>  1:26

Generates the aspect configuration.

- first generate a container with aspect annotations.
- then use it to compute aspect configurations; populate those
  directly into the formattable.

*** COMPLETED Run tests that are passing on windows                   :story:
    CLOSED: [2016-09-27 Tue 08:19]
    CLOCK: [2016-09-26 Mon 21:06]--[2016-09-26 Mon 21:16] =>  0:10

At present we have a release build on windows but we are not running
any tests. This is because some of the tests are failing at the
moment. We should run all test suites that are green to ensure we
don't regress without noticing.

Look at the stories with errors to determine which tests are passing.

*** COMPLETED Add helper expander to quilt.cpp                        :story:
    CLOSED: [2016-09-27 Tue 09:46]
    CLOCK: [2016-09-27 Tue 08:19]--[2016-09-27 Tue 09:45] =>  1:26

Generates the helper configuration.

*** COMPLETED Merge pre and post workflows                            :story:
    CLOSED: [2016-09-27 Tue 10:03]
    CLOCK: [2016-09-27 Tue 09:47]--[2016-09-27 Tue 10:03] =>  0:16

It seems we don't have much of a post reduction workflow. Merge them.

*** COMPLETED Add formattable element                                 :story:
    CLOSED: [2016-09-27 Tue 10:05]

*Rationale*: we introduced the type in the previous sprint. The
hooking of it is a different story.

Create a top-level formattable type that is an aggregation of the
element and the element configuration. Update workflow to output a
list of formattable and formatters to take in formattable.

Previous understanding:

- create a top-level type that has formatter, element properties and
  element. Must be non-generatable. Add formattable id as the sum of
  element id and formatter id.
- add =formattables::model= as an unordered map of id to
  formattable. Implement formatting workflow in terms of formattables
  model. Add all context properties to model such as
  streaming_settings_repository and helpers_. element_settings should
  be merged with configuration.
- remove formatting context and update formatting workflow to call a
  visitor to resolve the element and then call the formatter.
- add an enablement map for all formatters in the formatter

*** CANCELLED Move name builder into yarn                             :story:
    CLOSED: [2016-09-27 Tue 10:07]

*Rationale*: It was used only during formattables generation for the
helpers. The one method was moved into the expander.

At present we have name builder in quilt.cpp simply to build the
merged namespaces. We should have some kind of utility for this in
yarn.

*** CANCELLED Move registration of providers to initialiser           :story:
    CLOSED: [2016-09-27 Tue 10:07]

*Rationale*: No longer applies since provider refactor.

At present we are iterating through the formatters list in properties
and manually registering all include providers via the interface. This
is not ideal because the formatter interface needs to know of include
providers, meaning we can't move it away from =quilt.cpp=.

When we register a formatter we should also register the include
provider too.

Tasks:

- add provider support directly to the formatters instead of another
  class and remove registration from formatter interface.
- add a static registrar for the include providers in workflow.
- change initialiser to register the include providers from the same
  shared pointer.

*** CANCELLED Implement all formatter interfaces                      :story:
    CLOSED: [2016-09-27 Tue 10:10]

*Rationale*: we implemented primitives. there is no need to do this
for concepts.

We still have a couple of skeleton interfaces:

- primitives
- concepts

We should throw if formatting is required.

*** CANCELLED Remove =optional<list>=                                 :story:
    CLOSED: [2016-09-27 Tue 10:12]

*Rationale*: we've already done a few of these. This story is too much
of an epic to be useful.

We should not really be using optional<list>. The empty list is
sufficient for this.

Uses:

- include provider. Fixed with other story.

*** COMPLETED Formatters with duplicate names result in non-intuitive errors :story:
    CLOSED: [2016-09-27 Tue 10:10]

*Rationale*: completed with the addition of the formatter by formatter
name container. We now get a duplicate formatter id exception.

We added two formatters to io with the same name by mistake and the
resulting error was not particularly enlightening:

: std::exception::what: Qualified name defined more than once: cpp.io.enum_header_formatter.inclusion_required

We should have a very early on validation to ensure formatters have
distinct names.

Merged stories:

*Check for duplicate formatter names in formatter registrar*

At present it is possible to register a formatter name more than
once. Registrar should keep track of the names and throw if the name
is duplicated.

*** COMPLETED Fix bug in aspect and helper generation                 :story:
    CLOSED: [2016-09-27 Tue 10:58]
    CLOCK: [2016-09-27 Tue 10:43]--[2016-09-27 Tue 10:58] =>  0:15

It seems we are updating non-target types for these configurations but
we weren't before. This caused a break in the verification that
somehow was not spotted.

*** COMPLETED Investigate element annotation support                  :story:
    CLOSED: [2016-09-27 Tue 20:39]
    CLOCK: [2016-09-27 Tue 20:17]--[2016-09-27 Tue 20:39] =>  0:22
    CLOCK: [2016-09-27 Tue 10:59]--[2016-09-27 Tue 12:14] =>  1:15
    CLOCK: [2016-09-27 Tue 10:14]--[2016-09-27 Tue 10:42] =>  0:28

The new formattables do not yet support element annotations. Figure
out if we need to. Seems like we did a brutal hack and left the
processing of "element annotations" to the formatters
themselves. Also, now its clearer why we thought of an annotation
expander (which we since removed).

The right thing to do:

- rename element annotations to opaque annotations
- add opaque annotations to element configuration
- add a opaque annotations expander to read them into the element
  configuration.

Actually we should just avoid the element annotations altogether as
they make no sense at all. Create an opaque configuration and add it
at the correct level in formatter configuration.

Tried to add a verification step but its just too hard, what with
shared pointers etc.

*** CANCELLED Add streaming settings expander                         :story:
    CLOSED: [2016-09-28 Wed 09:39]
    CLOCK: [2016-09-27 Tue 20:55]--[2016-09-27 Tue 21:17] =>  0:22
    CLOCK: [2016-09-27 Tue 20:40]--[2016-09-27 Tue 20:54] =>  0:14

Add streaming settings to the element properties and populate them via
a new expander.

Actually we need to revert this change as these settings need to be
across the whole model.

*** COMPLETED Create the formattables model                           :story:
    CLOSED: [2016-09-28 Wed 09:40]
    CLOCK: [2016-09-28 Wed 08:30]--[2016-09-28 Wed 09:31] =>  1:01
    CLOCK: [2016-09-27 Tue 21:43]--[2016-09-27 Tue 21:50] =>  0:07
    CLOCK: [2016-09-27 Tue 21:18]--[2016-09-27 Tue 21:42] =>  0:24

There are a couple of properties that are shared by all
formattables. One way of solving this is to create a top-level
container for all formattables that also has these properties.

- create model class
- update workflow to return model
- update verification code.
- remove streaming settings from element, delete streaming expander.
- update streaming annotations factory to return correct container.
- create a model factory and a formattables factory. Model factory
  simply assembles model. Formattables workflow hooks them together.

*** COMPLETED Hook formattables into formatters                       :story:
    CLOSED: [2016-09-28 Wed 21:38]
    CLOCK: [2016-09-28 Wed 20:20]--[2016-09-28 Wed 21:38] =>  1:18
    CLOCK: [2016-09-28 Wed 11:39]--[2016-09-28 Wed 12:16] =>  0:37
    CLOCK: [2016-09-28 Wed 11:17]--[2016-09-28 Wed 11:38] =>  0:21
    CLOCK: [2016-09-28 Wed 11:01]--[2016-09-28 Wed 11:16] =>  0:15
    CLOCK: [2016-09-28 Wed 10:36]--[2016-09-28 Wed 11:00] =>  0:24
    CLOCK: [2016-09-28 Wed 09:32]--[2016-09-28 Wed 10:35] =>  1:03

Find a way to format out of the formattables container, side-by-side
with the current formatting workflow.

- remove element annotations from context, use element configuration
  instead.
- create a new formatters workflow that uses formattables.

*** COMPLETED Remove empty context                                    :story:
    CLOSED: [2016-09-28 Wed 22:21]

*Rationale*: done as part of refactor.

We were generating empty contexts before in context factory, but this
should not be required any longer.

<*** COMPLETED Remove include builder legacy classes                   :story:
    CLOSED: [2016-09-28 Wed 22:48]
    CLOCK: [2016-09-28 Wed 22:22]--[2016-09-28 Wed 22:48] =>  0:26
    CLOCK: [2016-09-28 Wed 21:38]--[2016-09-28 Wed 22:21] =>  0:43

When implementing inclusion expander we did a number of ugly hacks to
support both the legacy API and the new API. We need to remove all the
impls etc we added, in builder, factory, etc.

Merged stories:

*Remove all of the legacy infrastructure*

Includes:

- repositories, repository factories in formattables, annotations.

*** COMPLETED Review main classes in quilt.cpp                        :story:
    CLOSED: [2016-09-30 Fri 10:57]
    CLOCK: [2016-09-30 Fri 10:10]--[2016-09-30 Fri 10:57] =>  0:47
    CLOCK: [2016-09-29 Thu 16:30]--[2016-09-29 Thu 17:30] =>  1:00
    CLOCK: [2016-09-29 Thu 13:50]--[2016-09-29 Thu 14:34] =>  0:44
    CLOCK: [2016-09-29 Thu 10:21]--[2016-09-29 Thu 10:47] =>  0:26
    CLOCK: [2016-09-29 Thu 09:42]--[2016-09-29 Thu 09:53] =>  0:11
    CLOCK: [2016-09-29 Thu 09:07]--[2016-09-29 Thu 09:41] =>  0:34

After the large refactor we probably ended up with a lot of loose ends
in quilt.cpp. Do a cursory review of the code.

*** COMPLETED Clean up element segmentation                           :story:
    CLOSED: [2016-09-30 Fri 12:37]
    CLOCK: [2016-09-30 Fri 11:17]--[2016-09-30 Fri 12:37] =>  1:20

Originally we added all element segments at the same level. But in
truth:

- there are always two segments;
- one of which is the "master" segment: the one with "is element
  extension" set to false.

We should formalise this and make the configuration model reflect it.

*** COMPLETED Get OSX build to compile code                           :story:
    CLOSED: [2016-10-01 Sat 23:02]
    CLOCK: [2016-10-01 Sat 22:52]--[2016-10-01 Sat 23:03] =>  0:11
    CLOCK: [2016-10-01 Sat 20:31]--[2016-10-01 Sat 22:51] =>  2:20
    CLOCK: [2016-10-01 Sat 12:30]--[2016-10-01 Sat 13:40] =>  1:10
    CLOCK: [2016-09-30 Fri 23:52]--[2016-10-01 Sat 00:35] =>  0:43
    CLOCK: [2016-09-30 Fri 22:05]--[2016-09-30 Fri 23:52] =>  1:47
    CLOCK: [2016-09-30 Fri 21:10]--[2016-09-30 Fri 22:04] =>  0:54

We've added the initial support for OSX. However, it still needs a lot
of work:

- we can't install the conan package because we don't know how to
  install pkg files. We should raise a ticket on conan for this.
- Alternatively we could build boost ourselves and upload it to
  DropBox.

Notes:

- [[http://www.mactech.com/articles/mactech/Vol.26/26.02/TheFlatPackage/index.html][The Flat Package]]
- [[https://docs.travis-ci.com/user/multi-os/][Matrix with multiple OSs]]

*** COMPLETED Add a banner to readme                                  :story:
    CLOSED: [2016-10-02 Sun 11:54]
    CLOCK: [2016-10-02 Sun 09:20]--[2016-10-02 Sun 10:49] =>  1:29

It would be nice to have some kind of banner to make the readme a bit
more interesting.

*** COMPLETED Remove formatter group                                  :story:
    CLOSED: [2016-10-02 Sun 22:05]
    CLOCK: [2016-10-02 Sun 21:42]--[2016-10-02 Sun 22:05] =>  0:23

It seems we are not using this at present.

Merged stories:

*Consider supporting multiple formatter groups*

In some cases it would be nice for a field to belong to multiple
groups. For example =integrated_facet= is only applicable to class
header formatters. We could implement this by making the formatter
group a collection and having formatters belong to multiple groups.

*** COMPLETED Add more types to =quilt::cpp= canned tests             :story:
    CLOSED: [2016-10-02 Sun 22:21]
    CLOCK: [2016-10-02 Sun 22:06]--[2016-10-02 Sun 22:21] =>  0:15

Originally we used the =*_info= types in the canned tests, but these
are all about to be removed. We need to hunt for types in the
=quilt::cpp= model and add those to the canned tests.

*** COMPLETED Consider renaming model module to root module           :story:
    CLOSED: [2016-10-03 Mon 08:38]

*Rationale*: this seems to have been already done.

It would be more sensible to call it root module rather than model
module. We should also create a root module property in the model to
make it easier to locate.

*** CANCELLED Remove formatter id                                     :story:
    CLOSED: [2016-10-03 Mon 10:13]
    CLOCK: [2016-09-28 Wed 22:49]--[2016-09-28 Wed 22:53] =>  0:04

*Rationale*: in the new world, formatter names are different from
artefact names so we will need something like formatter id.

Not clear why we need this given we have formatter name.

Actually this requires a little bit of thinking as we use the id's in
the helper formatters.

*** COMPLETED Analysis around terminology in formatting space         :story:
    CLOSED: [2016-10-03 Mon 10:19]
    CLOCK: [2016-10-03 Mon 08:20]--[2016-10-03 Mon 08:59] =>  0:39
    CLOCK: [2016-10-02 Sun 17:08]--[2016-10-02 Sun 18:55] =>  1:47
    CLOCK: [2016-10-02 Sun 16:09]--[2016-10-02 Sun 17:07] =>  0:58

One part of the language which has not yet been clarified is around
formatters. We use the term "formatter" to mean several things:

- a formatting function in formatting space which produces a file; and
  we think of this file as also an entity in formatting space;
- a formatting function in formatting space which produces a part of a
  file - an aspect; we call these helpers at present.
- all of the infrastructure around file generation such as
  boilerplate, etc - the formatters model.

The biggest problem is that this conceptual approach does not
distinguish between the formatter and the conceptual entity underlying
it.

Another way of looking at this is that we have the artefact space,
made up of all the entities that compose a project. An artefact maps
one to one to a file, but a file is a specific representation on a
filesystem, file server etc whereas the artefact is the conceptual
notion behind it. However, the content of the file and the content of
the artefact are byte-wise identical for a given (imaginary) artefact
id. One takes an artefact in memory and expresses it as a file.

Artefacts are instances of archetypes. An archetype of an artefact is
akin to a class of an object; it is its meta-type. Archetypes live in
archetype space, which is partitioned hierarchically by facet,
sub-kernel and kernel.

Archetypes are uniquely identified by their id. An example of an
archetype id is =quilt.cpp.types.class_header=, where =quilt= is the
kernel, =cpp= is the sub-kernel, =types= the facet and =class_header=
the archetype group. Configuration/annotations binds to archetype ids.

Formatting functions (i.e. formatters) take in a set of arguments and
generate artefacts. Formatters inherit the taxonomy of the archetype
of the artefacts they generate. The formatter id is the archetype id
plus the postfix =_formatter=. Formatters are also grouped like
archetypes: =class_header= etc, but they are also support additional
arbitrary grouping via labels (header files, cmakefiles, etc).

Modeling space is made up of entities. Entities abstract one or more
archetypes. One entity is represented by a set of element segments
with a cardinality of one or two. One of the elements is called the
master element and the other is called the extension element.

There is a stereotype called =formatter=. When a type is marked as
=formatter= the user must supply a stitch template in the filesystem
with a name of the class and the extension =.stitch=. The wale
templates are fixed. Wale templates must be part of dogen data. The
expected stitch sections must be present (include dependencies,
format).

=quilt.cpp= has a formatting mode which intercepts the stereotype and
then does additional processing such as if "non-generatable" only
generate if there is no file, if formatter do wale/stitch, etc.

Renames:

- file: artefact
- file formatter: artefact formatter
- ownership_hierarchy: archetype_location, model_name becomes kernel,
  facet name becomes facet and formatter name archetype. Add
  sub-kernel.
- Element concept becomes Entity.

*** COMPLETED Remove =original_model_name=                            :story:
    CLOSED: [2016-10-03 Mon 13:51]
    CLOCK: [2016-10-03 Mon 13:35]--[2016-10-03 Mon 13:51] =>  0:16

This does not seem to be used any longer.

*** COMPLETED Refactor code around model origination                  :story:
    CLOSED: [2016-10-03 Mon 15:30]
    CLOCK: [2016-10-03 Mon 15:24]--[2016-10-03 Mon 15:30] =>  0:06
    CLOCK: [2016-10-03 Mon 14:16]--[2016-10-03 Mon 15:23] =>  1:07
    CLOCK: [2016-10-03 Mon 13:56]--[2016-10-03 Mon 14:15] =>  0:19
    CLOCK: [2016-10-03 Mon 13:52]--[2016-10-03 Mon 13:56] =>  0:04
    CLOCK: [2016-10-03 Mon 13:24]--[2016-10-03 Mon 13:35] =>  0:11
    CLOCK: [2016-10-03 Mon 10:22]--[2016-10-03 Mon 12:43] =>  2:21

We have the following use cases around generation type and
origination:

- serialisation registrar needs to know which of the references are
  "real" (dogen; non-proxy) models and which are proxy models. We are
  only interested in calling the registrars for the "real" models.
- inclusion directives should only be generated for the target and
  non-proxy models.
- in a target model, we need to distinguish between elements for which
  the overwrite flag will be false (services; non-generatable) and
  those for which it will be true (all others).
- in a target model, we need to determine which formatters will be
  enabled for a given element. For services at present we just have
  types. All other types enable all formatters.
- we need to filter out all non-target elements before we code
  generate.

Tasks:

- add field for is proxy reference
- add new enum in origin types for not yet determined
- in yarn, read field; if set to proxy reference, update all model
  elements.
- update json code to stop reading origin types, remove it from json
  and add it as a field in meta-data. Alternatively, JSON has the
  flag, and field is specific to dia; frontend just sets the model
  origin and leaves the rest as undetermined; yarn pipeline sets it
  correctly.

*Previous Understanding*

- remove origin types and generation types, replacing it with just a
  boolean for is target. Actually we need something like:
  proxy_reference, non_proxy_reference, target. We also need a good
  name for this enumeration.
- add a model-level flag: is empty. It is true if there are no model
  elements. has_generatable_types is then is_target && !is_empty.
- at present we are using origin type to determine whether to create a
  registrar, etc in cpp model. There is no other use case for
  this. This is done in several places due to the bad handling of C++
  specific types. Grep for =references= in =cpp= to find all
  locations. We could split references into two (dogen, non-dogen). Or
  references could have a origin type too.
- we should also replace has generatable types with something more
  like "target model has types" or "is target model empty". The idea
  we are trying to capture is that the target model contained at least
  one type. This could be set by the merger when it processes the
  target model.

*Previous Understanding*

In the past we added a number of knobs around generation, all with
their own problems:

- =origin_types=: was the model/type created by the user or the
  system. in reality this means did the model come from Dia or
  JSON. this is confusing as the user can also add JSON files (their
  own model library) and in the future the user can use JSON
  exclusively without needed Dia at all.
- =generation_types=: if the model is target, all types are to be
  generated /unless/ they are not properly supported, in which case
  they are to be "partially" generated (as is the case with
  services). This is a formatter decision and yarn should not know
  anything about it. Actually this is not quite true; users may want
  to stop generation.

These can be replaced by a single enumeration that indicates if the
type/model is target or not.

This work should be integrated with the model types story.

Merged stories:

*Split references into dogen and non-dogen models*

If we had two containers of references, one for dogen models and
another one for non-dogen models - which we could give a nice name, to
imply its foreign origin - we could then use the dogen references for
registrar, etc. This is a replacement for the origin type.

We need a good name for these. Candidates:

- proxy model: represents something that exists in the outside
  world. e.g. =is_proxy=.

*Remove =service= stereotype*

This really just means non-generatable, or do not generate. We already
have a stereotype for this. Remove =service= and any other stereotype
which is not being used such as =value_object= etc.

Actually, non-generatable is not a stereotype really. We should
instead have some meta-data that can affect generation:

- do not generate: do nothing at all. For references only. If a file
  exists with this file name, it will be deleted as part of
  housekeeping.
- generate blank file if it doesn't exist: we don't even want a
  template.
- generate with content if it doesn't exist, do not touch otherwise:
  what we call services at the moment. Generate a "template" that then
  gets filled in manually.
- generate and merge: merge the contents of the generated file with
  the current contents in the file system. When we support merging.
- generate and overwrite: generate the file and overwrite whatever
  exists in the file system.

This could be called "generation policy".

The second behaviour we get for free with services is that we disable
all facets except for types. A few points:

- we may want to have io, serialisation, etc. This is not possible at
  present. If a state of a service is made up of supported types, we
  could even use existing code generation.
- in order for this to be implemented correctly we need to hook in to
  the enablement management somehow. In addition, it seems each facet
  can have its own generation policy. For example we may want to
  manually create types but automatically generate io.
- the best way to handle this may be to setup "enablement profiles"
  that the user can hook up to. For example we could have a "default"
  profile that enables all facets (or uses facet defaults), a second
  "service" profile that enables types with partial generation and io
  with full generation and so on. We probably also need "generation
  profiles" to go with "enablement profiles".

*Allow creating "system" models in Dia*

With the "proxy/non-proxy" models refactoring, we now have all the
bits in place to allow users to create "system" models from Dia (what
we now call proxy models). The only tasks missing are:

- add meta-data to dia subsystem to allow users to supply a "is proxy"
  flag.
- post-process model if is proxy flag is set, updating all types to
  proxy references.

Actually this is probably best handled in yarn, so that dia and json
have common logic. We should just add the fields and add the
processing in yarn somewhere.

*** COMPLETED Remove formatter level facet folders                    :story:
    CLOSED: [2016-10-03 Mon 16:02]
    CLOCK: [2016-10-03 Mon 16:03]--[2016-10-03 Mon 16:05] =>  0:02
    CLOCK: [2016-10-03 Mon 15:58]--[2016-10-03 Mon 16:02] =>  0:04

We seem to have two of these, but the real one is at the model level.

Merged stories:

*Move facet directory to a better place*

At present we have this property at the formatter configuration level,
but its not clear why we need to duplicate it. In fact, it may even
make more sense to have it at a higher level since its the same for
all elements.

*** COMPLETED Consider removing the "fake" primitive formatters       :story:
    CLOSED: [2016-10-03 Mon 20:38]
    CLOCK: [2016-10-03 Mon 20:37]--[2016-10-03 Mon 20:38] =>  0:01

It is actually not possible to remove these formatters without major
changes to the code. Instead, we introduce the notion of "pseudo"
formatters which do not actually format (they will throw if attempts
are made). Pseudo formatters make the conceptual model consistent and
work well with aliases.

*Previous Understanding*

We need to support a strange use case: where the formatter does not
exist for a given element type. For example, we do not have primitive
formatters, but there are directives set in them:

#+begin_src json-mode
        {
            "meta_type" : "primitive",
            "simple_name" : "uint64_t",
            "extensions" : {
                "quilt.cpp.helper.family" : "Number",
                "quilt.cpp.aspect.requires_manual_default_constructor" : true,
                "quilt.cpp.types.class_header_formatter.inclusion_directive" : "<cstdint>",
                "quilt.cpp.hash.class_header_formatter.inclusion_required" : false,
                "quilt.cpp.io.class_header_formatter.inclusion_required" : false,
                "quilt.cpp.test_data.class_header_formatter.inclusion_required" : false,
                "quilt.cpp.serialization.class_header_formatter.inclusion_required" : false,
                "quilt.cpp.odb.class_header_formatter.inclusion_required" : false
            }
        },
#+end_src

The problem with this is that if we do not have a formatter for
primitives, then we will not read the directives. In the past this
worked because we were processing the cross-product of formatters and
element sub-types, so the mistake of
=quilt.cpp.types.class_header_formatter.inclusion_directive= was
actually resulted in the correct result. But of course, we cannot
replace class_header_formatter with the correct formatter name (as we
don't have one). Nor does it sound good to have to hard-code the
formatter name against the type. One way to solve this is with
canonical formatters:

- use the canonical formatter name in the declaration
- ensure we always read directives for the canonical formatter from
  the meta-data.
- when processing, only set the canonical formatter if it was not
  already set by meta-data.

When testing the fix, we need to delete the mock formaters created for
primitives.

Actually this won't work. This is because we do not have a canonical
formatter for these types. What we need instead is to read and store
these fields by facet as well. This is a bit of a problem because we
are now saying that some times we want to resolve a facet name into a
canonical formatter, but some other times we want to resolve a facet
name directly into a inclusion directive. We could do as follows:

- first try as is;
- if failed, try resolving name using facet to canonical.

Basically, we need to extract enablement information from
formattables. This container is then augmented with facet
information. This is obtained in two ways:

- using facet directives directly, if available;
- mapping facet to canonical and using the canonical;

*** COMPLETED Expander refactor in =quilt.cpp=                        :story:
    CLOSED: [2016-10-04 Tue 10:29]
    CLOCK: [2016-10-04 Tue 10:30]--[2016-10-04 Tue 10:37] =>  0:07
    CLOCK: [2016-10-04 Tue 09:59]--[2016-10-04 Tue 10:29] =>  0:30
    CLOCK: [2016-10-04 Tue 09:42]--[2016-10-04 Tue 09:58] =>  0:16
    CLOCK: [2016-10-03 Mon 22:30]--[2016-10-03 Mon 23:06] =>  0:36
    CLOCK: [2016-10-03 Mon 20:59]--[2016-10-03 Mon 22:29] =>  1:30
    CLOCK: [2016-10-03 Mon 20:53]--[2016-10-03 Mon 20:57] =>  0:04

We found some fundamental impedance mismatches whilst handling
enablement, which mean we need to change the expanders once again.

Tasks:

- change model to map of formattable.
- add facet configuration with enabled and directory.
- make the expanders "model expanders" rather than formattable
  expanders.
- update the file path expander to also compute the facet directories;
  for this we need to supply the path annotations. Actually we should
  just add another expander (facet_directory_expander?).
- update the enablement expander to also compute: a) facet enabelment
  b) enablement by id.
- update assistant with a "is facet xxx enabled".
- add a "facet dependencies" to formatter interface. Add a "enabled
  facet dependencies" to formatter configuration. During enablement,
  check to see if the facet dependency is enabled and if so, add it to
  the container. During formatting, assistant supplies a "is facet
  dependency enabled" method that queries the container. This is used
  for odb in cmakelists.

Merged stories:

*Add facet configuration to element configuration*

At present we need:

- facet folder
- enabled

We need to also add a "is facet enabled" method in assistant.

*** COMPLETED Create the notion of a formatter alias                  :story:
    CLOSED: [2016-10-04 Tue 13:14]
    CLOCK: [2016-10-04 Tue 12:05]--[2016-10-04 Tue 13:14] =>  1:09
    CLOCK: [2016-10-04 Tue 10:51]--[2016-10-04 Tue 12:04] =>  1:13
    CLOCK: [2016-10-04 Tue 10:37]--[2016-10-04 Tue 10:50] =>  0:13
    CLOCK: [2016-10-03 Mon 20:39]--[2016-10-03 Mon 20:51] =>  0:12
    CLOCK: [2016-10-03 Mon 20:09]--[2016-10-03 Mon 20:37] =>  0:28

Tasks:

- add a new trait for canonical formatters: facet + ".canonical";
- create a map of canonical formatter to actual formatter during model
  generation. Supply the map to the inclusion expander and from there
  to the inclusion builder.
- before we build the includes, first resolve it against the map; if
  it resolves, use the formatter name from resolution, if not use the
  original.
- map is copied across to model and from model into context.
- when formatting registrar, for each leaf ask if the formatter is
  enabled. Supply the id of the leaf and the serialisation facet; use
  the map to resolve the facet to a formatter name. If the id is not
  enabled, do not add it to registrar.
- in assistant, replace "is serialisation enabled" etc with calls to
  the canonical formatter instead. Remove those that are not in
  use. Make the name reflect the fact that we are looking at the
  canonical formatter.

*Previous Understanding*

We did a bit of a hack with mapping the facet to the default
formatter. What we really need is the notion of an alias. It still
looks like a formatter name (for example "header_formatter") but it
must be first resolved into an actual formatter. For this we need a
type index.

Other names:

- canonical formatter
- reference formatter

*** COMPLETED Remove enabled formatters from formatter configuration  :story:
    CLOSED: [2016-10-04 Tue 17:56]
    CLOCK: [2016-10-04 Tue 13:50]--[2016-10-04 Tue 14:12] =>  0:22

We left some remnants of the legacy approach. Remove and tidy-up
around this area.

*** COMPLETED Handle registration of services properly                :story:
    CLOSED: [2016-10-04 Tue 18:55]
    CLOCK: [2016-10-04 Tue 18:53]--[2016-10-04 Tue 18:55] =>  0:01
    CLOCK: [2016-10-04 Tue 18:13]--[2016-10-04 Tue 18:52] =>  0:39
    CLOCK: [2016-10-04 Tue 17:50]--[2016-10-04 Tue 18:12] =>  0:22
    CLOCK: [2016-10-04 Tue 14:21]--[2016-10-04 Tue 14:41] =>  0:20
    CLOCK: [2016-10-04 Tue 13:15]--[2016-10-04 Tue 13:20] =>  0:05
    CLOCK: [2016-10-03 Mon 20:01]--[2016-10-03 Mon 20:08] =>  0:07
    CLOCK: [2016-10-03 Mon 17:55]--[2016-10-03 Mon 19:02] =>  1:07
    CLOCK: [2016-10-03 Mon 16:07]--[2016-10-03 Mon 16:39] =>  0:32
    CLOCK: [2016-10-03 Mon 15:44]--[2016-10-03 Mon 15:58] =>  0:14
    CLOCK: [2016-10-03 Mon 15:31]--[2016-10-03 Mon 15:44] =>  0:13

The only way to do this is to filter the list of leaves by enabled
formatters. We need a container of enabled formatters by element id at
the formattable model level.

Problems:

- we need to be able to cope with lookups by facet id, e.g. is odb
  facet enabled? I don't necessarily have a qname or if I do, it may
  not have all of the formatters required (e.g. cmakelists).
- we need to be able to cope with lookups by canonical formatter name,
  e.g. I have included name x in types but I don't know what formatter
  it corresponds to.

Both of these problems have been addressed on their own stories. We
can now tackle leaves.

Tasks:

- change context to have the entire formattables model; setup the
  resolver and use it in is formatter name enabled.
- use the resolver to check if each leaf is enabled for serialisation
  using the canonical formatter. This can be a helper method in
  assistant.

*Previous Understanding*

We need a flag to determine if a class should contribute its leaves or
not. By default, if it is hand-crafted it does not contribute
leaves. This could (eventually) be overridable by users.

*Previous Understanding*

We need a way to determine if a type which is part of a generalisation
should be added to the registrar or not. In =generalisation_indexer=:

:     // FIXME: massive hack. must not add leafs for services.

One way would be to check if serialisation is enabled for that type
and if not, skip the type.

Another way is to check if the type is generatable. If not, skip
it. If we do it this way we need to wait for the generatable clean up.

*** CANCELLED Supply formatter's container to injector                :story:
    CLOSED: [2016-10-04 Tue 19:11]

*Rationale*: this would involve having to remove the utility method
for registration. In this particular case we'll keep the lack of
transparency.

At present the injector is calling the formatters' workflow
directly, in order to obtain the formatters' container. It should
receive it as a parameter during initialisation.

*** COMPLETED Introduce the concept of proxy models                   :story:
    CLOSED: [2016-10-04 Tue 19:12]

*Rationale*: this was completed as part of the origin types refactor.

These are models that exist solely to bring types in, but do not
define those types. Typically one uses a proxy model to expose
non-dogen types into dogen. We could add a flag to models
=is_proxy=. It would replace the notion of system models. We need to
check the stories in the backlog around this.

Interestingly we could have different defaults for formatters in proxy
models. For example, if a model is proxy we can assume that we should
not compute inclusion paths. This could save a lot of time when
specifying the models in JSON.

*** COMPLETED Add more validation to formatter registration           :story:
    CLOSED: [2016-10-04 Tue 19:12]

*Rationale*: this was completed as part of the leaves tidy-up.

We should check to ensure that only one formatter per facet is
declared the canonical formatter.

*** COMPLETED Check which properties need to loop through the entire model :story:
    CLOSED: [2016-10-04 Tue 19:14]

*Rationale*: the expander rewrite took care of this; all expanders are
now filtering as required.

In certain cases such as helpers we probably don't need to go through
all types; only the target types matter. Ensure we are not processing
other types for no reason.

Merged stories:

*Element properties includes non-target types*

We seem to be generating a lot of element properties and formatter
properties as well. We should only be generating these for the target
model.

*** COMPLETED Check generation type before dispatching element        :story:
    CLOSED: [2016-10-04 Tue 19:15]

*Rationale*: This was addressed with the expanders refactor.

At present we are doing this check in =visit=:

:     if (o.generation_type() == yarn::generation_types::no_generation)
:        return;

If we did it before the =visit= call we'd save the cost of
dispatching.

*** COMPLETED Move stereotypes to element                             :story:
    CLOSED: [2016-10-05 Wed 21:46]
    CLOCK: [2016-10-05 Wed 21:25]--[2016-10-05 Wed 21:46] =>  0:21

We need to have the ability to add stereotypes to any element.

*** STARTED Add support for profiles                                  :story:
    CLOCK: [2016-10-05 Wed 21:47]--[2016-10-05 Wed 22:14] =>  0:27
    CLOCK: [2016-10-05 Wed 21:04]--[2016-10-05 Wed 21:24] =>  0:20
    CLOCK: [2016-10-05 Wed 20:46]--[2016-10-05 Wed 21:03] =>  0:17
    CLOCK: [2016-10-05 Wed 15:22]--[2016-10-05 Wed 18:14] =>  2:52
    CLOCK: [2016-10-05 Wed 14:53]--[2016-10-05 Wed 15:21] =>  0:28
    CLOCK: [2016-10-05 Wed 13:01]--[2016-10-05 Wed 14:52] =>  1:51
    CLOCK: [2016-10-05 Wed 11:40]--[2016-10-05 Wed 12:15] =>  0:35
    CLOCK: [2016-10-05 Wed 11:17]--[2016-10-05 Wed 11:28] =>  0:11
    CLOCK: [2016-10-05 Wed 10:10]--[2016-10-05 Wed 11:16] =>  1:06
    CLOCK: [2016-10-05 Wed 09:26]--[2016-10-05 Wed 10:09] =>  0:43

At present we have to manually add a lot of configuration to each
model. In truth, most of the configuration is the same for a group of
models. It would be great to provide canned configurations that users
can reuse (or add their own) and then refer to in the model.

- add overwrite on all facet/formatter profiles.

Tasks:

- add data files to specify profiles, with classes to read them in
  from JSON. Profiles must be settable to global or local.
- add meta-data to allow users to supply a profile (local or global).
- update enablement expander to look for profiles.
- update all facet test models to use profiles.

*** STARTED Link profiles to stereotypes                              :story:

Once we have profiles, we need to have a way to link them to
stereotypes. At present we only have two use cases:

- hand-crafted
- formatter

When we spot one of these, we should then automatically look for a
profile with this name. If found apply it locally.

*Previous Understanding*

An element can be marked with the stereotype of handcrafted. We then
have several things to determine for this element:

- which formatters are disabled due to handcraft mode (e.g. all facets
  other than types);
- which formatters are enabled, but should only generate if there
  isn't a file already in the file system (e.g. class header and class
  implementation in types)
- which formatters are enabled and should generate as usual
  (e.g. forward declarations in types).

We must also allow users to override these settings so that:

- they can disable the types facet if required;
- they can provide their own implementations for other facets;
- they can ask the code generator to generate one for them
  (serialisation, io).

Finally, for the common case, we do not want users to have to set lots
of meta-data; we need a sensible default behaviour.

Actually, from a purely functional perspective, what is handcrafting?
It is a shorthand for:

- disable a set of formatters;
- enable another set of formatters;
- for a subset of the enabled formatters, generate only if there is no
  file in the filesystem, otherwise do nothing;
- for another subset of the enabled formatters, generate as usual.
- do not add leaves to the registrar (unless asked to).

One can conceive the notion of an enablement profile. These can be
global or local. We can also have overwritting profiles. These can
only be local. A sub-set of the enabled formatters can be set to
overwrite=false. Examples:

- default enablement profile: "enable all". Enables all facets and
  formatters.
- types and a facet profiles: "types and serialisation", "types and
  io" etc.
- "types class only": generates class header and implementation.
- default overwrite profile: "overwrite all". Overwrites all
  artefacts.

Now handcrafting becomes much easier:

- add meta-data to quilt: a) a way of specifying profiles for
  overwriting and enabling b) a way of specifying if leaves contribute
  to registration or not.
- define a set of profiles in data for overwriting and enabling. Users
  can provide their own profile directories.
- Link the overwriting and enabling with stereotypes: given a
  stereotype, we could map to a default profile. Actually this is more
  of a profile group. We could then state that a stereotype maps to a
  profile group.

Note: we don't need to do leaf management:

#+begin_quote
- add a flag for leaf management. It defaults to true, unless
  handcrafted. Add meta-data to allow overriding flag (or create story
  for it as we don't yet have a use case).
#+end_quote

We just need to enable/disable serialisation and the code will work.

- add a stereotype of handcrafted with a default profile.

*** STARTED Generate formatter interfaces                              :epic:
    CLOCK: [2016-10-04 Tue 18:56]--[2016-10-04 Tue 19:05] =>  0:09
    CLOCK: [2016-09-30 Fri 10:58]--[2016-09-30 Fri 11:17] =>  0:19

We should create another template language, in addition to stitch:
"wale". Wale is a very simple language that has templates that just do
token replacement. The tokens must have a special format:
={{{TOKEN}}}=. We receive a map of keys to values and do a blind
replacement to the keys on the wale document.

This links to stitch as follows:

- create a single file implementation of a formatter. It will
  implement both the provider interface and the appropriate formatter
  interface. It will call the stitch method to start off with. There
  are no headers, just cpp. It does the formatter registration.
- add support in stitch for "named sections": its possible to start a
  section and assign it a name. A stitch template will have two
  sections: inclusion provision and formatting.
- add support in stitch for "wale variables". These are just kvp's
  defined at the top:

: <#@ wale.variable="formatter_name=abcd" #>

  wale variables and sections are converted into a kvp container for
  wale input. Examples: facet, formatter name, etc.
- convert the formatter code into a wale template, adding wale
  variables as required.
- update stitch to detect wale usage and to call wale in those
  cases. This could be done by supplying a wale template:

: <#@ wale.template="abcd.wale" #>

- note that wale could be useful outside of stitch, for example for
  dart: we could wale-lise utility and then instantiate it for a given
  project.

*Previous Understanding*

It should be possible to generate some trivial types such as formatter
interfaces, formatter container, registrar and so on. For this we
need:

- a mustache type template;
- a set of fields from yarn types to be exposed to mustache;
- a list of types to iterate through.

Once we got this we could instantiate the templates. To integrate this
with knit we would need some way of specifying which types the
iteration would be over. We could mark a specific type with a given
stereotype, and then supply say the base class ("all leaf descendants
of xyz"). Dogen would then locate the descendants and for each call
the template.

For registrar and container its a bit trickier because we want a
collection of types in one go.

We also need a way to keep these templates away from the main (user
visible) code, since they are useful only for dogen.

See also [[https://github.com/cierelabs/boostache/tree/develop][boostache]].

Notes:

- we will need some "special" tags for copyright, includes
  etc. Includes will be particularly special because we need to
  augment the include list with additional includes. However, we may
  not even need to be aware of this.

*Stitch meta-templates*

*Note*: re-read story [[https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_64.org#code-generating-formatters-as-text-templates][Code-generating formatters as text templates]] as
some of these ideas were already there. Also: see [[https://github.com/no1msd/mstch][mstch]].

In the quest for defining a single stitch template which then becomes
a formatter - without any additional infrastructure required at all -
we hit on an idea: stitch meta-templates. Basically we would have two
different kinds of inputs to stitch: the template itself and the
meta-template. Meta-template is a provisional name. The meta-template
would define the formatter layout:

- class definition, using a stitch variable for the yarn element type
- registration of the formatter
- definition of a method for the includes
- definition of a method for the stitching

These last two would result in the creation of "regions". These
regions must then be "instantiated" in the template. This could easily
be achieved with some kind of new element:

: <#% region "includes">

Or some such stitch construct. All lines after this line are part of
the region "includes" until a new region is defined. The region is
stitched and then transposed to the place in the meta-template where
it was defined, for example:

: int f(int a, int b) {
: <#% region "includes">
: }

Would result in copying across the region into these brackets. This
will make defining multiple functions very easy, without having to
supply command line arguments, etc.

Notes:

- meta-templates are supplied as command line arguments.
- potential extension: =meta.stitch=
- stitch should still work on non-meta-template mode.
- some of these ideas had already been covered on another story but
  can't find it in backlog. It could be part of the original stitch
  epic. We need to revisit it to see if it contains additional
  insights.
- when an error occurs, it would be great if we could pin point the
  error to the template or to the meta-template. This is more of a
  concern when we add clang compilation support.

Further thoughts:

- there are two approaches for this: we could integrate stitch tighter
  with knit and have it return "chunks" of processed code instead of
  files. As per story "Integration of stitch and dogen", dogen would
  then be responsible for writing the header file as per methods
  defined in the class diagram. Each method would be marked as a
  region. Meta-data in the class associates a template with the
  class. Knitter uses stitch to convert the template into regions, and
  then takes these regions and inserts them into a generated
  file. This approach is very clever and requires a lot of machinery.
- the easier approach uses meta-templates. Class diagram associates
  both meta-template and template with class via meta-data. We could
  possibly also have a stitch stereotype to make it clearer. Yarn has
  a stitch class with attributes of these parameters. Dogen
  instantiates stitch (probably within quilt) with the parameters and
  generates the file. Actually we probably can't have this in quilt
  because we still need formatter properties.

*** Push stereotypes processing into yarn                             :story:

At present we have stereotypes as an enum, and the frontends are
responsible for resolving the stereotypes. This is not ideal:

- we assume unknown stereotypes are concepts;
- we map visitable to a flag to map it to a stereotype;
- we map fluent to a flag;
- we had to hack in the profile stereotype binding;
- the same work will have to be done in other frontends (e.g. JSON).

The right thing is:

- make stereotypes a string container;
- frontend simply populates the container and does not judgements;
- *all* stereotypes are put in the container; rule of thumb is, if its
  a UML stereotype then it must go in the container;
- stereotypes expander figures out if the stereotype is one that is
  actionable within yarn (visitor, modeled concepts) or one to
  pass-through (binding stereotypes.

*** Merge annotations with formattables                               :story:

Originally we split annotations from formattables because we thought
they had enough responsibilities to stand on their own as
classes. However, its now clear that the only job of the annotations
is to provide data for one expander. It makes a lot more sense to have
it all in one class.

Tasks:

- merge path annotations with model expander
- create separate annotations for facet directory expander
- merge streaming annotations and helper annotations with helper
  expander
- merge inclusion directive annotations with inclusion expander and
  possibly get rid of factory
- merge aspect annotations with aspect expander
- merge opaque annotations with opaque annotations expander and move
  all other opaque classes into formattables
- delete annotations namespace.

*** Remove object types in yarn                                       :story:

We need to figure out if this enumeration is still in use and if not
what needs to be done to remove it.

*** Order of headers is hard-coded                                    :story:

In inclusion expander, we have hacked the sorting:

:        // FIXME: hacks for headers that must be last
:        const bool lhs_is_gregorian(
:            lhs.find_first_of(boost_serialization_gregorian) != npos);
:        const bool rhs_is_gregorian(
:            rhs.find_first_of(boost_serialization_gregorian) != npos);
:        if (lhs_is_gregorian && !rhs_is_gregorian)
:            return true;

This could be handled via meta-data, supplying some kind of flag (sort last?).

*** Perform the archetype / artefact renames                          :story:

As per analysis story, we need to tidy-up terminology.

Renames:

- file: artefact
- file formatter: artefact formatter
- ownership_hierarchy: archetype_location, model_name becomes kernel,
  facet name becomes facet and formatter name archetype. Add
  sub-kernel.
- Element concept becomes Entity.

*** Refactor ownership hierarchy                                      :story:

Start implementing the archetype logic. Basically there is a artefact
unique identifier

- rename it to =artefact_descriptor=.
- remove all dia fields; these are now file importer specific and
  never reach dynamic.
- add =kernel= field. This is set to =stitch= or =quilt=.
- rename formatter field to =kind=

Merged stories:

*Consider adding "application" to ownership hierarchy*

Not all fields make sense to all tools in the dogen suite; some are
knit specific, some are stitch specific and some are shared. At
present this is not a problem because stitch loads up all of knit's
fields and assumes users won't make use of them. If they do, nothing
bad "should" happen. But a better way to solve this may be to only
load fields that belong to an application. We could add "application"
to ownership hierarchy, and filter on that. Note though that we would
need some way of saying "all applications" (e.g. at present, leave the
field blank).

*Consider renaming =ownership_hierarchy=*

We came up with the name =ownership_hierarchy= because we could not
think of anything else. However, it is not a particularly good name,
and it is increasingly so now that we need to use it across models. We
need a better name for this value type.

This work must be integrated with the [[https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_69.org#thoughts-on-cpp-refactoring][archetype work]].

*Split knitting from stitching settings*

*Rationale*: with "kernel" we will have quilt and stitch.

At present we only have a single common directory with all of the
available fields. Not all fields apply to both stitching and
knitting - but some do. We need a way to filter these. One possibility
is to use an approach similar to the formatter groups in the ownership
hierarchy. For now we simply have fields that have no meaning in
stitching but can be supplied by users.

*** Implement qualified name efficiently                              :story:

We should move qualified names to quilt. We can create a simple map of
id to qualified name and add that to the formattables model.

*Previous Understanding*

We used a =std::map= to store qualified names. In practice, we don't
need something this expensive.

- instead of mapping names to languages, we could map them to
  "styles". There are only a few "styles" across all programming
  languages (e.g. =.= separated, =::= separated and so on).
- we can also create an array of these styles. We know up front how
  many styles there are.
- finally we can create a enumeration to access the array. At present
  this is not possible because we cannot disable invalid, nor is it
  possible to move it to a different position (e.g. last). Also we
  will have to static cast the enum to access the int, which is not
  very pretty.

Once all of this is done we can simply do, at O(1):

: name.qualified[static_cast<unsigned int>(styles::double_colon_separated_style)]

We can prettify it a bit: [[http://stackoverflow.com/questions/8357240/how-to-automatically-convert-strongly-typed-enum-into-int][How to automatically convert strongly typed
enum into int?]]

: template <typename E>
: constexpr typename std::underlying_type<E>::type to_underlying(E e) {
:     return static_cast<typename std::underlying_type<E>::type>(e);
: }
:
: std::cout << foo(to_underlying(b::B2)) << std::endl;

Giving us:

: name.qualified[to_underlying(styles::double_colon_separated_style)]

*** Integration of stitch and dogen                                   :story:

Now that we have implemented stitch and proved it works (more or
less), we need to think how we can make using stitch from dogen
easier. At present there is not integration at all:

- users need to create regexes to ensure dogen does not trample on
  stitch files:

:    --ignore-files-matching-regex .*stitch
:    --ignore-files-matching-regex .*_stitch.hpp
:    --ignore-files-matching-regex .*_stitch.cpp

- users need to manually create a header file for each stitch
  template.
- users need to create stitch targets and run them to ensure the
  templates have been expanded. This means its possible to get dogen
  and stitch out of sync (but for now not a big problem).

In the ideal world, when we knit a model it would be nice if it could
also stitch as required. This could be achieved as follows:

- Create a meta-data tag that tells dogen a type has an associated
  stitch template with it.
- Create =cpp= types that represent the stitch header and
  implementation.
- Transformer needs to look for the meta-data tag and instantiate the
  =cpp= types.
- Create a =cpp= formatter for the header, as per regular
  formatters. The slight challenge here is that the formatter needs to
  be instantiable across facets, which we do not support at the
  moment.
- Create a cpp formatter for the implementation which instantiates
  stitch with the template and uses it to create a file. Same
  challenge as with the header.

*Previous Understanding*

- stitch can still be integrated with dogen. We could use meta-data to
  link a formatter (well, any class that needs stitch really, but at
  present just a formatter) with a stitch template. For example, a
  =class_header_formatter= could have a "is stitchable" flag set to
  on. This would then mean that dogen would look for a
  =class_header_formatter.stitch= file in the same directory as the
  CPP file. It would then use that to create a
  =class_header_formatter_stitch.cpp= file. It would also
  ignore/generate a =class_header_formatter_stitch.hpp= file and
  automatically add it to the inclusion dependencies of
  =class_header_formatter.cpp=. These are injected into stitch as we
  instantiate the template since stitch supports meta-data (we do need
  a way to inject the meta-data from dogen into the meta-data in the
  template; perhaps a kvp container passed in to the stitch workflow
  which could then be handed over to the parser). All these files are
  automatically added to the list of "exceptions" for housekeeping so
  that they do not get deleted. However, stitch would not know
  anything at all about any of this; this is all knitter's
  functionality. The problem is at present we haven't got a good place
  to perform the stitching as part of knitter's workflows. Perhaps as
  part of the expansion, we could set a number of stitch fields which
  would then be picked up by some knit-specific workflow classes.

*** Consider adding =fileset= to formatters' model                    :story:

We are using collections of files quite a bit, and it makes sense to
create an abstraction for it such as a =fileset=. However, for this to
work properly we need to add at least one basic behaviours: the
ability to merge two file sets. Or else we will end up having to
unpack the files, then merging them, then creating a new fileset.

Problem is, we either create the fileset as a non-generatable type -
not ideal - or we create it as generatable and need to add this as a
free function. We need to wait until dogen has support for merging
code generation.

*** Consider supplying element configuration as a parameter           :story:

Figure out if element configuration is context or if it is better
expressed as a stand alone formatting parameter.

*** Formatter repository should be created in quilt                   :story:

At present we are creating the formatter repository in
=quilt.cpp=. However it will be shared by all backends in the
kernel. Move it up to =quilt= level and supply it as a paramter to the backends.

*** Tidy-up of inclusion terminology                                  :story:

Random notes:

- imports and exports
- some types support both (headers)
- some support imports only (cpp)
- some support neither (cmakelists, etc).

*** Initialise formatters in the formatter's translation unit         :story:

At present we are initialising the formatters in each of the facet
initialisers. However, it makes more sense to initialise them on the
translation unit for each formatter. This will also make life easier
when we move to a mustache world where there may not be a formatter
header file at all.

*** Refactor path annotations factory                                 :story:

As part of this work we should also look at how the facet directory
expander is computing the facet directory; we are going through all
formatters. We could just read the facet information.

Tasks:

- get distinct list of facets across all formatters and generate field
  definitions from this list;
- cache top-level fields and facet fields and copy results instead of
  re-reading them.

*** Move odb options file into odb folder                             :story:

There is not particularly good reason for this file to exist at the
src level.

In order to implement this story we need to have a working odb setup
to test it and ensure we didn't break anything.

** Deprecated
*** CANCELLED Consider caching "all modules" in location              :story:
    CLOSED: [2016-10-02 Sun 20:39]

*Rationale*: we don't have enough use cases to justify the
cost. Instead we created the name flattener in yarn.

At present we are adding the module lists together to build the
qualified name; location could have a "all modules" list that
concatenates external, model and internal modules. We should look at
performance before doing this change though.

We are also using this information in =quilt.cpp= via the name builder
(this is the only reason it cannot be removed). Adding it to the
name/location is a bit painful since we use it in a lot of places, but
we have other options:

- create a service to do the merging and do it on the fly
- add a method to nameable with the flat module list.

Merged stories:

*Add "namespaces" to name*

Name should have a flat class with all namespaces in yarn, instead of
generating it on every formatter.
*** CANCELLED Consider reducing the number of qname lookups in cpp model :story:
    CLOSED: [2016-10-02 Sun 20:40]

*Rationale*: The refactoring of quilt reduced the look-ups.

At present we are still using =yarn::name= in a lot of repositories in
quilt. We already had one go in moving to id's but there are still
quite a few left. Investigate to see if there are more that can be
moved.

*** CANCELLED Group the file related fields under a prefix            :story:
    CLOSED: [2016-10-02 Sun 20:42]

*Rationale*: this does not line up with the new understanding of the
conceptual model.

Now we have =element= as a prefix, it probably makes sense to also
group the fields that are related to file names, paths etc. These
could be under =file= or perhaps =paths=? Examples:

- =quilt.cpp.file.include_directory_name=
- =quilt.cpp.source_directory_name=

*** CANCELLED Element formatter should have a container api           :story:
    CLOSED: [2016-10-02 Sun 20:45]

*Rationale*: Not applicable after the =quilt.cpp= refactor.

In general, where the client is performing a loop over a well known
container and then calling a method, we should add an API for that
well known container. This is the case with the element formatter.

This also reduces the number of splices done by the calling code. All
the logging should be done in the element formatter as well.

*** CANCELLED Perform an in-depth product backlog groom                :epic:
    CLOSED: [2016-10-02 Sun 21:04]

*Rationale*: we've added the tags; the process is continuous so the
story does not add any value.

We now have lots of references to types (and models) that have been
refactored away - either renamed or deleted altogether. As we are
reaching the final form for =yarn= and =quilt=, we need to go
through all the stories and update them to the new world.

- add two todos to the backlog: not reviewed, reviewed
  (=<REVIEWING>=). Actually, added org mode tag support for this to
  make it more obvious and filterable.
- mark all stores as not reviewed
- go through all the stories and mark them suitably as we review them.

*** CANCELLED Create a set of definitions for tagging and meta-data   :story:
    CLOSED: [2016-10-02 Sun 21:12]

*Rationale*: This is part of the conceptual model work.

We still use these terms frequently. We should define them in dynamic
to have specific meanings.
*** CANCELLED Handling of managed directories is incorrect            :story:
    CLOSED: [2016-10-02 Sun 21:14]

*Rationale*: its not clear this is a problem at present.

At present we are querying the yarn dia importer to figure out what
the managed directories are. These are basically the top-level
directories from where we want the housekeeper to operate. In reality
this is (or can be placed) in the meta-data. We should be able to
extract the managed directories from the meta-data as a step in one of
the workflows.

This can be done by the backend. It does mean that we should be
returning a composite type from generation:

- list of files;
- list of managed directories.

Alternatively we could have a =managed_directories= method that takes
in an yarn model and then internally reads in the meta-data for a given
model to produce the list.

*Merged with previous story*

Compute managed directories from knitting options

At present the backend is returning empty managed directories. This
means housekeeping will fail in the new world. We need to change the
interface of this method to take in the knitting options and return
the managed directories.

This is not entirely trivial. At present the managed directories are
computed in the locator. It takes into account split project, etc to
come up with all the directories used by the backend. We need to make
these decisions during path expansion, expect we only need manged
directories for the root object. However we do not know which object
is the root object at present, during the expansion. We could identify
it via the QName and the yarn model in context thought. We could then
populate the managed directories as a text collection. We then need
some settings and a factory to pull out the managed directories from
the root object. This could be done in =managed_directories=, by
having an yarn model as input.

*** CANCELLED Header guard in formatters should be optional           :story:
    CLOSED: [2016-10-02 Sun 21:15]

*Rationale*: new approach is to use =empty()= where available.

At present we are relying on empty header guards to determine what to
do in boilerplate. We should use boost optional.

*** CANCELLED Add kvp support to =identifier_parser=                  :story:
    CLOSED: [2016-10-02 Sun 21:24]

*Rationale*: This is only done in yarn.dia these days.

We have code to split kvps all over the place. We should do this in a
single pace, and use boost spirit or tokenizer. For one such
implementation with spirit see:

[[http://boost-spirit.com/home/2010/02/24/parsing-skippers-and-skipping-parsers/][Parsing Skippers and Skipping Parsers]]
*** CANCELLED Create =src= and =include= facets                       :story:
    CLOSED: [2016-10-02 Sun 21:36]

*Rationale*: according to the new conceptual model, these are not
facets; the formatter is just selecting a different physical location
for the artefact.

At present we have some formatters that are not in the traditional
facets such as =types=, etc. We should make facets for them. We need
to check what the current facet name is. There should only be one case
of this, the CMakeLists formatters.
*** CANCELLED Move enabled formatters to element configuration        :story:
    CLOSED: [2016-10-04 Tue 19:08]

*Rationale*: this is now handled correctly.

All elements have the same view of enabled formatters.

*** CANCELLED Move enabled formatters to a higher level               :story:
    CLOSED: [2016-10-04 Tue 19:09]

*Rationale*: this is now handled correctly.

At present we have =enabled_formatters= at the formatter level. This
should be at the element level. It can't be model level because
eventually we will have different enablement configurations for each
formatter.
