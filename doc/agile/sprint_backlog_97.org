#+title: Sprint Backlog 97
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- Finish C# support;
- Finish Upsilon support.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2017-02-02 Thu 18:13]
| <75>                                                                        |         |       |       |       |
| Headline                                                                    | Time    |       |       |     % |
|-----------------------------------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                                                | *33:57* |       |       | 100.0 |
|-----------------------------------------------------------------------------+---------+-------+-------+-------|
| Stories                                                                     | 33:57   |       |       | 100.0 |
| Active                                                                      |         | 33:57 |       | 100.0 |
| STARTED Sprint and product backlog grooming                                 |         |       |  0:01 |   0.0 |
| COMPLETED Edit release notes for previous sprint                            |         |       |  0:43 |   2.1 |
| COMPLETED Add support for configurable enumerations types                   |         |       |  4:10 |  12.3 |
| COMPLETED Allow disabling =invalid= value in enumerations                   |         |       |  0:12 |   0.6 |
| COMPLETED Add support for configurable enumeration values                   |         |       |  5:26 |  16.0 |
| COMPLETED Test data for booleans is not oscillating correctly               |         |       |  1:15 |   3.7 |
| STARTED Inclusion directive logic is too complex                            |         |       |  1:17 |   3.8 |
| STARTED Handle "special includes" generically                               |         |       |  8:38 |  25.4 |
| STARTED Add support for primitives across the pipeline                      |         |       | 12:15 |  36.1 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2017-01-30 Mon 09:22]--[2017-01-30 Mon 09:23] =>  0:01

Updates to sprint and product backlog.

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2017-01-30 Mon 09:44]
    CLOCK: [2017-01-30 Mon 20:45]--[2017-01-30 Mon 21:08] =>  0:23
    CLOCK: [2017-01-30 Mon 09:24]--[2017-01-30 Mon 09:44] =>  0:20

Add github release notes for previous sprint.

Title: Dogen v0.96.0, "Praia das Miragens"

#+begin_src markdown
![alt text](http://static.panoramio.com/photos/large/820003.jpg)
Praia das Miragens, Namibe, Angola. (C) Ivo Cardoso, 2007. Sourced from Panoramio.

Overview
=======
The main theme of the sprint was infrastructural work to enable multi-language support in yarn. This was done mainly for the customer-specific upsilon model but it will be reused in a more general form to provide support for Language Agnostic Models.

The only other area of interest in this sprint was the start of the work on "primitives". What was previously called "primitives" are now "built-ins", to best reflect their nature; a new meta-model concept of primitive was introduced. The idea is that users can create their own primitive types. Work on this has only started and the next sprint will provide clarity around the implementation.

User visible changes
===============
In this sprint, a small number of user visible changes were made:

- **Log level is now settable**: Command line utilities no longer use the deprecated ```verbose``` parameter. Instead, ```log_level``` was introduced. It maps to the existing levels of logging in Dogen.
- **JSON format was tidied up**: A few inconsistencies around naming of attributes in JSON were resolved. Please look at the [example models](https://github.com/DomainDrivenConsulting/dogen/tree/master/test_data/yarn.json/input) if you need to update your own models.

For more details of the work carried out this sprint, see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_96.org).

Next Sprint
========
The next sprint will continue to focus on Upsilon and C#.

Binaries
======
You can download experimental binaries from [Bintray](https://bintray.com/domaindrivenconsulting/Dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_0.96.0_amd64-applications.deb](https://dl.bintray.com/domaindrivenconsulting/Dogen/0.96.0/dogen_0.96.0_amd64-applications.deb)
- [dogen-0.96.0-Darwin-x86_64.dmg](https://dl.bintray.com/domaindrivenconsulting/Dogen/0.96.0/dogen-0.96.0-Darwin-x86_64.dmg)
- [dogen-0.96.0-Windows-AMD64.msi](https://dl.bintray.com/domaindrivenconsulting/Dogen/dogen-0.96.0-Windows-AMD64.msi)

**Note**: They are produced by CI so they may not yet be ready.

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/820962437465866241][Tweet]]

*** COMPLETED Add support for configurable enumerations types         :story:
    CLOSED: [2017-01-30 Mon 14:30]
    CLOCK: [2017-01-30 Mon 14:30]--[2017-01-30 Mon 14:39] =>  0:09
    CLOCK: [2017-01-30 Mon 14:10]--[2017-01-30 Mon 14:29] =>  0:19
    CLOCK: [2017-01-30 Mon 13:38]--[2017-01-30 Mon 14:09] =>  0:31
    CLOCK: [2017-01-30 Mon 13:16]--[2017-01-30 Mon 13:37] =>  0:21
    CLOCK: [2017-01-30 Mon 12:39]--[2017-01-30 Mon 13:15] =>  0:36
    CLOCK: [2017-01-30 Mon 11:28]--[2017-01-30 Mon 12:01] =>  0:33
    CLOCK: [2017-01-30 Mon 10:49]--[2017-01-30 Mon 11:27] =>  0:38
    CLOCK: [2017-01-30 Mon 09:45]--[2017-01-30 Mon 10:48] =>  1:03

#+begin_quote
*Story*: As a dogen user, I need to configure the built-in type of my
enumerations so that I model my domain accurately.
#+end_quote

We've updated the =builtins= model with a "default enumeration value"
field. This allows us to dynamically determine which built-in to use
as the type of enumerations. However:

- we didn't follow it through in the formatters; we are hard-coding
  this at present in C++. In a cross-language world, we should
  dynamically detect the default enumeration type. This is not quite
  as trivial as it seems (what would happen if we loaded multiple
  programming languages?). Supporting this properly may require adding
  a programming language to the model.
- it is not possible to override this from JSON/Dia. We could do this
  by supplying a type via dynamic extensions.

Tasks:

- add meta-data parameter to enumeration expander
- add resolver support to resolve name
- add meta-data flag for using language default type

*** COMPLETED Allow disabling =invalid= value in enumerations         :story:
    CLOSED: [2017-01-30 Mon 14:49]
    CLOCK: [2017-01-30 Mon 14:40]--[2017-01-30 Mon 14:51] =>  0:11
    CLOCK: [2017-01-30 Mon 14:30]--[2017-01-30 Mon 14:31] =>  0:01

#+begin_quote
*Story*: As a dogen user, I may not want to allow invalid values in
enumerations because they do not model my problem domain accurately.
#+end_quote

At present all enumerations must have an invalid value. One can
conceive cases where that is not a useful thing. We should have a
dynamic extension flag that disables it.

*** COMPLETED Add support for configurable enumeration values         :story:
    CLOSED: [2017-01-30 Mon 23:01]
    CLOCK: [2017-01-30 Mon 23:02]--[2017-01-30 Mon 23:06] =>  0:04
    CLOCK: [2017-01-30 Mon 21:08]--[2017-01-30 Mon 23:01] =>  1:53
    CLOCK: [2017-01-30 Mon 18:20]--[2017-01-30 Mon 18:23] =>  0:03
    CLOCK: [2017-01-30 Mon 17:51]--[2017-01-30 Mon 18:19] =>  0:28
    CLOCK: [2017-01-30 Mon 17:38]--[2017-01-30 Mon 17:50] =>  0:12
    CLOCK: [2017-01-30 Mon 16:31]--[2017-01-30 Mon 17:37] =>  1:06
    CLOCK: [2017-01-30 Mon 15:23]--[2017-01-30 Mon 16:31] =>  1:08
    CLOCK: [2017-01-30 Mon 14:50]--[2017-01-30 Mon 15:22] =>  0:32

At present we generate the enumeration value as part of the
transformation process in =yarn.dia=, based on the relative position
of the enumerator. This is not ideal:

- it does not allow users to supply their own values;
- it does not allow users to disable enumeration values altogether and
  rely on language defaults instead.

We could:

- add meta-data for users to supply their own values;
- add meta-data to disable setting the enumerator value altogether.

*** COMPLETED Test data for booleans is not oscillating correctly     :story:
    CLOSED: [2017-02-02 Thu 15:51]
    CLOCK: [2017-02-02 Thu 16:52]--[2017-02-02 Thu 16:53] =>  0:01
    CLOCK: [2017-02-02 Thu 16:30]--[2017-02-02 Thu 16:52] =>  0:22
    CLOCK: [2017-02-02 Thu 15:54]--[2017-02-02 Thu 16:29] =>  0:35
    CLOCK: [2017-02-02 Thu 15:36]--[2017-02-02 Thu 15:53] =>  0:17

We are not handling correctly zero and one, both producing
false. Ideally we should have a true, false, ... sequence across the
board rather than false, false, true, ... This can cause tests to fail
spuriously because we rely on generators where g(0) != g(1). If a
class has only a property of type bool this (should) be a problem. Why
it hasn't been thus far is not clear.

Huge amount of time was spent chasing a red-herring: its not possible
to have just a single boolean on a base class. This causes the canned
tests to break. The reason why is because of the way the tests are
executed and the way boolean works:

- we always throw away the first output of the generator; this was
  done to avoid it being equal to the default constructed instance of
  a type.
- however, the default constructed boolean is false whereas the first
  sequence of the generator is actually true;
- but the second value of the generator is false, which is equal to
  the default. So whilst this technique works for non-oscillating
  types, it breaks on booleans.
- this problem will manifest itself whenever there is a boolean and no
  other type (to force differences). The reason why we didn't notice
  this before is because the types in trivial inheritance with
  booleans are not currently being tested.
- the problem was solved by ensuring the oscillations of the bools do
  match the expectations of the tests.

*** STARTED Inclusion directive logic is too complex                  :story:
    CLOCK: [2017-02-02 Thu 18:02]--[2017-02-02 Thu 18:13] =>  0:11
    CLOCK: [2017-02-02 Thu 17:25]--[2017-02-02 Thu 18:01] =>  0:36
    CLOCK: [2017-02-02 Thu 16:54]--[2017-02-02 Thu 17:24] =>  0:30

At present we have a number of flags handling inclusion directive
generation:

- =quilt.cpp.inclusion_required=: if true, the type requires inclusion
  across the board; defaults to true.
- =quilt.cpp.hash.class_header.inclusion_required=: i.e. formatter
  specific inclusion required; if true this specific formatter
  requires an inclusion directive. Defaults to true.

The logic is then as follows:

- if the top-level inclusion directive is true and there are no
  "overrides", we generate the inclusion directives ourselves.
- if the top-level inclusion directive is true and there are
  "overrides", we use the overrides.
- if the top-level inclusion directive is false, no inclusion
  directives are used for this type.

Now in practice, the use cases are a bit more limited:

- either the type is a code-generator type, in which case, all flags
  are true and all overrides are unused.
- or the type belongs to a proxy model and has one or more
  overrides. In this case, for the archetypes where there is an
  override, we use that, for all other archetypes we do not require
  inclusion. An additional case is where we just don't support the
  archetype but we're ignoring that for now.

So it seems the key problem is in distinguishing the origin of the
type: if it comes from a proxy model, we should never generate the
directives, and use overrides where available; if it comes from a
reference or target model we shuld always generate the directives.

This could be achieved by flagging proxy types somehow.

Another interesting point is that if we somehow could know if there is
at least one overridden directive for any of the formatters, we could
then not bother having a field for the formatter level
=inclusion_required=; we could simply default them all to
false. This could be achieved by a meta-data API that checks to see if
a field exists by name (we probably have this already).

Cases:

| Scenario                                    | Example     | Action                       |
|---------------------------------------------+-------------+------------------------------|
| Proxy model that does not require overrides | int         | inclusion_required is false. |
| Proxy model that requires some overrides    | std::string | detect presence of override. |
| Non-proxy model                             |             | Generate directives          |

*** STARTED Handle "special includes" generically                     :story:
    CLOCK: [2017-02-02 Thu 15:09]--[2017-02-02 Thu 15:35] =>  0:26
    CLOCK: [2017-02-02 Thu 15:04]--[2017-02-02 Thu 15:08] =>  0:04
    CLOCK: [2017-02-02 Thu 14:03]--[2017-02-02 Thu 15:03] =>  1:00
    CLOCK: [2017-02-02 Thu 10:33]--[2017-02-02 Thu 12:01] =>  1:28
    CLOCK: [2017-02-02 Thu 10:28]--[2017-02-02 Thu 10:32] =>  0:04
    CLOCK: [2017-02-02 Thu 10:24]--[2017-02-02 Thu 10:27] =>  0:03
    CLOCK: [2017-02-02 Thu 09:49]--[2017-02-02 Thu 10:23] =>  0:34
    CLOCK: [2017-02-02 Thu 09:21]--[2017-02-02 Thu 09:48] =>  0:27
    CLOCK: [2017-02-02 Thu 09:10]--[2017-02-02 Thu 09:20] =>  0:10
    CLOCK: [2017-02-02 Thu 09:04]--[2017-02-02 Thu 09:09] =>  0:05
    CLOCK: [2017-02-02 Thu 08:53]--[2017-02-02 Thu 09:03] =>  0:10
    CLOCK: [2017-02-02 Thu 08:02]--[2017-02-02 Thu 08:52] =>  0:50
    CLOCK: [2017-02-02 Thu 06:48]--[2017-02-02 Thu 07:32] =>  0:44
    CLOCK: [2017-02-01 Wed 16:54]--[2017-02-01 Wed 17:43] =>  0:49
    CLOCK: [2017-02-01 Wed 15:09]--[2017-02-01 Wed 16:53] =>  1:44

We did a quick hack to handle "special includes": we simply "detected"
them in include builder and then did the appropriate action in each of
the include providers. In order to make this work dynamically, we need
somehow to have "associated includes" on a per type basis. For
example:

- type =x= requires include =y= in formatter =f=.

This can easily be achieved via an "additional inclusion directive"
which is a container. For example:

:        "extensions" : {
:                "quilt.cpp.helper.family" : "Dereferenceable",
:                "quilt.cpp.types.class_header_formatter.inclusion_directive" : "<boost/weak_ptr.hpp>",

Could have:

:                "quilt.cpp.types.class_header_formatter.additional_inclusion_directive" : "<some_include.hpp>",

If multiple are provided then they are all added. This highlights an
important point: we need a way to inject type specific includes from a
formatter. It makes no sense to declare all of these up front in a
library since we do not know what all possible formatters are, nor
what requirements they may have for inclusion. At the same time,
formatters cannot be expected to declare types. The solution is to be
able to "inject" these dependencies from a JSON file associated with
the formatter. We could supply the qualified name and the properties
to inject. This problem can be solved later on - create a separate
story for this.

Tasks:

- move to the repository/factory pattern for dependencies;
- rename meta-data to =inclusion_directive.principal=;
- add =inclusion_directive.auxiliary=;
- change code to also include auxiliary directives.

*** STARTED Add support for primitives across the pipeline            :story:
    CLOCK: [2017-02-01 Wed 14:02]--[2017-02-01 Wed 15:08] =>  1:06
    CLOCK: [2017-02-01 Wed 11:40]--[2017-02-01 Wed 12:01] =>  0:21
    CLOCK: [2017-02-01 Wed 11:06]--[2017-02-01 Wed 11:39] =>  0:33
    CLOCK: [2017-02-01 Wed 11:01]--[2017-02-01 Wed 11:05] =>  0:04
    CLOCK: [2017-02-01 Wed 10:55]--[2017-02-01 Wed 11:01] =>  0:06
    CLOCK: [2017-02-01 Wed 10:43]--[2017-02-01 Wed 10:54] =>  0:11
    CLOCK: [2017-02-01 Wed 09:25]--[2017-02-01 Wed 10:42] =>  1:17
    CLOCK: [2017-01-31 Tue 17:10]--[2017-01-31 Tue 17:46] =>  0:36
    CLOCK: [2017-01-31 Tue 16:43]--[2017-01-31 Tue 16:49] =>  0:06
    CLOCK: [2017-01-31 Tue 16:37]--[2017-01-31 Tue 16:42] =>  0:05
    CLOCK: [2017-01-31 Tue 16:28]--[2017-01-31 Tue 16:36] =>  0:08
    CLOCK: [2017-01-31 Tue 16:20]--[2017-01-31 Tue 16:27] =>  0:07
    CLOCK: [2017-01-31 Tue 16:01]--[2017-01-31 Tue 16:19] =>  0:18
    CLOCK: [2017-01-31 Tue 15:55]--[2017-01-31 Tue 16:00] =>  0:05
    CLOCK: [2017-01-31 Tue 15:40]--[2017-01-31 Tue 15:54] =>  0:14
    CLOCK: [2017-01-31 Tue 15:31]--[2017-01-31 Tue 15:39] =>  0:08
    CLOCK: [2017-01-31 Tue 15:10]--[2017-01-31 Tue 15:30] =>  0:20
    CLOCK: [2017-01-31 Tue 14:50]--[2017-01-31 Tue 15:09] =>  0:19
    CLOCK: [2017-01-31 Tue 14:12]--[2017-01-31 Tue 14:49] =>  0:37
    CLOCK: [2017-01-31 Tue 13:25]--[2017-01-31 Tue 13:52] =>  0:27
    CLOCK: [2017-01-31 Tue 12:45]--[2017-01-31 Tue 13:24] =>  0:39
    CLOCK: [2017-01-31 Tue 11:53]--[2017-01-31 Tue 12:00] =>  0:07
    CLOCK: [2017-01-31 Tue 11:46]--[2017-01-31 Tue 11:52] =>  0:06
    CLOCK: [2017-01-31 Tue 10:55]--[2017-01-31 Tue 11:35] =>  0:40
    CLOCK: [2017-01-31 Tue 10:28]--[2017-01-31 Tue 10:40] =>  0:12
    CLOCK: [2017-01-31 Tue 10:09]--[2017-01-31 Tue 10:27] =>  0:18
    CLOCK: [2017-01-31 Tue 09:46]--[2017-01-31 Tue 10:08] =>  0:22
    CLOCK: [2017-01-31 Tue 09:16]--[2017-01-31 Tue 09:45] =>  0:29
    CLOCK: [2017-01-31 Tue 07:45]--[2017-01-31 Tue 09:15] =>  1:30
    CLOCK: [2017-01-31 Tue 07:08]--[2017-01-31 Tue 07:11] =>  0:03
    CLOCK: [2017-01-31 Tue 06:59]--[2017-01-31 Tue 07:07] =>  0:08
    CLOCK: [2017-01-31 Tue 06:31]--[2017-01-31 Tue 06:58] =>  0:27
    CLOCK: [2017-01-31 Tue 05:31]--[2017-01-31 Tue 05:37] =>  0:06

- add a new yarn element: primitive. Add an attribute of type name
  called =underlying_type=.
- add an is nullable flag, settable from meta-data. If true, the
  primitive can be null.
- add a stereotype for primitive.
- add a meta-data parameter for the underlying type. Make it the same
  as for enumerations. Add it to the parsing expander.
- add a primitive expander, similar to the enumeration expander in
  intermediate model expansion.
- add formatters for primitive across all facets and languages.
- add a test model for each language with primitives that test all
  built-ins, string and date.

*Previous Understanding*

One extremely useful feature would be to create "aliases" for types
which could be implemented as strongly-typed aliases where there is
language support. The gist of the problem is as described in here:

[[http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3515.pdf][Toward Opaque Typedefs for C++1Y]]

This is also similar to the problem space of boost dimensions,
although their problem is more generic. The gist of it is that one
should be able to "conceptually" sub-class primitives such as int and
even types such as string and have the code generator create some
representation of that type that has the desired properties (including
a "to underlying" function). These types would not be interchangeable
with their aliased types. For example, if we define a "book id" as an
unsigned int, it should not be interchangeable with unsigned
int. Potentially it should also not have certain int abilities such as
adding/multiplication and so forth.

Links:

- [[http://www.boost.org/doc/libs/1_37_0/boost/strong_typedef.hpp][Boost Strong Typedef]]
- [[http://stackoverflow.com/questions/23726038/how-can-i-create-a-new-primitive-type-using-c11-style-strong-typedefs][How can I create a new primitive type using C++11 style strong
  typedefs?]]
- [[http://stackoverflow.com/questions/28916627/strong-typedefs][Strong typedefs]]
- [[http://programmers.stackexchange.com/questions/243154/c-strongly-typed-typedef][C++ strongly typed typedef]]
- [[http://www.ilikebigbits.com/blog/2014/5/6/type-safe-identifiers-in-c][Type safe handles in C++]]
3
Note: the other stories in the backlog about typedefs are just about
the C++ feature, not this extension to it. Hence we called it "type
aliasing" to avoid confusion.

The implementation is fairly similar to enumerations:

- add a stereotype for this concept.
- add a yarn element.
- add a meta-data parameter for the underlying type. Make it the same
  as for enumerations. Add validation to ensure the element is always
  a primitive. Actually, this is fine for enumerations but not for
  "primitives". We need an additional parameter on each element (can
  be the underlying element of a primitive?).
- add formatters.

The first problem is what to call it. Type alias is not a good name
because an alias implies they are interchangeable; this is what one is
trying to avoid. One sneaky way out is to call primitives "builtins"
and call these "primitives". This somewhat reflects the truth in that
builtins are supposed to be hardware level concepts.

*** Drop "inclusion" prefix in quilt.cpp                              :story:

The inclusion related classes in quilt.cpp have really long names. We
probably don't really need them to have the "inclusion" prefix as we
know what they are doing by looking at just
"directive/dependencies". Drop the inclusion prefix across the board.

*** Immutable types cannot be owned by mutable types                  :story:

When we try to create a mutable class that has a property of an
immutable type, the code fails to compile due to the swap
method. This is because immutable types do not provide swap.

*** "Assistant" type found in test model                              :story:

We seem to be generating an "Assistant" type on the =primitve= test model:

: 2017-02-01 10:28:44.513705 [DEBUG] [quilt.cpp.formattables.helper_expander] Procesing element: <dogen><test_models><primitive><Assistant>

Figure out what this type is and why its appearing on this test model.

*** Mark elements that are valid enumeration underlying elements      :story:

The following are the valid types for enumerations:

- C#: byte, sbyte, short, ushort, int, uint, long, or ulong.
- C++: int, unsigned int, long, unsigned long, long long, or unsigned long long

We need to populate =can_be_enumeration_underlier= and add these types
to the indices. We then need to update the validator to check the user
has selected a valid underlying type.

*** Mark elements that are valid primitive underlying elements        :story:

The following are the valid types for primitives:

- all built-ins;
- string types.
- date, time, etc.

*** Merge both yarn model validators                                  :story:

In truth we do not need =model= validation, just =intermediate_model=
validation; the transformation between the two is trivial. What we do
need is two kinds of =intermediate_model= validation:

- after the "single" =intermediate_model= is generated.
- after the merged, resolved, etc =intermediate_model= is generated.

We could call these "stages" and have two methods:

- =validate_first_stage=
- =validate_second_stage=

Actually the problem is this class is going to become too messy. Maybe
we do need to classes, but reflecting the stages rather than the model
types:

- first stage validator
- second stage validator

Both validate =intermediate_model=.

Tasks:

- move =abstract_elements= to indices
- decomposer now operates on intermediate models
- rename validators

*** Add validation rules for primitives and enumerations              :story:

We need to add all of the rules related to validation of primitives
and enumerations to the validators. This can only be done after the
indices have been populated.

*** Add mapping support between upsilon and LAM                       :story:

At present we map upsilon directly to a language-specific model
(C++/C#), which gets code-generated. However, from a tailor
perspective, this is not ideal; we would end up with N different
models. Ideally, we should get a LAM representation of the JSON model
which could then be used to code-generate multiple languages.

This is probably not too hard, given the mapper knows how to convert
between upsilon and LAM. We just need to finish LAM support and then
try mapping them and see what breaks. Tailor would have to somehow
tell yarn to set the output language to LAM.

Notes:

- if output is more than one language, change it to LAM. Otherwise
  leave it as language specific.
- we need to inject via meta-data the annotations for the output
  languages.
- We only need to perform mapping if input language is upsilon. For
  all other languages we can leave it as is. But for upsilon, tailor
  needs to do a full intermediate model workflow.
- unparsed type needs to be recomputed as part of mapping.
- we are not adding the LAM mapping to the upsilon id container.
- we need to add support for "default mappings"

*** Make the Zeta model compilable                                    :story:

We need to work through the list of issues with the Zeta model and get
it to a compilable state.

*** Add support for Language Agnostic Models (LAM)                    :story:

Tasks:

- create the basic LAM types and add mapping for both C# and C++.
- create a LAM test model which tests that the mapping for all types
  generates compilable code.

LAM type map:

| Type                            | C++                              | C#                                                | Upsilon              |
|---------------------------------+----------------------------------+---------------------------------------------------+----------------------|
| lam::byte                       | unsigned char                    | uchar                                             |                      |
| lam::character                  | char                             | char                                              |                      |
| lam::integer8                   | std::int8_t                      | sbyte                                             |                      |
| lam::integer16                  | std::int16_t                     | System.Int16                                      |                      |
| lam::integer32                  | std::int32_t                     | System.Int32                                      |                      |
| lam::integer64                  | std::int64_t                     | System.Int64                                      | Integer64            |
| lam::integer                    | int                              | int                                               |                      |
| lam::single_floating            | float                            | float                                             |                      |
| lam::double_floating            | double                           | double                                            | Double               |
| lam::boolean                    | bool                             | bool                                              | Boolean              |
| lam::string                     | std::string                      | string                                            | String, Binary, Guid |
| lam::date                       | boost::gregorian::date           | System.DateTime                                   | Date                 |
| lam::time                       | boost::posix_time::time_duration | System.TimeSpan                                   | UtcTime              |
| lam::date_time                  | boost::posix_time::ptime         | System.DateTime                                   | UtcDateTime          |
| lam::decimal                    | std::decimal                     | System.Decimal                                    | Decimal              |
| lam::dynamic_array<T>           | std::vector<T>                   | System.Collections.Generic.List<T>                | Collection           |
| lam::static_array<T>            | std::array<T>                    | System.Collections.Generic.Array<T>               |                      |
| lam::unordered_dictionary<K, V> | std::unordered_map<K, V>         | System.Collections.Generic.Dictionary<K, V>       |                      |
| lam::ordered_dictionary<K, V>   | std::map<K, V>                   | System.Collections.Generic.SortedDictionary<K, V> |                      |
| lam::unordered_set<K>           | std::unordered_set<K>            | System.Collections.Generic.HashSet<T>             |                      |
| lam::ordered_set<K>             | std::set<K>                      | System.Collections.Generic.SortedSet<T>           |                      |
| lam::queue<T>                   | std::queue<T>                    | System.Collections.Generic.Queue<T>               |                      |
| lam::stack<T>                   | std::stack<T>                    | System.Collections.Generic.Stack<T>               |                      |
| lam::linked_list<T>             | std::list<T>                     | System.Collections.Generic.LinkedList<T>          |                      |
| lam::pointer<T>                 | boost::shared_ptr<T>             | <erase>                                           |                      |

*Previous Understanding*

When we start supporting more than one language, one interesting
feature would be to be able to define a model once and have it
generated for all supported languages. This would be achieved by
having a system model (or set of system models) that define all the
key types in a language agnostic manner. For example:

: lam::string
: lam::int
: lam::int16

Each of these types then has a set of meta-data fields that map them
to a type in a supported language:

: lam:string: cpp.concrete_type_mapping = std::string
: lam:string: csharp.concrete_type_mapping = string

And so on. We load the user model that makes use of LAM, we generate
the merged model still with LAM types and then we perform a
translation for each of the supported and enabled languages: for every
LAM type, we replace all its references with the corresponding
concrete type. We need to split the supplied mapping into a QName, use
the QName to load the system models for that language, look up the
type and replace it. After the translation no LAM types are left. We
end up with N yarn merged models where N is the number of supported and
enabled languages.

Each of these models is then sent down to code generation. This should
be equivalent to manually generating models per language - we could
use this as a test.

Once we have LAM, it would be great to be able to exchange data
between languages. This could be done as follows:

- XML: create a "LAM" XML schema, and a set of formatters that read
  and write from it. This is kind of like reverse mapping the types
  back to LAM types when writing the XML.
- JSON: similar approach to XML, minus the schema.
- POF: use the coherence libraries to dump the models into POF.

Tasks:

- create the LAM model with a set of basic types.
- add a set of mapping fields into yarn: =yarn.mapping.csharp=, etc
  and populate the types with entries for each supported language.
- create a notion of mapping of intermediate models into
  languages. The input is the merged intermediate model and the output
  is N models one per language. We also need a way to associate
  backends with languages. Each model is sent down to its backend.
- note that reverse mapping is possible: we should be able to
  associate a type on a given language with it's lam type. This means
  that, given a model in say C#, we could reconstruct a yarn lam model
  (or tell the user about the list of failures to map). This should be
  logged as a separate story.

Links:

- [[http://stackoverflow.com/questions/741054/mapping-between-stl-c-and-c-sharp-containers][Mapping between stl C++ and C# containers]]
- [[http://stackoverflow.com/questions/3659044/comparison-of-c-stl-collections-and-c-sharp-collections][Comparison of C++ STL collections and C# collections?]]

*** Map upsilon primitives to intrinsics                              :story:

Upsilon allows users to create "strong typedefs" around primitve
types. We need to unpack these into their intrinsic counterparts and
them map the intrinsics to native types.

Slight mistake: we mapped the primitive types themselves but in
reality what needs to be mapped are the fields making references to
the primitive types. We should just filter out all primitives.

Additional wrinkle: what the end users want is to unpack "real
primitives" into intrinsics, but "other" primitives should be mapped
to objects. This can be achieved by hard-coding =Plaform= primitives
into the mapping layer. However, some non-platform primitives may also
be candidates too. We need to create a list of these to see how
widespread the problem is.

Another alternative is to apply hard-coded regexes:

- if the name matches any of the intrinsic names

Finally, the last option may be to have yet another mapping data file
format that lists the primitives to unbox.

*** Add validation for C# keywords                                    :story:

At present we are checking the model does not contain C++ keywords but
we're not doing the same for C#.

- [[https://en.wikibooks.org/wiki/C_Sharp_Programming/Keywords][C# Programming/Keywords]]

We should also ensure models in LAM are checked for both C# and C++
keywords - or actually always check all keywords for all languages.

*** Tidy-up "is floating point"                                       :story:

We should introduce "point type" enumeration to replace "is floating
point":

- none
- floating
- fixed
- exact

*** Enumerations coming out of Upsilon are empty                      :story:

We don't seem to be translating the enumerators into yarn
enumerators.

*** Add support for nullable built-ins and primitives                 :story:

One useful feature in C# is the ability to add nullable types:

: Nullable<int>
: ?

This is particularly useful for built-in types, although its also
applicable to value types. For primitives this is slightly more
straightforward and we can make it a property of the meta-type (since
the whole point is that users define new primitives for each domain
type). For built-ins its slightly more tricky because its a property
of the attribute. We'd have to extend:

- the name tree to add a "is nullable" to each name tree
- the parser to read nullable and do the right thing
- LAM, to suport some kind of =lam::nullable= which in C++ translates
  to =boost::optional= and C# =Nullable=. Interestingly enough we can
  create a "Nullable type" in the global namespace.

*** Add case conversion support                                       :story:

When we map a LAM model into C#, it will have whatever case we used
originally. This is not ideal as in C++ we'd like to use underscores
instead. It would be nice if there was an "identifier converter" that
went through the model and updated all identifiers from underscores to
camel case. This includes classes, attributes, enumerators, etc. The
LAM model would remain with underscores.

For this to work correctly we'd need some kind of "casing" enumeration
associated with the model, and then another one associated with each
language. This means that if the model is already in camel case, we
would just generate camel case for both C++ and C#.

*** Consider renaming LAM to a sewing term                            :story:

In keeping with the rest of Dogen we should also use a sewing term for
LAM. Wool is an interesting one.

*** Windows package has element mappings                              :story:

For some reason even after renaming the mappings file it is still on
windows. This could also be a bug of the installer; after a uninstall
and reinstall the problem went away. Double check with a clean
install.

*** Comments in C# appear to be the attribute name                    :story:

It seems we are copying across the attribute name rather than a
comment. This could also be a problem with the input. Check the Zeta
model.

*** Add support for generic container types to C#                     :story:

We should add all major container types and tests for them.

: IEnumerable<T>
: ICollection<T>
: IList<T>
: IDictionary<K, V>
: List<T>
: ConcurrentQueue<T>, ConcurrentStack<T>, LinkedList<T>
: Dictionary<TKey, TValue>
: SortedList<TKey, TValue>
: ConcurrentDictionary<TKey, TValue>
: KeyedCollection<TKey, TItem>

Notes:

- we need a way to determine if we are using a helper, the assistant
  or a sequence generator directly.

*** Allow users to choose mapping sets                                :story:

At present we load the "default" mappings, which are also the only
mappings available. It is entirely possible that users will not agree
with those mappings. If we add a name to the mappings, and provide a
meta-data tag to choose mappings we can then allow users to provide
their own and set the meta-data accordingly. Mapper then reads the
meta-data in the model and uses the requested element map. For this we
need to name the element maps and we also need to create a "mapping
set". These can be indexed by name in the mapping repository. Mapper
chooses the mapping set to use.

*** Allow users to override mapping sets at the element level         :story:

Sometimes we may want to use a different mapping just for a particular
element. For example, by default =lam::linked_list= binds to
=std::list= for C++; once Dogen supports =std::forward_list=, one may
want to override this for a partial number of elements. It would be
nice if one could have a meta-data tag at the attribute level that
would override the mapping. The one slight wrinkle is that we would
not be able to supply a breakdown of:

- simple name
- model name
- internal modules

and so forth. So this may cause issues for resolution. We'd have to
test it and see what breaks. If this fails, the alternative is that
the mapping is by id, and we'd resolve it internally using the mapping
container, e.g.:

- create a map of names for each language by id
- user supplies the id for a given language, we look it up and
  retrieve the name.

*** Add support for command line meta-data parameters                 :story:

We do not want to force end users to change their existing file
format. However, it is sometimes necessary to supply parameters into
dogen which are not representable in the existing format. We could
create a very simple extension to the command line arguments that
would generate scribbles; these would then be appended to the model
during the yarn workflow. Example:

: --kvp a=b

or:

: --meta-data a=b

*** Do not generate upsilon proxy models                              :story:

At present we are marking all types in an upsilon config as target. In
practice, only one of the models is the target.

*** Load system models based on language prefix                       :story:

We used a convention for system models that have the language as a
prefix:

: cpp.boost.json
: cpp.builtins.json
: cpp.std.json
: csharp.builtins.json
: csharp.system.collections.generic.json
: csharp.system.collections.json
: upsilon.builtins.json

Coincidentally, this could make life easier when it comes to filtering
models by language: we could pattern match the file name depending on
the language and only load those who match. The convention would then
become a rule for system models. With this we would not have to load
the models, process annotations, etc just to get access to the
language.

*** Add support for ignoring types                                    :story:

#+begin_quote
*Story*: As a dogen user, I want to ignore certain types I am working
on so that I can evolve my diagram over time, whilst still being able
to commit it.
#+end_quote

Sometimes when changing a diagram it may be useful to set some types
to "ignore", i.e. make dogen pretend they don't exist at all. For
instance one may want to introduce new types one at a time. It would
be nice to have a dynamic extension flag for ignoring.

We should probably have some kind of warning to ensure users are aware
of the types being ignored.

*** Add auxiliary function properties to c#                           :story:

We need to associate a function with an attribute and a
formatter. This could be the helper or the assistant (or nothing).

Actually this is not quite so straightforward. In =io= (c#) we have:

: assistant.Add("ByteProperty", value.ByteProperty, true/*withSeparator*/);

This is a bit of a problem because we now need to different
invocations, one for helper another for the assistant, which differ on
the function prototype. For the helper we need something like:

: Add(assistant, "ByteProperty", value.ByteProperty, true/*withSeparator*/);

So a string is no longer sufficient. Maybe we could have a struct with
auxiliary function properties:

- auxiliary function types = enum with { assistant, helper }
- auxiliary function name = string

So we can have a map of attribute id to map of formatter id to
auxiliary function properties.

Actually we should also create "attribute properties" as a top-level
container so that in the future we can latch on other attribute level
properties.

*** Add internal object dumper resolution                             :story:

We should try to resolve an object to a local dumper, if one exists;
for all model types and primitives. Add a registrar for local dumpers.

: using System;
: using System.Collections.Generic;
:
: namespace Dogen.TestModels.CSharpModel
: {
:     static public class DynamicDumperRegistrar
:     {
:         public interface IDynamicDumper
:         {
:             void Dump(AssistantDumper assistant, object value);
:         }
:
:         static private IDictionary<Type, IDynamicDumper> _dumpers = new Dictionary<Type, IDynamicDumper>();
:
:         static void RegisterDumper(Type type, IDynamicDumper dumper)
:         {
:         }
:     }
: }

*** Fix issues with bintray windows uploads                           :story:

At present we are doing a lot of hacks for windows:

- hardcoding the path to the package
- not uploading on just tags
- uploading to the top-level folder instead of the version.

Ideally we want to reuse the Travis BinTray descriptor but AppVeyor
does not support this directly.

*** Model references are not transitive                               :story:

For some reason we do not seem to be following references of
referenced models. We should load them automatically, now that they
are part of the meta-data. However, the =yarn.json= model breaks when
we remove the reference to annotation even though it does not use this
model directly and =yarn= is referencing it correctly.

*** Add support for boxed types                                       :story:

At present we support built-in types such as =int= but not
=System.Integer=. In theory we should be able to add these types with:

:        "quilt.csharp.assistant.requires_assistance": true,
:        "quilt.csharp.assistant.method_postfix": "ShortByte"

And they should behave just like built-ins.

*** Add handcrafted class to C# test model                            :story:

We should make sure handcrafted code works in C#.

Actually in order to get handcrafted types to work we need support for
enablement. This is a somewhat tricky feature so we should leave it
for after all the main ones are done.

*** Add support for arrays                                            :story:

At present the yarn parser does not support array notation:
=string[]=. We need to look into how arrays would work for C++ and
implement it in a compatible way.

Links:

- [[https://www.dotnetperls.com/array][array]]

*** Add fluency support for C#                                        :story:

We need to add fluent support for C#.

C# properties are not compatible with the fluent pattern. Instead, one
needs to create builders, across the inheritance tree.

Links:

- [[http://stackoverflow.com/questions/13761666/how-to-use-fluent-style-syntactic-sugar-with-c-sharp-property-declaration][How to use Fluent style syntactic sugar with c# property declaration]]

*** Add visitor support to C#                                         :story:

Implement the visitor formatters for C#.

*** Benchmarks do not work for utility tests                          :story:

When we run the benchmarks for utility we get an error:

: Running 95 test cases...
: /home/marco/Development/DomainDrivenConsulting/dogen/projects/utility/tests/asserter_tests.cpp(141): error: in "asserter_tests/assert_directory_good_data_set_returns_true": check asserter::assert_directory(e, a) has failed

Seems like the tests do not clean up after themselves. We need to add
some clean up logic and re-enable the tests.

*** Add cross-model support to C#                                     :story:

At present we do not have any tests that prove that cross-model
support is working (other than proxy models). We need to create a user
level model that makes use of types from another model. In theory it
should just work since we are using fully qualified names everywhere.

*** Generate AssemblyInfo in C#                                       :story:

We need to inject a type for this in fabric. For now we can leave it
mainly blank but in the future we need to have meta-data in yarn for
all of its properties:

: [assembly: AssemblyTitle ("TestDogen")]
: [assembly: AssemblyDescription ("")]
: [assembly: AssemblyConfiguration ("")]
: [assembly: AssemblyCompany ("")]
: [assembly: AssemblyProduct ("")]
: [assembly: AssemblyCopyright ("marco")]
: [assembly: AssemblyTrademark ("")]
: [assembly: AssemblyCulture ("")]
: [assembly: AssemblyVersion ("1.0.*")]

These appear to just be properties at the model level.

*** Consider adding a clone method for C#                             :story:

It would be nice to have a way to clone a object graph. We probably
have an equivalent story for this for C++ in the backlog.

*** Consider making the output directory configurable in C#           :story:

At present we are outputting binaries into the =bin= directory,
locally on the project directory. However, it would make more sense to
output to =build/output= like C++ does. For this to work, we need to
be able to supply an output directory as meta-data.

*** Add support for nuget                                             :story:

A proxy model may require obtaining a nuget package. Users should be
able to define a proxy model as requiring a nuget package and then
Dogen should generate packages.config and add all such models to it.

: +  <package id="NUnit" version="2.6.4" targetFramework="net45" />

*** Augment element ID with meta-model type                           :story:

The element ID is considered to be a system-level, opaque
identifier. It could, for all intents and purposes, be a large int. We
have decided to use a string so we can dump it to the log and figure
out what is going on without having to map IDs to a human-readable
value. In the same vein, we could also add another component to the ID
that would contain the meta-model element for that ID. This
information could be placed at the start.

Of course, we will not be able to remove the look-ups we have at
present that try to figure out the meta-model element because they are
related to resolution. But for any other cases it may result in
slightly more performant code. We need to look at all the use cases.

*** Identifiable needs to use camel case in C#                        :story:

At present we are building identifiables with underscores.

*** Generate windows packages with CPack                              :story:

We tried to generate windows packages by using the NSIS tool, but
there are no binaries available for it at present. However, it seems
CPack can now generate MSIs directly:

- [[http://stackoverflow.com/questions/18437356/how-to-generate-msi-installer-with-cmake][How to generate .msi installer with cmake?]]
- [[https://cmake.org/cmake/help/v3.0/module/CPackWIX.html][CPackWIX]]

We need to investigate how to get the build to produce MSIs using WIX.

*** Move enablement into quilt                                        :story:

We need to make use of the exact same logic as implemented in
=quilt.cpp= for enablement. Perhaps all of the enablement related
functionality can be lifted and grafted onto quilt without any major
changes.

*** Add feature to disable regions                                    :story:

We need a way to stop outputting regions if the user does not want
them.

*** Add parameters for using imported assemblies                      :story:

Assemblies imported via proxy models need to have the ability to
supply two parameters:

- assembly name: this is not always the same as the proxy model name;
- root namespace: similarly this may differ from the proxy model name.

These should be supplied as meta data and used when constructing
fabric types.

*** Add msbuild target for C# test model                              :story:

Once we are generating solutions, we should detect msbuild (or xbuild)
and build the solution. This should be a CMake target that runs on
Travis.

*** Add visibility to yarn elements                                   :story:

We need to be able to mark yarn types as:

- public
- internal

This can then be used by C++ as well for visibility etc.

*** Add partial element support to yarn                               :story:

We need to be able to mark yarn elements as "partial". It is then up
to programming languages to map this to a language feature. At present
only [[https://msdn.microsoft.com/en-us/library/wa80x488.aspx][C# would do so]].

It would be nice to have a more meaningful name at yarn
level. However, seems like this is a fairly general programming
concept now: [[https://en.wikipedia.org/wiki/Class_(computer_programming)#Partial][wikipedia]].

*** Add visibility to yarn attributes                                 :story:

We need to be able to mark yarn attributes as:

- public
- private
- protected

*** Add final support in C#                                           :story:

Links:

- [[https://msdn.microsoft.com/en-us/library/88c54tsw.aspx][sealed (C# Reference)]]

*** Add aspects for C# serialisation support                          :story:

We need to add serialisation support:

- C# serialisation
- Data Contract serialisation
- Json serialisation

In C# these are done via attributes so we do not need additional
facets. We will need a lot of configuration knobs though:

- ability to switch a serialisation method on at model level or
  element level.
- support for serialisation specific arguments such as parameters for
  Json.Net.

Links:

- [[https://msdn.microsoft.com/en-us/library/ms731923(v%3Dvs.110).aspx][Types Supported by the Data Contract Serializer]]
- [[https://msdn.microsoft.com/en-us/library/ms731073(v%3Dvs.110).aspx][Serialization and Deserialization]]
- [[https://msdn.microsoft.com/en-us/library/ms733127(v%3Dvs.110).aspx][Using Data Contracts]]
- [[https://msdn.microsoft.com/en-us/library/ms731923(v%3Dvs.110).aspx][Types Supported by the Data Contract Serializer]]

*** Consider adding =artefact_set= to formatters' model               :story:

We are using collections of artefacts quite a bit, and it makes sense
to create an abstraction for it such as a =artefact_set=. However, for
this to work properly we need to add at least one basic behaviour: the
ability to merge two artefact sets. Or else we will end up having to
unpack the artefacts, then merging them, then creating a new artefact
set.

Problem is, we either create the artefact set as a non-generatable
type - not ideal - or we create it as generatable and need to add this
as a free function. We need to wait until dogen has support for
merging code generation.

** Deprecated
