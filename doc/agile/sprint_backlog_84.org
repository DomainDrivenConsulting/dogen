#+title: Sprint Backlog 84
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) spike(p) }

* Mission Statement

- complete the properties refactoring across all models;
- finish implementing IO helpers.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2016-07-06 Wed 19:24]
| <75>                                                                        |        |      |      |       |
| Headline                                                                    | Time   |      |      |     % |
|-----------------------------------------------------------------------------+--------+------+------+-------|
| *Total time*                                                                | *9:13* |      |      | 100.0 |
|-----------------------------------------------------------------------------+--------+------+------+-------|
| Stories                                                                     | 9:13   |      |      | 100.0 |
| Active                                                                      |        | 9:13 |      | 100.0 |
| STARTED Sprint and product backlog grooming                                 |        |      | 0:55 |   9.9 |
| STARTED Manual updates and blog posts                                       |        |      | 0:37 |   6.7 |
| COMPLETED Try to fix tag build issues                                       |        |      | 1:28 |  15.9 |
| COMPLETED Enable build type on travis                                       |        |      | 1:17 |  13.9 |
| COMPLETED Add initial support for coveralls                                 |        |      | 0:29 |   5.2 |
| COMPLETED Simplify local builds on emacs                                    |        |      | 0:20 |   3.6 |
| COMPLETED Create a debug build for clang in travis                          |        |      | 0:10 |   1.8 |
| COMPLETED Rename element settings back to aspect settings                   |        |      | 0:50 |   9.0 |
| STARTED Refactor general settings                                           |        |      | 3:07 |  33.8 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2016-07-06 Wed 18:31]--[2016-07-06 Wed 18:35] =>  0:04
    CLOCK: [2016-07-05 Tue 21:27]--[2016-07-05 Tue 21:47] =>  0:20
    CLOCK: [2016-07-05 Tue 21:22]--[2016-07-05 Tue 21:26] =>  0:04
    CLOCK: [2016-07-05 Tue 21:11]--[2016-07-05 Tue 21:21] =>  0:10
    CLOCK: [2016-07-04 Mon 20:05]--[2016-07-04 Mon 20:22] =>  0:17

Updates to sprint and product backlog.

*** STARTED Manual updates and blog posts                             :story:
    CLOCK: [2016-07-05 Tue 21:48]--[2016-07-05 Tue 22:25] =>  0:37

Time taken with blog posts and updates to the manual.

*** COMPLETED Try to fix tag build issues                             :story:
    CLOSED: [2016-07-04 Mon 21:03]
    CLOCK: [2016-07-04 Mon 21:39]--[2016-07-04 Mon 22:12] =>  0:33
    CLOCK: [2016-07-04 Mon 21:15]--[2016-07-04 Mon 21:38] =>  0:23
    CLOCK: [2016-07-04 Mon 20:30]--[2016-07-04 Mon 21:02] =>  0:32

For some reason we are getting failures when building the tag:

: CMake Error at CMakeLists.txt:203 (string):
:  string sub-command STRIP requires two arguments.

For some reason the git commit count command is failing on a tag. At
any rate, we do not seem to need the strip, so the easy fix for now is
to remove it.

Actually, reproducing the commands locally, the error is:

: fatal: ambiguous argument 'master': unknown revision or path not in the working tree.
: Use '--' to separate paths from revisions, like this:
: 'git <command> [<revision>...] -- [<file>...]'

This is probably related to checking out the branch but requesting
rev-list from master. We can ask for the current branch's rev-list
instead:

: git rev-list --count HEAD

We were already doing this for the hash of the top-commit.

*** COMPLETED Enable build type on travis                             :story:
    CLOSED: [2016-07-05 Tue 21:10]
    CLOCK: [2016-07-05 Tue 20:17]--[2016-07-05 Tue 20:22] =>  0:05
    CLOCK: [2016-07-05 Tue 19:04]--[2016-07-05 Tue 20:16] =>  1:12

Using =BUILD_TYPE= seems to disable the stage folder in travis -
though it works locally. We probably shouldn't use the stage folder
since its not a CMake idiom.

The other thing to notice is that we do not have a =make_directory=
for these folders anywhere in the code base. Its not clear how it has
been working so far.

- generate the folders if they do not exist;
- remove =WITH_DEBUG=.

*** COMPLETED Add initial support for coveralls                       :story:
    CLOSED: [2016-07-06 Wed 18:01]
    CLOCK: [2016-07-06 Wed 18:01]--[2016-07-06 Wed 18:30] =>  0:29

Seems like all we need to do to have code coverage from travis is to
enable it in the YML file.

Try just copying the code from [[https://github.com/JoakimSoderberg/coveralls-cmake][coveralls-cmake]]

- we are generating far too much output. We need to keep it quieter or
  we will break travis.
- we are not filtering out non-project files from initial
  processing. There must be a gcov option to ignore files.

: Process: /home/marco/Development/DomainDrivenConsulting/dogen/build/output/gcc-5/Debug/projects/quilt/spec/CMakeFiles/quilt.spec.dir/main.cpp.gcda
: ------------------------------------------------------------------------------
: File '../../../../projects/quilt/spec/main.cpp'
: Lines executed:62.50% of 8
: Creating '^#^#^#^#projects#quilt#spec#main.cpp.gcov'
:
: File '/usr/local/personal/include/boost/smart_ptr/detail/sp_counted_impl.hpp'
: Lines executed:60.00% of 20
: Creating '#usr#local#personal#include#boost#smart_ptr#detail#sp_counted_impl.hpp.gcov'

See also:

- [[https://github.com/JoakimSoderberg/coveralls-cmake-example/blob/master/CMakeLists.txt][example use of coveralls-cmake]]
- [[https://github.com/SpinWaveGenie/SpinWaveGenie/blob/master/libSpinWaveGenie/CMakeLists.txt][SpinWaveGenie's support for Coveralls]]

**** Direct use of Coveralls failed

We had to remove coveralls:

: - coveralls --gcov "$GCOV" --gcov-options '\-lp' -e /usr

This was generating over 10 MB of logging so the build got terminated.

We also add to remove debug builds:

: -DWITH_DEBUG=on -DWITH_PROFILING=on

We were getting a lot of internal compiler errors:

: FAILED: /usr/bin/g++-4.9   -DBOOST_ALL_DYN_LINK -g -O0 -Wall -Wextra -pedantic -Werror -Wno-system-headers -Woverloaded-virtual -Wwrite-strings -fprofile-arcs -ftest-coverage -std=c++11 -frtti -fvisibility-inlines-hidden -fvisibility=default -isystem /usr/include/libxml2 -Istage/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/dia/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/dia_to_sml/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/frontend/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/backend/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/sml/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/config/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/cpp/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/cpp_formatters/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/sml_to_cpp/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/formatters/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/utility/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/knit/include -I/home/travis/build/DomainDrivenConsulting/dogen/projects/knitter/include -MMD -MT projects/sml_to_cpp/src/CMakeFiles/sml_to_cpp.dir/types/transformer.cpp.o -MF "projects/sml_to_cpp/src/CMakeFiles/sml_to_cpp.dir/types/transformer.cpp.o.d" -o projects/sml_to_cpp/src/CMakeFiles/sml_to_cpp.dir/types/transformer.cpp.o -c /home/travis/build/DomainDrivenConsulting/dogen/projects/sml_to_cpp/src/types/transformer.cpp
: g++-4.9: internal compiler error: Killed (program cc1plus)
: Please submit a full bug report,
: with preprocessed source if appropriate.
: See <file:///usr/share/doc/gcc-4.9/README.Bugs> for instructions.

Finally note also that we must add coverage _after_ the script
executes or else we risk doing coverage whilst the build is taking
place. Hopefully this is the reason for these errors:

: /home/travis/build/DomainDrivenConsulting/output/projects/test_models/class_without_attributes/src/CMakeFiles/class_without_attributes.dir/io/package_1/class_1_io.cpp.gcda:cannot open data file, assuming not executed
: File '/usr/include/c++/4.9/bits/basic_ios.h'
: No executable lines

We should read up on the [[http://docs.travis-ci.com/user/build-lifecycle/][life-cycle]] properly.

**** Travis Examples

Seems like all we need to do to have code coverage from travis is to
enable it in the YML file. We should look into copying it from the
[[https://github.com/apolukhin/Boost.DLL][Boost.DLL]] [[https://raw.githubusercontent.com/apolukhin/Boost.DLL/master/.travis.yml][example]]. We also need to enable coverage on all builds,
separately from nightlies. The key parts appear to be these:

:  - ../../../b2 cxxflags="--coverage -std=$CXX_STANDARD" linkflags="--coverage"

and

: after_success:
:    - find ../../../bin.v2/ -name "*.gcda" -exec cp "{}" ./ \;
:    - find ../../../bin.v2/ -name "*.gcno" -exec cp "{}" ./ \;
:    - sudo apt-get install -qq python-yaml lcov
:    - lcov --directory ./ --base-directory ./ --capture --output-file coverage.info
:    - lcov --remove coverage.info '/usr*' '*/filesystem*' '*/container*' '*/core/*' '*/exception/*' '*/intrusive/*' '*/smart_ptr/*' '*/move/*' '*/fusion/*' '*/io/*' '*/function/*' '*/iterator/*' '*/preprocessor/*' '*/system/*' '*/boost/test/*' '*/boost/detail/*' '*/utility/*' '*/dll/example/*' '*/dll/test/*' '*/pe_info.hpp' '*/macho_info.hpp' -o coverage.info
:    - gem install coveralls-lcov
:    - cd .. && coveralls-lcov test/coverage.info

Another way seems to be using gcov, as per [[https://github.com/fabianschuiki/Maxwell][Maxwell]] [[https://raw.githubusercontent.com/fabianschuiki/Maxwell/master/.travis.yml][travis.yml]]:

: - if [ "$CXX" = "g++" ]; then sudo apt-get install -qq g++-4.8; export CXX="g++-4.8" CC="gcc-4.8" GCOV="gcov-4.8"; fi
:  - sudo pip install cpp-coveralls

and

: script:
:  - export CTEST_OUTPUT_ON_FAILURE=1
:  - cmake -DCMAKE_BUILD_TYPE=gcov . && make && make test
: after_success:
:  - coveralls --gcov "$GCOV" --gcov-options '\-lp' -e CMakeFiles -E ".*/test/.*" -E ".*/mock/.*" -e maxwell/gen -e language -e thirdparty -e maxwell/ast/nodes -e maxwell/driver/gramdiag.c -e maxwell/driver/Parser.cpp -e maxwell/driver/Parser.hpp -e maxwell/driver/Scanner.cpp -e maxwell/driver/position.hh -e maxwell/driver/stack.hh -e maxwell/driver/location.hh

Yet another way seems to be creating a script to do coverage, as per
[[https://github.com/BoostGSoC13/boost.afio][boost.afio]] [[https://raw.githubusercontent.com/BoostGSoC13/boost.afio/master/.travis.yml][travis.yml]]. The script is available [[https://raw.githubusercontent.com/BoostGSoC13/boost.afio/master/test/update_coveralls.sh][here]].

Another example from [[https://github.com/boostorg/dll/blob/develop/.travis.yml][Boost.Dll]].

*** COMPLETED Simplify local builds on emacs                          :story:
    CLOSED: [2016-07-06 Wed 18:32]
    CLOCK: [2016-07-06 Wed 00:20]--[2016-07-06 Wed 00:40] =>  0:20

With the move to build type, local builds on emacs are getting more
and more complicated. We need some kind of script. The command line at
present is rather monstrous:

: export PROJ=~/Development/DomainDrivenConsulting/dogen/ &&
: export BUILD=Release &&
: cd ${PROJ}/build/output/gcc-5/${BUILD} &&
: CMAKE_INCLUDE_PATH=/usr/local/personal/include
: CMAKE_LIBRARY_PATH=/usr/local/personal/lib
: CC=gcc-5 CXX=g++-5
: cmake ${PROJ} -G Ninja -DCMAKE_BUILD_TYPE=${BUILD}
: -DCMAKE_EXPORT_COMPILE_COMMANDS=TRUE -DWITH_LATEX=FALSE &&
: ninja -j5

Create a simple bash script with a couple of parameters:

- clang or gcc
- debug or release
- cmake dir

Usage:

: COVERALLS=1
: /home/marco/Development/DomainDrivenConsulting/dogen/build/scripts/build.linux.sh
: Debug gcc /usr/local/personal

*** COMPLETED Create a debug build for clang in travis                :story:
    CLOSED: [2016-07-06 Wed 18:59]
    CLOCK: [2016-07-05 Tue 21:00]--[2016-07-05 Tue 21:10] =>  0:10

In order to enable code coverage we need to have a debug build. For
this we need to setup travis with a build matrix, with two build types
for clang (debug and release).

Example YML: [[https://github.com/Microsoft/GSL/blob/master/.travis.yml][GSL]]
*** COMPLETED Rename element settings back to aspect settings         :story:
    CLOSED: [2016-07-06 Wed 19:24]
    CLOCK: [2016-07-06 Wed 19:07]--[2016-07-06 Wed 19:24] =>  0:17
    CLOCK: [2016-07-06 Wed 18:33]--[2016-07-06 Wed 19:06] =>  0:33

As per design story, we incorrectly added non-aspect attributes to
this class. Remove them and rename the class.

*** STARTED Refactor general settings                                 :story:
    CLOCK: [2016-07-06 Wed 00:13]--[2016-07-06 Wed 00:20] =>  0:07
    CLOCK: [2016-07-06 Wed 00:06]--[2016-07-06 Wed 00:12] =>  0:06
    CLOCK: [2016-07-05 Tue 23:16]--[2016-07-06 Wed 00:05] =>  0:49
    CLOCK: [2016-07-05 Tue 22:26]--[2016-07-05 Tue 23:15] =>  0:49
    CLOCK: [2016-07-04 Mon 22:54]--[2016-07-04 Mon 23:30] =>  0:36
    CLOCK: [2016-07-04 Mon 22:13]--[2016-07-04 Mon 22:53] =>  0:40

Tasks:

- create a file settings class that reflects dynamic (and nothing
  more). Create an associated factory, repository etc.
- rename the existing general settings to file properties. Make the
  factory use the file settings to produce the properties.
- move general settings from the bundle into element properties.

*Previous Understanding*

A while ago we came up with this name for the settings of the generic
formatter model. This is the model with basic infrastructure to be
reused by the more specialised formatters. However, now that we have
many (many) settings classes, general settings may not be the most
appropriate name. We need to look a bit more deeply into the role of
this class and see if a better name is not available.

We could call it preamble settings because all settings are related to
the file preamble; annoyingly, we also generate a post-amble from
it. There doesn't seem to be any good names for the pair (preamble,
post-amble). In networking this would be called frame markers perhaps.

Now that we are not using =meta_data= any more, perhaps we could
re-purpose it for this (=meta_data_settings=). In a way, preambles and
post-ambles are meta-data, as opposed to the real file
contents. Having said that, one could say the same about any kind of
comments.

We could also use [[http://www1.appstate.edu/~yaleread/typographichierarchy.pdf][typography terminology]]: headers and footers.

Now that we have subsidiary settings and principal settings do we need
the rename? We should consider "universal settings" maybe.

In addition, the convention is now that "settings" mean a strongly
typed representation of =dynamic= data; general "settings" are not
settings in this sense. However, we do need a class to model settings
properly (i.e. to mirror dynamic exactly, without any
transformations).

In truth, =annotation= is probably sufficient - or perhaps
=annotation_properties=. It could then have an =enabled= property to
replace =generate_preamble=. This is more accurate due to the
preamble/postamble setup explained above. In this setup, we'd have
=annotation_settings= to map to dynamic data, with an annotation
settings factory which reads these off of dynamic object; then, an
annotation factory to generate annotations. Finally, we can introduce
the annotation formatter to generate the portion of boilerplate
related to just the annotation. Boilerplate formatter collaborates
with annotation formatter.

More ideas on this: are these not just "file settings"? After all the
meta-data it contains relates to file-level properties. As =file= is
an entity defined in =formatters= this fits the bill nicely. We still
have to deal with the dilemma described above (these "settings" are
not all directly read out of meta-data). We should then call these
"file properties". We need to then refactor the code so that there is
a file settings class that is an exact match of what is read out of
dynamic and is then used as input to generate the file properties.
*

*** Rename bundle to element settings                                 :story:

As per design story, these are really the settings that belong to the
element. Rename and deal with the fallout.

*** Add support for file properties overrides                         :story:

At present we have hard-coded the file properties (old general
settings) to be read from the root object only. In an ideal world, we
should be able to override some of these such as the copyrights. It
may not make sense to be able to override them all though.

*** Create a IO settings class                                        :story:

Add a class to model all of the settings required to produce the io
invocation, create a repository for it and associated factory and
finally add the repository to the context.

*** Detect knitter and disable code generation accordingly            :story:

At present you can try to build the codegen knitting targets even
before you built knitter. We should make them conditional on detecting
=knitter=. We just need to make sure this is not cached by CMake.

*** Implement streaming for type in terms of IO settings              :story:

- rename it o "IO invocation for type".
- call it with an ID; look up the corresponding IO settings in the global
  IO settings container from context.
- remove all other streaming for type implementations and use the new
  one in the legacy formatters.

*** Group the file related fields under a prefix                      :story:

Now we have =element= as a prefix, it probably makes sense to also
group the fields that are related to file names, paths etc. These
could be under =file= or perhaps =paths=? Examples:

- =quilt.cpp.file.include_directory_name=
- =quilt.cpp.source_directory_name=

*** Implement qualified name efficiently                              :story:

We used a =std::map= to store qualified names. In practice, we don't
need something this expensive.

- instead of mapping names to languages, we could map them to
  "styles". There are only a few "styles" across all programming
  languages (e.g. =.= separated, =::= separated and so on).
- we can also create an array of these styles. We know up front how
  many styles there are.
- finally we can create a enumeration to access the array. At present
  this is not possible because we cannot disable invalid, nor is it
  possible to move it to a different position (e.g. last). Also we
  will have to static cast the enum to access the int, which is not
  very pretty.

Once all of this is done we can simply do, at O(1):

: name.qualified[static_cast<unsigned int>(styles::double_colon_separated_style)]

We can prettify it a bit: [[http://stackoverflow.com/questions/8357240/how-to-automatically-convert-strongly-typed-enum-into-int][How to automatically convert strongly typed
enum into int?]]

: template <typename E>
: constexpr typename std::underlying_type<E>::type to_underlying(E e) {
:     return static_cast<typename std::underlying_type<E>::type>(e);
: }
:
: std::cout << foo(to_underlying(b::B2)) << std::endl;

Giving us:

: name.qualified[to_underlying(styles::double_colon_separated_style)]

*** Create utility methods for =__type__= etc                         :story:

At present we've hard-coded the field name for =__type__= and so forth
in each formatter. This is not ideal. Create a simple utility method
that returns it and update all formatters to use it instead. List of
hard-coded things:

- =__type__=
- =<empty>=
- =data=
- =value=
- =memory=
- string helper variables: =<new_line>=, =<quote>=
- =tidy_up_string=

*** Why do we need helpers and io for some types?                     :story:

At present we have helper support for maps, sets, pairs etc. We also
seem to have utility support for these. Originally the idea was that
we needed utility so that users could have a map of dogen types and
still have streaming support. This is useful. However, what is
slightly less clear is why we don't just use the utility methods
inside the IO subsystem to output these types, but instead use
helpers. We should try doing that and see what breaks, there may be a
reasons for this.

In theory we just have to remove the helpers in IO for utility
supported types and add the includes to the meta-data; regenerate and
see what breaks. It could be related to the ordering of template
functions or some such problem. If so we need to document this in
manual. We should also do a quick search in backlog for this.

*** Character member variables are not tidied up on io                :story:

At present there is no code to convert non-printable chars into
something acceptable in JSON. We probably never noticed this before
because test data generates printable chars. Code generated is as
follows (all primitives model):

: << "\"char_property\": " << "\"" << v.char_property() << "\"" << ", "

We need a "tidy-up char" function to handle this properly.

*** Implement IO helper methods with new helper infrastructure        :story:

Problems:

- we do not have a "streaming for type" function in assistant. We need
  to figure out how to obtain this data from the helper.
- we do not have a name tree so we do not know what the key and value
  names are for associative containers. We probably need to add the
  name tree to the helper descriptor.
- =string_conversion_method= cannot be implemented as is;we need it
  for all properties, not just in the context of helpers. This seems
  to imply we need a way to access this information directly from the
  property. It will need some thinking.

*** Lists of strings are not properly tidied up on io                 :story:

In the log file, when we dump include dependencies we see invalid
JSON:

: [ "<iosfwd>", ""dogen/sml/types/merger.hpp"" ]

This implies we are not calling =tidy_up_string=. This can be tested
by creating a container of =filesystem::path=.

*** Type-bound helpers and generic helpers                            :story:

Not all helpers are bound to a type. We have the case of inserter
helper in io which is used by main formatters directly. We need to
make this distinction in the manual.

*** Check which properties need to loop through the entire model      :story:

In certain cases such as helpers we probably don't need to go through
all types; only the target types matter. Ensure we are not processing
other types for no reason.

*** Add validation for helper families                                :story:

At present we are checking that the name tree has the expected number
of type arguments:

:    const auto children(t.children());
:    if (children.size() != 1) {
:        BOOST_LOG_SEV(lg, error) << invalid_smart_pointer;
:        BOOST_THROW_EXCEPTION(formatting_error(invalid_smart_pointer));
:    }
:    smart_pointer_helper_stitch(fa, t);

In the future with dynamic helpers we will remove these checks. In
order to implement them we need to declare the type families up front
in a JSON file, with a name and number of type arguments. When
constructing the type helpers, we can check the name tree to make sure
the number of type arguments is correct.

*** Update assistant to use new helper information                    :story:

Once all the pieces are in place, the assistant can then use the
element properties to find out which helpers are required for each
type; call those helpers and populate the file with the generate
code. We can remove all previous helper support.

*** Create a settings class for the "requires" settings               :story:

We need to populate these in a settings workflow of some kind.

*** Consider caching "all modules" in location                        :story:

At present we are adding the module lists together to build the
qualified name; location could have a "all modules" list that
concatenates external, model and internal modules. We should look at
performance before doing this change though.

*** Consider reducing the number of qname lookups in cpp model        :story:

At present we are still using =yarn::name= in a lot of repositories in
quilt. We already had one go in moving to id's but there are still
quite a few left. Investigate to see if there are more that can be
moved.

*** Implement formattables in terms of yarn types                     :epic:

At present formattables are just a shadow copy of yarn types plus
additional =cpp= specific types. In practice:

- for the types that are shadow copies, we could have helper utilities
  that do the translation on the fly (e.g. for names).
- for additional information which cannot be translated, we could have
  containers indexed by qualified name and query those just before we
  call the transformer. This is the case with formatter properties. We
  need something similar to house "type properties" such as
  =requires_stream_manipulators=. These could be moved into aspect
  settings.
- for types that do not exist in yarn, we could inherit from element;
  this is the case for registrar, forward declarations, cmakelists and
  odb options. Note that with this we are now saying that element
  space contains anything which can be modeled, regardless of if they
  are part of the programming language type system, or build system,
  etc. This is not ideal, but its not a problem just yet. We could
  update the factory to generate these types and then take a copy of
  the model and inject them in it.

*** Add support for selectively disabling helpers on a family         :story:

At present when a type belongs to a helper family it must provide all
helpers across all facets. This means that we can't support the cases
where a helper is required for one facet for one type but not for
others. For example, we cannot create a family for =Dereferenceable=
including both smart pointers and optionals because optional does not
need a helper for =types=.

One solution for this is to allow disabling the helper for a given
type on a given facet. However, our templating mechanism in dynamic is
not able to cope with this use case. Changes required:

- add a "component" to ownership hierarchy. This would be "helper" in
  our case. We should also set "type" which has been hacked via the
  qualified name.
- create a supported/enabled field with a component of helper and a
  facet template. We could change this to formatter template if
  required in the future.
- merge the families of optional and smart pointer into
  =Dereferenceable=.
- disable the helper for types for optional.
- update the helper settings to read this new field.
- enabled method now checks the helper properties.

*** Remove nested type info                                           :story:

Once all of the infrastructure is in place, we should not need this
class any more. Remove code from transformer and remove object types
and anything else that was used to dispatch based on type.

*** Rename methods parsing name trees                                 :story:

We have a variety of names for the methods parsing name trees
recursively. The best one seems to be =walk_name_tree=. We should use
this name consistently.

*** Initialise formatters in the formatter's translation unit         :story:

At present we are initialising the formatters in each of the facet
initialisers. However, it makes more sense to initialise them on the
translation unit for each formatter. This will also make life easier
when we move to a mustache world where there may not be a formatter
header file at all.

*** Consider using indices rather than associative containers         :story:

Once we generate the final model the model becomes constant; this
means we can easily assign an [[https://en.wikipedia.org/wiki/Ordinal_number][ordinal number]] to each model
element. These could be arranged so that we always start with
generatable types first; this way we always generate dense
containers - there are some cases where we need both generatable types
and non-generatable types; in other cases we just need generatable
types; we never need just non-generatable types. We also need to know
the position of the first non-generatable type (or alternatively, the
size of the generatable types set).

Once we have this, we can start creating vectors with a fixed size
(either total number of elements or just size of generatable
types). We can also make it so that each name has an id which is the
ordinal (another model post-processing activity). Actually we should
call it "type index" or some other name because its a transient
id. This means both properties and settings require no lookups at all
since all positions are known beforehand (except in cases where the
key of the associative container must be the =yarn::name= because we
use it for processing).

In theory, a similar approach can be done for formatters too. We know
upfront what the ordinal number is for each formatter because they are
all registered before we start processing. If formatters obtained
their ordinal number at registration, wherever we are using a map of
formatter name to a resource, we could use a fixed-size
vector. However, formatters may be sparse in many cases (if not all
cases?). For example, we do not have formatter properties for all
formatters for every =yarn::name= because many (most) formatters don't
make sense for every yarn type. Thus this is less applicable, at least
for formatter properties. We need to look carefully at all use cases
and see if there is any place where this approach is applicable.

*** Handle "special includes" correctly                               :story:

We did a quick hack to handle "special includes": we simply "detected"
them in include builder and then did the appropriate action in each of
the include providers. In order to make this work dynamically, we need
somehow to have "associated includes" on a per type basis. For
example:

- type =x= requires include =y= in formatter =f=.

This can easily be achieved via an "additional inclusion directive"
which is a container. For example:

:        "extensions" : {
:                "quilt.cpp.helper.family" : "Dereferenceable",
:                "quilt.cpp.types.class_header_formatter.inclusion_directive" : "<boost/weak_ptr.hpp>",

Could have:

:                "quilt.cpp.types.class_header_formatter.additional_inclusion_directive" : "<some_include.hpp>",

If multiple are provided then they are all added. This highlights an
important point: we need a way to inject type specific includes from a
formatter. It makes no sense to declare all of these up front in a
library since we do not know what all possible formatters are, nor
what requirements they may have for inclusion. At the same time,
formatters cannot be expected to declare types. The solution is to be
able to "inject" these dependencies from a JSON file associated with
the formatter. We could supply the qualified name and the properties
to inject. This problem can be solved later on - create a separate
story for this.

*** Registrar in serialisation is not stable sorted                   :story:

We seem to have a traffic light diff on =registrar_ser.cpp=:

: -    dogen::config::register_types(ar);
:      dogen::quilt::cpp::register_types(ar);
:      dogen::yarn::register_types(ar);
: +    dogen::config::register_types(ar);

This is probably a lack of a stable sort in model dependencies.

*** Support only specific attributes for certain facets               :story:

Whenever an object has a unique identifier, it may make sense to make
use of it for:

- hashing
- equality
- less than

And so forth. For example, names and name trees don't really require
comparing the entire state of the object. We need a way to mark
properties against each facet in the meta-data.

** Deprecated
