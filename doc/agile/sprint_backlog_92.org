#+title: Sprint Backlog 92
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- implement dart.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2016-11-07 Mon 14:12]
| <75>                                                                        |        |      |      |       |
| Headline                                                                    | Time   |      |      |     % |
|-----------------------------------------------------------------------------+--------+------+------+-------|
| *Total time*                                                                | *5:23* |      |      | 100.0 |
|-----------------------------------------------------------------------------+--------+------+------+-------|
| Stories                                                                     | 5:23   |      |      | 100.0 |
| Active                                                                      |        | 5:23 |      | 100.0 |
| STARTED Sprint and product backlog grooming                                 |        |      | 0:10 |   3.1 |
| COMPLETED Edit release notes for previous sprint                            |        |      | 0:27 |   8.4 |
| COMPLETED Tidy-up README file                                               |        |      | 1:07 |  20.7 |
| COMPLETED Sort out PIC/PIE linking problems                                 |        |      | 1:55 |  35.6 |
| STARTED Try to fix BinTray problems                                         |        |      | 1:09 |  21.4 |
| STARTED Supply model references via meta-data rather than command line      |        |      | 0:35 |  10.8 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2016-11-07 Mon 09:08]--[2016-11-07 Mon 09:18] =>  0:10

Updates to sprint and product backlog.

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2016-11-07 Mon 10:10]
    CLOCK: [2016-11-07 Mon 09:19]--[2016-11-07 Mon 09:46] =>  0:27

Add github release notes for previous sprint.

Title: Dogen v0.91.0, "Namibe"

#+begin_src markdown
Overview
========
With this sprint we have concluded the bulk of the work on internal refactoring. There were also a number of user visible changes:

- **integration of knit and stitch**: its no longer necessary to run the stand alone executable to transform stitch templates; elements can be configured to run this automatically as part of knitting.
- **introduction of wale**: in addition to stitch, a simpler type of templates was introduced.
- **stitch templates can make use of profiles**: it is now possible to avoid duplication in stitch templates by creating profiles.

For more details see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_91.org).
#+end_src

*** COMPLETED Tidy-up README file                                     :story:
    CLOSED: [2016-11-07 Mon 11:32]
    CLOCK: [2016-11-07 Mon 11:31]--[2016-11-07 Mon 11:42] =>  0:11
    CLOCK: [2016-11-07 Mon 10:34]--[2016-11-07 Mon 11:30] =>  0:56

Our README is quite old and stale. We need to:

- mention MDSD
- add build instructions

*** COMPLETED Sort out PIC/PIE linking problems                       :story:
    CLOSED: [2016-11-07 Mon 13:22]
    CLOCK: [2016-11-07 Mon 10:23]--[2016-11-07 Mon 10:34] =>  0:11
    CLOCK: [2016-11-07 Mon 09:46]--[2016-11-07 Mon 10:22] =>  0:36
    CLOCK: [2016-11-07 Mon 08:00]--[2016-11-07 Mon 09:08] =>  1:08


Ever since we last dist-upgraded we stop being able to build Dogen. We
are getting linking errors to do with PIC. The problem seems to be
related to [[https://wiki.debian.org/Hardening#DEB_BUILD_HARDENING_PIE_.28gcc.2Fg.2B-.2B-_-fPIE_-pie.29][DEB_BUILD_HARDENING_PIE]], which forces all binaries to be
built with PIE. However, our libraries are not built with PIC, so
there seems to be some kind of incompatibility.

We rebuilt latest boost with the testing compiler but that didn't
quite solve all the issues, so the problem is also within the dogen
code.

[[https://github.com/ldc-developers/ldc/pull/1664][This ticket]] provides some insight:

#+begin_quote
Modern Linux distributions have their toolchain generate PIC code for
additional security features (like ASLR).
Since there is no (sane) way to detect whether the toolchain defaults to
PIC code, we simply default to PIC code on all Linux
distributions to avoid linking issues on these OSes.

The relocation model can be switched back to non-PIC code manually at
any time.
#+end_quote

Seems like the solution is just to add:

#+begin_src
set(CMAKE_POSITION_INDEPENDENT_CODE ON)
#+end_src

To the top-level CMake file. It at least solves the problem locally.

Links:

- [[https://cmake.org/pipermail/cmake/2010-September/039468.html][PIE and PIC in mixed projects]]
- [[http://stackoverflow.com/questions/38296756/what-is-the-idiomatic-way-in-cmake-to-add-the-fpic-compiler-option][What is the idiomatic way in CMAKE to add the -fPIC compiler option?]]

*** STARTED Try to fix BinTray problems                               :story:
    CLOCK: [2016-11-07 Mon 13:15]--[2016-11-07 Mon 13:34] =>  0:19
    CLOCK: [2016-11-07 Mon 12:20]--[2016-11-07 Mon 12:34] =>  0:14
    CLOCK: [2016-11-07 Mon 11:43]--[2016-11-07 Mon 12:19] =>  0:36

According to BinTray support:

#+begin_src
As we can see at the provided descriptor output, you didnâ€™t entered "uploadPattern" for the files, and this seems to be the reason for the issue.
The file pattern format should be like this (excludePattern is optimal):

{"includePattern": "target/(.*)", "excludePattern": "target/.*.zip$", "uploadPattern": "/$1"}

You can find project example in our GitHub "Bintray Examples" page : travis-ci-example.
#+end_src

Try to update descriptor and see if it fixes it. Using =$1= actually
resulted in a =$1= package, presumably because we are not using
regexes. We need to hard-code the name.

*** STARTED Supply model references via meta-data rather than command line :story:
    CLOCK: [2016-11-07 Mon 14:07]--[2016-11-07 Mon 14:12] =>  0:05
    CLOCK: [2016-11-07 Mon 13:36]--[2016-11-07 Mon 14:06] =>  0:30

It doesn't make any sense to have model dependencies in the command
line. After all, the model cannot be interpreted without them. A
better way to do this would be to split this functionality into two:

- command line supplies "import directories" or "reference
  directories", that is, directories to search when looking for
  models. By default the system directory is already in the
  path. Actually by default we should look into the current directory;
  this is sufficient for all our current use cases.
- model supplies "import statements". The problem here is that we need
  to also supply the file name of the model. We could perhaps omit the
  extension and then load all files that match (e.g. =.dia=, =.json=,
  etc). If more than one matches we should error. Actually we should
  just supply the full filename, as well as keep the current notation
  for the external project path.

This is also a nice way to avoid loading system models unnecessary;
users still need to declare the models they depend on, regardless if
system or user.

Each model should also supply the external module path as meta-data.

This is particularly painful since cross-model inheritance was
introduced because it means references are now transitive (we need to
know of the references of any model we reference). Once we add them to
the model, we should also load referenced models' references so that
the process is automatic.

In addition to references, we must also be able to supply the external
module path for the target model via the meta-data.

Notes:

- in order for this to work we need to refactor the pre-merge workflow
  quite considerably. We need to split out the target model, process
  that first, then use the annotations to build the descriptors. This
  probably means we need to merge the descriptor factory with the
  pre-merge workflow. We should do this refactoring first.

Tasks:

- refactor descriptor factory, merge it with pre-merge workflow.
- add new references field to workflow
- add parsing of field as per options
- add references to all models
- remove command line option

Merged stories

*External module path and references as meta-data*

It actually does not make a lot of sense to allow users to supply
external module paths and references as command line options. This is
because the model will fail to build unless we provide the correct
ones; these are not configurable items in this sense. The project
path, etc are - and so should remain command line options.

We need to move these two into the meta-data. This would also mean we
no longer need to pass in external module paths for references, which
is much cleaner.

*** Merge properties factory with stitching factory                   :story:

In stitch we still have a few classes that are light on
responsibilities. One case is the stitching properties factory, traits
etc. We should merge all of this into a single class, properties
factory.

*** Rename project directory path                                     :story:

The C++ options have an attribute called
=project_directory_path=. This is a bit misleading; it is actually the
top-level directory that will contain the project directory. In
addition, this is not really C++ specific at all; it would apply to
any kernel and sub-kernel. We should rename it and move it to output
options.

*** Add log-level to command line                                     :story:

We are now increasingly logging at trace levels. We need to allow
users to supply a more fine-grained log configuration. This could be
done by simply allowing users to set the log level via a command-line
flag: =log_level=. It would replace verbose.

*** Create a tool to generate product skeletons                       :story:

Now that dogen is evolving to a MDSD tool, it would be great to be
able to create a complete product skeleton from a tool. This would
entail:

- directory structure. We should document our standard product
  directory structure as part of this exercise. Initial document added
  to manual as "project_structure.org".
- licence: user can choose one.
- copyright: input by user, used in CMakeFiles, etc. added to the
  licence.
- CI support: travis, appveyor
- EDE support:
- CMake support: top-level CMakefiles, CPack. versioning
  templates, valgrind, doxygen. For CTest we should also generate a
  "setup cron" and "setup windows scheduler" scripts. User can just
  run these from the build machine and it will start running CTest.
- conan support: perhaps with just boost for now
- agile with first sprint
- README with emblems.

Name for the tool: dart.

Tool should have different "template sets" so that we could have a
"standard dogen product" but users can come up with other project
structures.

Tool should add FindODB if user wants ODB support. Similar for EOS
when we support it again. We should probably have HTTP links to the
sources of these packages and download them on the fly.

Tool should also create git repo and do first commit (optional).

For extra bonus points, we should create a project in GitHub, Travis
and AppVeyor from dart.

We should also generate a RPM/Deb installation script for at least
boost, doxygen, build essentials, clang.

We should also consider a "refresh" or "force" statement, perhaps on a
file-by-file basis, which would allow one to regenerate all of these
files. This would be useful to pick-up changes in travis files, etc.

One problem with travis files is that each project has its own
dependencies. We should move these over to a shell script and call
these. The script is not generated or perhaps we just generate a
skeleton. This also highlights the issue that we have different kinds
of files:

- files that we generate and expect the user to modify;
- files that we generate but don't expect user modifications;
- files that the user generates.

We need a way to classify these.

Dart should use stitch templates to generate files.

We may need some options such as "generate boost test ctest
integration", etc.

Notes:

- [[https://github.com/elbeno/skeleton][Skeleton]]: project to generate c++ project skeletons.

*** Consider adding =artefact_set= to formatters' model               :story:

We are using collections of artefacts quite a bit, and it makes sense
to create an abstraction for it such as a =artefact_set=. However, for
this to work properly we need to add at least one basic behaviour: the
ability to merge two artefact sets. Or else we will end up having to
unpack the artefacts, then merging them, then creating a new artefact
set.

Problem is, we either create the artefact set as a non-generatable
type - not ideal - or we create it as generatable and need to add this
as a free function. We need to wait until dogen has support for
merging code generation.

*** Consider supplying element configuration as a parameter           :story:

Figure out if element configuration is context or if it is better
expressed as a stand alone formatting parameter.

*** Formatters' repository should be created in quilt                 :story:

At present we are creating the formatters' repository in
=quilt.cpp=. However it will be shared by all backends in the
kernel. Move it up to =quilt= level and supply it as a paramter to the
backends.

*** Initialise formatters in the formatter's translation unit         :story:

At present we are initialising the formatters in each of the facet
initialisers. However, it makes more sense to initialise them on the
translation unit for each formatter. This will also make life easier
when we move to a mustache world where there may not be a formatter
header file at all.

*** Add knobs to control output of constructors and operators         :story:

At present we are outputting all of the default constructors and the
operators in the handcrafted templates. Ideally it should just be the
class name. We need a way of controlling all of the default
constructors and all of the operators in one go so we can set it on
the handcrafted profile.

** Deprecated
*** CANCELLED Add region support to stitch                            :story:
    CLOSED: [2016-10-25 Tue 11:05]

*Rationale*: This requires too much engineering effort. Decided on a
simpler approach.

- extend stitch to allow injecting external kvps such as
  decoration. This can probably be done manually but needs to be
  investigated.
- extend stitch to support named regions; the text template will
  preserve the names after template instantiation.
- note: regions are a property of the artefact. knit will also have to
  support regions. Perhaps we should start having well-defined regions
  such as =decoration.preamble=, =decoration.postamble=, etc.
