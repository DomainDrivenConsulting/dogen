#+title: Sprint Backlog 78
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) spike(p) }

* Mission Statement

- continue work on the cpp/quilt refactor.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75
#+CAPTION: Clock summary at [2016-01-04 Mon 21:36]
| <75>                                                                        |        |      |      |
| Headline                                                                    | Time   |      |      |
|-----------------------------------------------------------------------------+--------+------+------|
| *Total time*                                                                | *0:07* |      |      |
|-----------------------------------------------------------------------------+--------+------+------|
| Stories                                                                     | 0:07   |      |      |
| Active                                                                      |        | 0:07 |      |
| STARTED Sprint and product backlog grooming                                 |        |      | 0:07 |
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2016-01-04 Mon 21:28]--[2016-01-04 Mon 21:35] =>  0:07


Updates to sprint and product backlog.

*** STARTED Update manual                                             :story:

Updates to manual.

*** STARTED Supply formatter properties and settings directly to formatter :story:

In preparation for removing the cpp formattables, we need to supply
the formatter properties and settings in the format method, rather
than via the cpp type.

*** Tidy-up master include generation                                 :story:

At present we have one humongous hack in the factory to generate the
master includers. How to do this properly:

- wait until we start using yarn types.
- loop through the yarn model instead of the path derivatives.
- use a visitor to dispatch the types.
- do not filter out services?
- filter registrars etc based on type dispatching.

*** Create a separate flow for yarn based types                       :story:

We won't be able to replace all cpp types in one go, so the best way
to go about this is to incrementally update the formatters. This could
be done by having two sets of elements to format, one formattable
based and the other yarn based. We can update the interfaces, one type
a time and have them share the same registrars etc.

*** Implement formattables in terms of yarn types                     :story:

At present formattables are just a shadow copy of yarn types plus
additional =cpp= specific types. In practice:

- for the types that are shadow copies, we could have helper utilities
  that do the translation on the fly (e.g. for names).
- for additional information which cannot be translated, we could have
  containers indexed by qualified name and query those just before we
  call the transformer. This is the case with formatter properties. We
  need something similar to house "type properties" such as
  =requires_stream_manipulators=. These could be moved into aspect
  settings.
- for types that do not exist in yarn, we could inherit from element;
  this is the case for registrar, forward declarations, cmakelists and
  odb options. Note that with this we are now saying that element
  space contains anything which can be modeled, regardless of if they
  are part of the programming language type system, or build system,
  etc. This is not ideal, but its not a problem just yet. We could
  update the factory to generate these types and then take a copy of
  the model and inject them in it.

*** Create a settings class for the "requires" settings               :story:

We need to populate these in a settings workflow of some kind.

*** Attach helper methods to types dynamically                        :story:

In order to cope with the removal of nested type info, we need a way
to determine what helper methods are required for a given yarn type.

For this we need a way to allow helper methods to bind dynamically to
types. This can be done by using meta-data. The helper method
registers a name and the type uses that name it its key for helper
method. Where possible the helper method should use the name of the
STL concept it is binding to. We need settings support for reading
this field, and registration support for helper methods (registrar,
etc).

We should also find a nicer way to package helper methods, maybe
aligned to a model and type or concept.

Once this is done we need to remove the =object_types= that exist in
yarn just to figure out what helper methods to use.

*** Create a UML profile to formalise yarn concepts                   :story:

Profile should include the hashable, etc changes.

*** Create a map between UML/MOF terminology and yarn                 :story:

It would be helpful to know what a yarn type means in terms of
UML/MOF, and perhaps even explain why we have chosen certain names
instead of the UML ones. We should also cover the modeling of
relationships and the relation between yarn concepts and UML/MOF
classes. This will form a chapter in the manual.

The UML specification is available [[http://www.omg.org/spec/UML/2.5/][here]] and MOF specification is
available [[http://www.omg.org/spec/MOF/2.5][here]].

We need a way to uniquely identify a property. This could be done by
appending the containing type's qualified name to the property name.

See also [[http://www.uml-diagrams.org/][The Unified Modeling Language]] for a more accessible treatment.

*** Remove =service= stereotype                                       :story:

This really just means non-generatable, or do not generate. We already
have a stereotype for this. Remove =service= and any other stereotype
which is not being used such as =value_object= etc.

Actually, non-generatable is not a stereotype really. We should
instead have some meta-data that can affect generation:

- do not generate: do nothing at all. For references only. If a file
  exists with this file name, it will be deleted as part of
  housekeeping.
- generate blank file if it doesn't exist: we don't even want a
  template.
- generate with content if it doesn't exist, do not touch otherwise:
  what we call services at the moment. Generate a "template" that then
  gets filled in manually.
- generate and merge: merge the contents of the generated file with
  the current contents in the file system. When we support merging.
- generate and overwrite: generate the file and overwrite whatever
  exists in the file system.

This could be called "generation policy".

The second behaviour we get for free with services is that we disable
all facets except for types. A few points:

- we may want to have io, serialisation, etc. This is not possible at
  present. If a state of a service is made up of supported types, we
  could even use existing code generation.
- in order for this to be implemented correctly we need to hook in to
  the enablement management somehow. In addition, it seems each facet
  can have its own generation policy. For example we may want to
  manually create types but automatically generate io.
- the best way to handle this may be to setup "enablement profiles"
  that the user can hook up to. For example we could have a "default"
  profile that enables all facets (or uses facet defaults), a second
  "service" profile that enables types with partial generation and io
  with full generation and so on. We probably also need "generation
  profiles" to go with "enablement profiles".

*** Update copyright notices                                          :story:

We need to update all notices to reflect personal ownership until DDC
was formed, and then ownership by DDC.

- first update to personal ownership has been done, but we need to
  test if multiple copyright entries is properly supported.

*** Handle registration of services properly                          :story:

We need a way to determine if a type which is part of a generalisation
should be added to the registrar or not. In =generalisation_indexer=:

:     // FIXME: massive hack. must not add leafs for services.

One way would be to check if serialisation is enabled for that type
and if not, skip the type.

*** Refactor code around model origination                            :story:

- remove origin types and generation types, replacing it with just a
  boolean for is target. Actually we need something like:
  proxy_reference, non_proxy_reference, target. We also need a good
  name for this enumeration:
- at present we are using origin type to determine whether to create a
  registrar, etc in cpp model. There is no other use case for
  this. This is done in several places due to the bad handling of C++
  specific types. Grep for =references= in =cpp= to find all
  locations. We could split references into two (dogen, non-dogen).
- we should also replace has generatable types with something more
  like "target model has types" or "is target model empty". The idea
  we are trying to capture is that the target model contained at least
  one type. This could be set by the merger when it processes the
  target model.

*Previous Understanding*

In the past we added a number of knobs around generation, all with
their own problems:

- =origin_types=: was the model/type created by the user or the
  system. in reality this means did the model come from Dia or
  JSON. this is confusing as the user can also add JSON files (their
  own model library) and in the future the user can use JSON
  exclusively without needed Dia at all.
- =generation_types=: if the model is target, all types are to be
  generated /unless/ they are not properly supported, in which case
  they are to be "partially" generated (as is the case with
  services). This is a formatter decision and yarn should not know
  anything about it. Actually this is not quite true; users may want
  to stop generation.

These can be replaced by a single enumeration that indicates if the
type/model is target or not.

This work should be integrated with the model types story.

Merged stories:

*Split references into dogen and non-dogen models*

If we had two containers of references, one for dogen models and
another one for non-dogen models - which we could give a nice name, to
imply its foreign origin - we could then use the dogen references for
registrar, etc. This is a replacement for the origin type.

We need a good name for these. Candidates:

- proxy model: represents something that exists in the outside
  world. e.g. =is_proxy=.

*** Helper methods should have their own includes                     :story:

When a formatter relies on the helper methods, we have a problem: we
need to determine the required includes from the main formatter
without knowing what the helper methods may need. We have hacked this
with things like the "special includes" but there must be a cleaner
way of doing this. For example, we could ask the helper methods
formatter to provide its includes and it would be its job to either
delegate further or to compute the includes. This would at least
remove the duplication of code between io and types.

*** Add =interface= stereotype                                        :story:

Even though we can't generate much outside of plain types, we should
already have support for a stereotype of =interface= which for now
behaves just like =service=. In the future we may be able to code
generate the interface. This should be implemented in yarn as a type
on its own right.

- add an interface which is: element, operatable, relatable. Not
  stateful. We should also have a "is abstract" flag
  somewhere. Perhaps in relatable?

*** Implement module expander test                                    :story:

We copied across the code for the module expander test from yarn json
but didn't actually finished implementing it.

*** Create =src= and =include= facets                                 :story:

At present we have some formatters that are not in the traditional
facets such as =types=, etc. We should make facets for them. We need
to check what the current facet name is. There should only be one case
of this, the CMakeLists formatters.

*** Move all properties in =cpp= to a properties namespace            :story:

Once all formattables are gone, we should have only properties left in
the formattables namespace. We should then rename it to
properties.

Merged stories:

*Split formatter properties and associated classes from formattables*

We have two kinds of data: the formattables themselves (mapped from
yarn) and associated data (formatter properties). The latter is
totally independent. We should create a namespace for all of these
classes and a workflow that produces the data ready for consumption. A
tentative name is =manifest=.

*** Consider renaming nested name                                     :story:

*New understanding*:

This story requires further analysis. Blindly following the composite
pattern was tried but it resulted in a lot of inconsistencies because
we then had to follow MEC-33 and create =abstract_qname=; however, the
nested qname does not really behave like a composite qname; its more
like the difference between a type in isolation and a type
instantiated as an argument of a function. For example, whilst the
type in isolation may have unknown template parameters, presumably, as
an argument of a function these have been instantiated with real
types.

One way to solve this is just to make the type name a bit more
explicit rather than try to imply the composite pattern
(e.g. "nested"). We need a name that signifies "instantiated
type". Look at the C++ standard for the difference between defining a
generic type and instantiating a generic type.

No good names yet (type reference, type instantiation, instantiated
name). What are we trying to represent: an identifier which points to
a complete definition of a name such that the name can be instantiated
as a type in the underlying language. By "instantiated" we mean used
to define variables of this type. In this light: instantiable name,
definable name? If we choose instantiable name, we could then rename
"children" to type arguments.

Other notes:

- there is such a thing as a element instance identifier. We call it
  nested name at present. The element instance identifier identifies
  instantiations of types. It models two cases: for the case where the
  type has no type parameters, the instance identifier is equal to the
  element identifier; for all other cases, it is a hierarchical
  collection of element identifiers, modeling the type parameter
  structure.

*Previous understanding*:

We should just follow the composite pattern in the naming.

*** Copyright holders is scalar when it should be an array            :story:

At present its only possible to specify a single copyright holder. It
should be handled the same was as odb parameters, but because that is
done with a massive hack, we are not going to extend the hack to
copyright holders.

*** Filter out unused types from final model                          :story:

When we finished assembling the model we should be able to determine
which supporting types are in use and drop those that are not. This
can be done just before building the final model (or as part of that
task).

We should have a class responsible for removing all types from a model
which are not in use. This could be done as part of model assembly.

One way this could be achieved is by adding a "usages" property,
computed during resolution. Resolver could keep track of the
non-target names that are in use and return those.

*** Handle enumeration type dynamically                               :story:

Add some enumeration post-processing that assigns it a underlying
type. Should be done with merged model (look for a primitive type with
property =is_default_enumeration_type=).

This should be done as part of resolution perhaps; user provides a raw
type, we expand it during expansion and resolve it during
resolution. If the string is empty, we should use the default
enumeration type. It is chosen from the collection of
primitives. There can only be one type marked as
default. =is_enumeration_default_type=? Read from JSON file.

*** Services and leaves are not properly handled                      :story:

We are manually ignoring services when calculating leaves.

*** Use dots in data files extensions                                 :story:

At the moment we use extensions such as =xmlyarn=. It should really be
=.xml.yarn= or something of the kind.

*** Consider renaming includers                                       :story:

Its very confusing to have header files that include lots of other
header files called "includers". There is too much overloading. We
should consider calling them "master header files" as per Schaling
terminology in the [[http://theboostcpplibraries.com/boost.spirit][boost book]].

*** Update Windows CDash agent                                        :story:

We need to get the build green on the Windows agent again.

*** Add tests to identifier parser with invalid names                 :story:

We need to handle properly the following cases:

- totally blank name.
- template with angle brackets but nothing inside: =a<>=.
- template with angle brackets, type and then a comma: =a<b,>=.

** Deprecated
*** CANCELLED Add support for pulling dependencies from biicode       :story:
    CLOSED: [2015-12-22 Tue 01:10]

*Rationale*: We are going with Conan since it was so easy to setup.

[[https://www.biicode.com/][Biicode]] is a nuget-like repo for c++. We should look into both
consuming dependencies from it and pushing dogen into it. In addition
there are associated emblems:

https://github.com/Manu343726/snail

We should also look into [[https://www.biicode.com/biicode-open-source-challenge][the challenge]].

We should push both the C++ libraries as well as the dogen binary.

We should take the least intrusive possible approach to start with, by
creating a split setup for biicode.

*** CANCELLED Create a blog post on biicode                           :story:
    CLOSED: [2015-12-22 Tue 01:10]

*Rationale*: We are going with Conan since it was so easy to setup.

Investigate adding biicode support since we need to add a RapidJson
dependency. Create a blog post about it.

Post has [[https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/blog/biicode.org][already been started]].
*** CANCELLED Add relationship types to handle "requires"             :story:
    CLOSED: [2015-12-23 Wed 15:44]

*Rationale*: This solution is too complicated now that there is no
need to make it generic. We need to revisit the problem and focus only
on enablement.

*New Understanding*

- we could solve this problem if in dynamic fields could have a
  "propagation type" that results in propagating field instances
  across the element graph.
- this can only be done as the last step in yarn because we need all
  properties to have been indexed, merging, resolution etc.
- at this point we could generate a graph. Vertices are the dynamic
  objects; edges are obtained by looking at the relevant
  relationships: regular associations, weak associations, parents. We
  perhaps should have one graph per relationship type to make things
  easier.
- the graph starts at a root, and the next vertex is the first dynamic
  object that needs to be "computed". We look at all the fields in
  that object that require "computation" and at the "computation
  type".
- cycles are the big problem. However, it seems one cannot have cycles
  in C++ as this would cause inclusion problems. This is normally
  resolved by weak relationships. We need to confirm this for cycles
  with more than 2 edges. If this is true, we could force all
  languages to declare relationships as weak when there is a cycle
  somehow (note that we do not have the concept of pointers in java/c#
  so perhaps the relationship itself would have to be annotated). We
  could then have a default behaviour for weak relationships such as
  never follow, etc.
- at present we are handling the inclusion of non-existing formatters
  in master includers by manually filtering these. See factory for
  master includers. This should all be handled by enablement and the
  graph.

*Previous Understanding*

This story needs to be named properly, once we actually understand
what it is that it is about.

Moment of realisation: we could describe all relationships between
types as relations in the form a R b. We are already doing these, its
just that we model them in a variety of ways (properties, relationship
types, etc). This is fine because the driver for the modeling is the
"language" model (e.g. =cpp=). However, there is a class of use cases
that we have yet failed to solve. The general form of these use cases
is as follows:

- type b has some meta-data m;
- type b is related to type a via some relation R;
- type a should also be treated as having m.

Another variation is where a is related to multiple types b0, b1, bn
and we want to perform some computation on m0, m1, mn to determine the
value for a.

It seems that both of these use cases could be solved if only we had a
way to represent a R b in =tack::model=. We have spotted the following
Rs:

- non-transitive aggregation, not "expanding" generics: all types
  aggregated with a type; if a type is a generic type, we ignore the
  type parameters. It is non-transitive in the following sense: if
  type a aggregates type b and type b aggregates type c, it does not
  mean that type a aggregates type c. Use cases: requires manual move
  constructor, requires manual default constructor.
- non-transitive aggregation, "expanding" generics: all types
  aggregated with a type; if a type is a generic type, then all of the
  type parameters are considered to also be associated. Use cases:
  requires stream manipulators.
- transitive association, "expanding" generics: all types aggregated
  to a type and all types that those types aggregate to; all types
  that this type inherits from and their parents. Use cases:
  enablement.

Note that we still haven't solved the fundamental enablement problem,
as we can still have cycles on the graph (e.g. a is related to
a). However, we can now create the traversal with cycles algorithm: it
follows R and remembers the original type (e.g. a); when we spot that
type again (e.g. y depends on a and a depends on y) we add all types
that depend on it (y) to a "blocked" pile. We do process all other
dependencies of y. The pile would have the form of: a blocks y. Even
though y is blocked, we can still answer a. Once we answered a we can
then answer all types blocked by a (they may have more than one block
though). The key thing here is if a type has a cycle on itself its not
a problem, we can just skip it. If a type has a dependency on a type
which has a cycle, we must first sort out the type with the cycle.

This story still needs a lot of work but its just a dump of all of the
ideas at this point in time.

Notes:

- we need a "requires" repository, factory etc in formattables that
  handles all of the "requires xyz" cases. We may need two of these,
  per relation type.
- we need to expand enablement to perform the algorithm above.
- we need to expand relationship management in tack, adding these new
  relationship types and populating them.
- includes builder needs access to the "requires" data in order to
  compute includes.

Merged stories:

*Add support for the relationships graph in enabler*

*Note*: this story needs refactoring. It is basically here to cover
the support for a graph with cycles in enabler but has not yet been
updated.

This needs a bit more analysis. The gist of it is that not all types
support all formatters. We need a way to determine if a formatter is
not supported. This probably should be inferred by a "is dogen model"
property (see backlog); e.g. non-dogen models need their types to have
an inclusion setup in order to be "supported", otherwise they should
default to "not-supported". However the "supported" flag is populated,
we then need to take into account relationships and propagate this
flag across the model such that, if a type =A= in a dogen model has a
property of a type =B= from a non-dogen model which does not support a
given formatter =f=, then =A= must also not support =f=.

In order to implement this feature we need to:

- update the SML grapher to take into account relationships
  (properties that the class has) as well as inheritance.
- we must only visit related types if we ourselves do not have values
  for all supported fields.
- we also need a visitor that detects cycles; when a cycle is found we
  simply assume that the status of the revisited class is true (or
  whatever the default value of "supported" is) and we write a warning
  to the log file. We should output the complete path of the cycle.
- users can override this by setting supported for all formatters
  where there are cycles.
- we could perhaps have a bitmask by qname; we could start by
  generating all bitmasks for all qnames and setting them to default
  value. We could then find all qnames that have supported set to
  false and update the corresponding bitmasks. Then we could use the
  graph to loop through the qnames and "and" the bitmasks of each
  qname with the bitmasks of their related qnames. The position of
  each field is allocated by the algorithm (e.g. the first "supported"
  field is at position 0 and so on). Actually the first position of
  the bitmask could be used to indicate if the bitmask has already
  been processed or not. In the presence of a cycle force it to true.
- we need a class that takes the SML model and computes the supported
  bitmasks for each qname; the supported expander then simply takes
  this (perhaps as part of the expansion context), looks up for the
  current qname and uses the field list to set the flags
  appropriately.
- we should remove all traces of supported from a settings
  perspective; supported and multi-level enabled are just artefacts of
  the meta-data. From a settings perspective, there is just a
  formatter level (common formatter settings) enabled which determines
  whether the formatter is on or off. How that flag came to be
  computed is not relevant outside the expansion process. This also
  means we can have simpler or more complex policies as time allows us
  improve on this story; provided we can at least set all flags to
  enabled we can move forward.

Solution for cycles:

- detect the cycle and then remember the pair (a, b) where b is the
  start of the cycle and a is the last vertex before the cycle. We
  should assume that a is (true, true) for the edge (a, b) and compute
  all other edges. Finally, once the graph has been processed we
  should check all of the pairs in a cycle; for these we should simply
  look at the values of b, and update a accordingly.

Other notes:

- we need some validation to ensure that some types will be generated
  at all. The existing "generatable types" logic will have to be
  removed or perhaps updated; we should take the opportunity to make
  it reflect whether a type belongs to the target model or not. This
  has no bearing on generatability (other that non-target types are
  always not generated). So at the middle-end level we need to check
  if there are any target types at all, and if not, just want the user
  and exit. Then, a second layer is required at the model group /
  language level to determine if there are any types to generate. It
  is entirely possible that we end up not generating anything at all
  because once we went through the graph everything got
  disabled. Users will have to somehow debug this when things go
  wrong.
- following on from this, we probably need a "dump info" option that
  explains the enabled/supported decisions for a given model, for all
  target types; possibly, users could then supply regexes to filter
  this info (e.g. why did you not generate =hash= for type =xyz=? can
  I see all types for formatter =abc=?). It may be useful to have an
  option to toggle between "target only types" and "all types",
  because the system types may be the ones causing the problem.
- the enabled supported logic applies to all formatters across all
  model groups.

*Capture enablement validation rules*

Enablement requires some validation. This story captures all the rules
we need to check for.

- integrated IO must not be enabled if IO is enabled and vice-versa
  (opaque settings validator). actually it seems this is possible, we
  need to investigate the current implementation.
- types must be enabled
- if serialisation is enabled, types forward declaration of the
  serialisation classes must be enabled
*** CANCELLED Use clang to extract stitch template header             :story:
    CLOSED: [2016-01-01 Fri 17:50]

*Rationale*: this is far too complicated. Instead we will use the
meta-templates approach.

Once we integrate clang, we could look at the expanded stitch template
and infer the required header file. For the current use case, this is
just a case of extracting the function signature. This may not work so
well for more complicated scenarios such as with a class.

We should keep in mind that stitch templates will not be stand-alone
in a world where merging is supported, so this story may not make a
whole lot of sense.
