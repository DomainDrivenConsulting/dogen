#+title: Release Notes for Sprint 47
#+options: date:nil toc:nil author:nil num:nil
#+todo: ANALYSIS IMPLEMENTATION TESTING | COMPLETED CANCELLED
#+tags: story(s) epic(e) task(t) note(n) spike(p)

* Release Notes

This file contains all stories that were closed during sprint 47.

The *Mission Statement* for this sprint is a continuation of the
previous sprint: to get the build environment back up and running
across all the build agents. By the end of this sprint we intend to
have all build agents with green builds, and the packages uploaded to
GDrive.

** Development Stories Implemented

#+begin: clocktable :maxlevel 3 :scope subtree
Clock summary at [2014-03-27 Thu 08:22]

| Headline                                              | Time   |      |      |
|-------------------------------------------------------+--------+------+------|
| *Total time*                                          | *7:53* |      |      |
|-------------------------------------------------------+--------+------+------|
| Development Stories Implemented                       |        | 7:53 |      |
| IMPLEMENTATION Release notes and backlog grooming     |        |      | 0:50 |
| IMPLEMENTATION Updates to the manual and readme files |        |      | 5:51 |
| IMPLEMENTATION Complete the integral work for Linux   |        |      | 0:15 |
| COMPLETED Fix issues with missing builds              |        |      | 0:57 |
#+end:

*** IMPLEMENTATION Release notes and backlog grooming                  :task:
    CLOCK: [2014-03-27 Thu 07:52]--[2014-03-27 Thu 08:22] =>  0:30
    CLOCK: [2014-03-18 Tue 08:07]--[2014-03-18 Tue 08:12] =>  0:05
    CLOCK: [2014-03-18 Tue 07:52]--[2014-03-18 Tue 08:07] =>  0:15

Updates to release notes and backlog.

*** IMPLEMENTATION Updates to the manual and readme files              :task:
    CLOCK: [2014-03-25 Tue 07:51]--[2014-03-25 Tue 08:11] =>  0:20
    CLOCK: [2014-03-24 Mon 08:04]--[2014-03-24 Mon 08:50] =>  0:46
    CLOCK: [2014-03-21 Fri 07:56]--[2014-03-21 Fri 08:40] =>  0:44
    CLOCK: [2014-03-20 Thu 17:32]--[2014-03-20 Thu 18:02] =>  0:30
    CLOCK: [2014-03-20 Thu 07:56]--[2014-03-20 Thu 08:37] =>  0:41
    CLOCK: [2014-03-19 Wed 18:09]--[2014-03-19 Wed 18:50] =>  0:41
    CLOCK: [2014-03-19 Wed 07:58]--[2014-03-19 Wed 08:37] =>  0:39
    CLOCK: [2014-03-18 Tue 21:03]--[2014-03-18 Tue 21:45] =>  0:42
    CLOCK: [2014-03-18 Tue 18:24]--[2014-03-18 Tue 19:00] =>  0:36
    CLOCK: [2014-03-18 Tue 08:28]--[2014-03-18 Tue 08:40] =>  0:12

Use build downtime to update the manual and / or readme file.

*** IMPLEMENTATION Complete the integral work for Linux               :story:
    CLOCK: [2014-03-18 Tue 08:12]--[2014-03-18 Tue 08:27] =>  0:15

Since we can't use docker, we need to figure out where we left
integral and get it in a state good enough to be used in production.

- it seems we have not pulled (or pushed) the latest integral work. We
  need to sync with lorenz before we proceed.

*** COMPLETED Fix issues with missing builds                          :spike:
    CLOSED: [2014-03-19 Wed 18:10]
    CLOCK: [2014-03-18 Tue 22:00]--[2014-03-18 Tue 22:57] =>  0:57


We seem to have no builds for the last few days, probably due to the
changes done while messing around with docker.

*** Implement integral features for OSX and Windows                   :story:

These operative systems do not have =systemd=. We should do a cursory
investigation on =launchd= on OSX, but if it becomes too complicated,
we should just add the missing features to integral (ported across
from PFH).

We should also consider moving across to Windows 7.

*** Implement flymake from the EDE project                            :story:

This move of directories highlighted the fragility of the current
flymake hack: every time the top-level directory changes we need to
update =cunene=. Ideally what we want is to have a top-level file -
most ideally =dogen.ede= with some lisp code that would setup the
dogen paths for flymake. Users would only need to load this up to use it.

*** Remove versioning from packages                                   :story:

We don't seem to have a particularly good story around versioning in
packages. It's best to remove it for now until we really understand
how it should work.

In addition, we will be using Docker to test the packages, making
versioning less of a necessity.

*** Install packages into =/usr=                                      :story:

As we will be using Docker to test the packages, we can now write
files into =/usr/bin= without fear. Move from =/opt= into =/usr=.

*** Fix issues with database tests                                    :story:

Last sprint we solved the delays in nightlies by adding concurrency to
the tests; however, that broke the database tests. We need to refactor
the tests to allow them to run concurrently.

**** Re-enable schema updates

We are deleting the entire DB schema and re-applying it for every
invocation of the tests. This does not work on a concurrent world. We
commented it out for now, but we need a proper solution for this.

**** Investigate errors in tests

We seem to have traffic-lighters in the database tests when executing
them concurrently. Somewhere they must be trampling on each others
feet.

*** Add support to upload packages into GDrive                        :story:

We need to upload the packages created by the build to a public Google
Drive (GDrive) location.

- Google drive folder created [[https://drive.google.com/folderview?id%3D0B4sIAJ9bC4XecFBOTE1LZEpINUE&usp%3Dsharing][here]].
- See [[https://developers.google.com/drive/quickstart-ruby][this article]].
- [[http://stackoverflow.com/questions/15798141/create-folder-in-google-drive-with-google-drive-ruby-gem][Create folders]] to represent the different types of uploads:
  =tag_x.y.z=, =last=, =previous=. maybe we should only have latest
  and tag as this would require no complex logic: if tag create new
  folder, if latest, delete then create.

*** Enable package sanity tests for Linux                             :story:

Now that we will be using docker, we could create a simple =systemd=
ctest script that runs as root in a docker container:

- it monitors the GDrive location for files that match a given regular
  expression (e.g. we need to make sure we match the bitness and the
  platform)
- if it finds one, it installs it and runs sanity scripts.
- it then uninstalls it and makes sure the docker image is identical
  to how we started (however that is done in docker)

** Deprecated Development Stories
